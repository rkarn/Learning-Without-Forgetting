{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([b'coarse_labels', b'batch_label', b'filenames', b'fine_labels', b'data']) dict_keys([b'coarse_label_names', b'fine_label_names'])\n",
      "50000 21 50000 50000 50000\n",
      "10000 20 10000 10000 10000\n",
      "100 20\n",
      "100 20\n",
      "100 20\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 5.0)\n",
    "\n",
    "os.chdir('/root/CIFAR-100-Dataset')\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "train_set=unpickle('train')\n",
    "test_set=unpickle('test')\n",
    "meta_set=unpickle('meta')\n",
    "\n",
    "train_set_dict_keys= train_set.keys()\n",
    "meta_set_dict_keys=meta_set.keys()\n",
    "print(train_set_dict_keys, meta_set_dict_keys)\n",
    "print(len(train_set[b'data']), len(train_set[b'batch_label']), len(train_set[b'fine_labels']), len(train_set[b'coarse_labels']), len(train_set[b'filenames']))\n",
    "print(len(test_set[b'data']), len(test_set[b'batch_label']), len(test_set[b'fine_labels']), len(test_set[b'coarse_labels']), len(test_set[b'filenames']))\n",
    "print(len(meta_set[b'fine_label_names']), len(meta_set[b'coarse_label_names']))\n",
    "\n",
    "print(len(set(train_set[b'fine_labels'])), len(set(train_set[b'coarse_labels'])))\n",
    "print(len(set(test_set[b'fine_labels'])), len(set(test_set[b'coarse_labels'])))\n",
    "\n",
    "x_train=train_set[b'data']\n",
    "x_test=test_set[b'data']\n",
    "y_train=np.array(train_set[b'coarse_labels'])\n",
    "y_test=np.array(test_set[b'coarse_labels'])\n",
    "\n",
    "#cleanup_nums = {\"Worms\":0, \"Shellcode\":1, \"Reconnaissance\":2, \"Normal\":3, \"Generic\":4, \"Fuzzers\":5, \"Exploits\":6, \"DoS\":7, \"Backdoor\":8, \"Analysis\":9}\n",
    "#Y_train_all_attacks.replace(cleanup_nums,inplace=True)\n",
    "#Y_test_all_attacks.replace(cleanup_nums,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train), type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['draw_if_interactive', 'pylab', 'select']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "os.chdir('/root/pathint/fig_split_mnist')\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace\n",
    "\n",
    "import sys, os\n",
    "sys.path.extend([os.path.expanduser('..')])\n",
    "from pathint import utils\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# import operator\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "select = tf.select if hasattr(tf, 'select') else tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "input_dim = 3072\n",
    "output_dim = 20\n",
    "\n",
    "# Network params\n",
    "n_hidden_units = 1000\n",
    "activation_fn = tf.nn.relu\n",
    "\n",
    "# Optimization params\n",
    "batch_size = 100\n",
    "epochs_per_task = 20\n",
    "\n",
    "n_stats = 1\n",
    "\n",
    "# Reset optimizer after each age\n",
    "reset_optimizer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "task_labels = [[0,1,2,3], [4,5,6,7], [8,9,10], [11,12,13,14], [15,16,17],[18,19]]\n",
    "#task_labels = [[4,2], [0,6], [3,8], [9,7], [1,5],[8,9],[6,7],[5,5],[3,2],[0,1]]\n",
    "#task_labels = [[8,9], [6,7], [4,5], [2,3], [0,1]]\n",
    "#task_labels = [[0,9], [7,8], [3,6], [1,4], [2,5]]\n",
    "#task_labels = [[0,1,2], [3,4,5], [6,7,8,9]]\n",
    "#task_labels = [[1,5,8],[2,5,7,9],[3,4,6]]\n",
    "#task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9],[1,5],[0,9],[3,8],[0,6],[4,2],[3,5],[0,4],[9,6],[1,2]]\n",
    "n_tasks = len(task_labels)\n",
    "nb_classes  = 20\n",
    "training_datasets = []\n",
    "validation_datasets = []\n",
    "multihead=False\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(y_train, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = x_train[idx], np_utils.to_categorical(label_map[y_train[idx]], len(labels))\n",
    "    else:\n",
    "        data = x_train[idx], np_utils.to_categorical(y_train[idx], nb_classes)\n",
    "        training_datasets.append(data)\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(y_test, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = x_test[idx], np_utils.to_categorical(label_map[y_test[idx]], len(labels))\n",
    "    else:\n",
    "        data = x_test[idx], np_utils.to_categorical(y_test[idx], nb_classes)\n",
    "        validation_datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import keras.backend as K\n",
    "import keras.activations as activations\n",
    "\n",
    "output_mask = tf.Variable(tf.zeros(output_dim), name=\"mask\", trainable=False)\n",
    "\n",
    "def masked_softmax(logits):\n",
    "    # logits are [batch_size, output_dim]\n",
    "    x = select(tf.tile(tf.equal(output_mask[None, :], 1.0), [tf.shape(logits)[0], 1]), logits, -1e32 * tf.ones_like(logits))\n",
    "    return activations.softmax(x)\n",
    "\n",
    "def set_active_outputs(labels):\n",
    "    new_mask = np.zeros(output_dim)\n",
    "    for l in labels:\n",
    "        new_mask[l] = 1.0\n",
    "    sess.run(output_mask.assign(new_mask))\n",
    "    #print(sess.run(output_mask))\n",
    "    \n",
    "def masked_predict(model, data, targets):\n",
    "    pred = model.predict(data)\n",
    "    #print(pred)\n",
    "    acc = np.argmax(pred,1)==np.argmax(targets,1)\n",
    "    return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn, input_shape=(input_dim,)))\n",
    "model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn))\n",
    "#model.add(Dense(n_hidden_units, activation=activation_fn))\n",
    "model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax))\n",
    "#model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax, input_shape=(input_dim,)))\n",
    "\n",
    "from pathint import protocols\n",
    "from pathint.optimizers import KOOptimizer\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.callbacks import Callback\n",
    "from pathint.keras_utils import LossHistory\n",
    "from keras.callbacks import History \n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "#protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "#protocol_name, protocol = protocols.FISHER_PROTOCOL('sum')\n",
    "opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "#opt = SGD(1e-3)\n",
    "#opt = RMSprop(lr=1e-3)\n",
    "oopt = KOOptimizer(opt, model=model, **protocol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=oopt, metrics=['accuracy'])\n",
    "model.model._make_train_function()\n",
    "saved_weights = model.get_weights()\n",
    "\n",
    "save_weights_epoch=[]\n",
    "save_loss_epoch=[]\n",
    "print_weights = LambdaCallback(on_epoch_end=lambda batch, logs: save_weights_epoch.append(model.get_weights()))\n",
    "history = LossHistory()\n",
    "#history = History()\n",
    "callbacks = [history]\n",
    "datafile_name = \"split_mnist_data_%s.pkl.gz\"%protocol_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regularizer_fn': <function quadratic_regularizer at 0x7f98a223f488>, 'step_updates': [('grads2', <function <lambda>.<locals>.<lambda> at 0x7f97611082f0>)], 'task_updates': [('omega', <function <lambda>.<locals>.<lambda> at 0x7f9761108bf8>), ('cweights', <function <lambda>.<locals>.<lambda> at 0x7f9761108e18>), ('grads2', <function <lambda>.<locals>.<lambda> at 0x7f9761108b70>)], 'init_updates': [('cweights', <function <lambda>.<locals>.<lambda> at 0x7f9761108a60>)]}\n"
     ]
    }
   ],
   "source": [
    "print(protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fits(cvals, training_data, valid_data, eval_on_train_set=False, nstats=1):\n",
    "    acc_mean = dict()\n",
    "    acc_std = dict()\n",
    "    model_weights_save = []   #Empty list to save the model weights aftertraining each task\n",
    "    imp_par = dict()  #Empty list to save importance parameter after learning each progressive task\n",
    "    for cidx, cval_ in enumerate(tqdm(cvals)):\n",
    "        runs = []\n",
    "        for runid in range(nstats):\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # model.set_weights(saved_weights)\n",
    "            cstuffs = []\n",
    "            evals = []\n",
    "            print(\"setting cval\")\n",
    "            cval = cval_\n",
    "            oopt.set_strength(cval)\n",
    "            oopt.init_task_vars()\n",
    "            print(\"cval is\", sess.run(oopt.lam))\n",
    "            for age, tidx in enumerate(range(n_tasks)):\n",
    "                print(\"Age %i, cval is=%f\"%(age,cval))\n",
    "                print(\"settint output mask\")\n",
    "                set_active_outputs(task_labels[age])\n",
    "                stuffs = model.fit(training_data[tidx][0], training_data[tidx][1], batch_size, epochs_per_task, callbacks=[print_weights])\n",
    "                save_loss_epoch.append(stuffs.history['loss'])\n",
    "                oopt.update_task_metrics(training_data[tidx][0], training_data[tidx][1], batch_size)\n",
    "                oopt.update_task_vars()\n",
    "                ftask = []\n",
    "                model_weights_save.append(model.get_weights()) #Save the model weights aftertraining each task\n",
    "                for j in range(n_tasks):\n",
    "                    set_active_outputs(task_labels[j])\n",
    "                    if eval_on_train_set:\n",
    "                        f_ = masked_predict(model, training_data[j][0], training_data[j][1])\n",
    "                    else:\n",
    "                        f_ = masked_predict(model, valid_data[j][0], valid_data[j][1])\n",
    "                    ftask.append(np.mean(f_))\n",
    "                evals.append(ftask)\n",
    "                cstuffs.append(stuffs)\n",
    "\n",
    "                # Re-initialize optimizater variables\n",
    "                if reset_optimizer:\n",
    "                    oopt.reset_optimizer()\n",
    "\n",
    "            evals = np.array(evals)\n",
    "            runs.append(evals)\n",
    "        \n",
    "        runs = np.array(runs)\n",
    "        acc_mean[cval_] = runs.mean(0)\n",
    "        acc_std[cval_] = runs.std(0)\n",
    "    return dict(mean=acc_mean, std=acc_std),model_weights_save, imp_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# cvals = np.concatenate(([0], np.logspace(-2, 2, 10)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-1, 2, 2)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-2, 0, 3)))\n",
    "#cvals = np.logspace(-3, 3, 7)#[0, 1.0, 2, 5, 10]\n",
    "cvals = [0, 1.0]\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cval\n",
      "cval is 0.0\n",
      "Age 0, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0780 - acc: 0.2506     \n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Age 1, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Age 2, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 2/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 3/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 4/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 5/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 6/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 7/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 8/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 9/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 10/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 11/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 12/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 13/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 14/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 15/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 16/20\n",
      "7500/7500 [==============================] - 5s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 17/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 18/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 19/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 20/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Age 3, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Age 4, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 2/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 4/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 5/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 6/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 7/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 8/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 9/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 10/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 11/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 12/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 13/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 14/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 15/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 16/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 17/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 18/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 19/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 20/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Age 5, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 2/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 3/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 4/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 5/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 6/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 7/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 8/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 9/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 10/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 11/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 12/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 13/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 14/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 15/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 16/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 17/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 18/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 19/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 20/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [11:04<11:04, 664.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cval\n",
      "cval is 1.0\n",
      "Age 0, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0901 - acc: 0.2494     \n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0887 - acc: 0.2499     \n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Age 1, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Age 2, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 2/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 3/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 4/20\n",
      "7500/7500 [==============================] - 5s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 5/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 6/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 7/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 8/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 9/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 10/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 11/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 12/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 13/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 14/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 15/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 16/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 17/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 18/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 19/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 20/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Age 3, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 6s - loss: 12.0886 - acc: 0.2500     \n",
      "Age 4, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 2/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 4/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 5/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 6/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 7/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 8/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 9/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 10/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 11/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 12/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 13/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 14/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 15/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 16/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 17/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 18/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 19/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Epoch 20/20\n",
      "7500/7500 [==============================] - 4s - loss: 10.7454 - acc: 0.3333     \n",
      "Age 5, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 2/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 3/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 4/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 5/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 6/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 7/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 8/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 9/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 10/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 11/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 12/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 13/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 14/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 15/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 16/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 17/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     - ETA: 0s - loss: 7.9422 - a\n",
      "Epoch 18/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 19/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n",
      "Epoch 20/20\n",
      "5000/5000 [==============================] - 3s - loss: 8.0590 - acc: 0.5000     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [22:07<00:00, 663.74s/it]\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "recompute_data = True\n",
    "\n",
    "if recompute_data:\n",
    "    data,model_weights_save,imp_par = run_fits(cvals, training_datasets, validation_datasets, eval_on_train_set=False, nstats=n_stats)\n",
    "    utils.save_zipped_pickle(data, datafile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 1000)              3073000   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                20020     \n",
      "=================================================================\n",
      "Total params: 4,094,020\n",
      "Trainable params: 4,094,020\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(3072, 1000)\n",
      "(1000,)\n",
      "(1000, 1000)\n",
      "(1000,)\n",
      "(1000, 20)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "print(model.summary())\n",
    "model.save_weights('saved_weights.h5') #This file cannot be opend normaly to view the weghts. It can be loaded through load_model() or can be opend via hdf5 viewer\n",
    "\n",
    "#Shape of the array containg model weights\n",
    "a_list = model.get_weights()\n",
    "for i in range(len(a_list)):\n",
    "    print((np.array(a_list[i])).shape)\n",
    "\n",
    "#a_list[0][0][0] = a_list[0][0][0]+0.00001\n",
    "#print(a_list[0][0][0])\n",
    "#model.set_weights(a_list)\n",
    "\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#import pydot\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_zipped_pickle(datafile_name)\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: array([[0.89707047, 0.72999353, 0.85853499, 0.64988939, 0.53443673,\n",
      "        0.058653  , 0.83987661, 0.84052575, 0.9960624 , 0.7922204 ],\n",
      "       [0.89707047, 0.84221925, 0.82854393, 0.31596469, 0.53577149,\n",
      "        0.058653  , 0.75778183, 0.96976414, 0.9419503 , 0.7922204 ],\n",
      "       [0.89707047, 0.80579327, 0.30259178, 0.64986749, 0.53390283,\n",
      "        0.05870477, 0.70386988, 0.96976414, 0.94108523, 0.87873086],\n",
      "       [0.89707047, 0.80902679, 0.30259178, 0.7313884 , 0.56807261,\n",
      "        0.05870477, 0.14021312, 0.96976414, 0.99612207, 0.8803153 ],\n",
      "       [0.89707047, 0.80856056, 0.30259178, 0.7313884 , 0.56700481,\n",
      "        0.05870477, 0.14021312, 0.96976414, 0.99612207, 0.88043414],\n",
      "       [0.45288994, 0.80615422, 0.30247147, 0.7313884 , 0.56700481,\n",
      "        0.94108816, 0.14021312, 0.96772071, 0.99612207, 0.88051336],\n",
      "       [0.45288994, 0.8019732 , 0.30247147, 0.70484263, 0.46609717,\n",
      "        0.94108816, 0.78568424, 0.96515776, 0.99612207, 0.88079064],\n",
      "       [0.45288994, 0.84221925, 0.30247147, 0.67488008, 0.46609717,\n",
      "        0.94108816, 0.78568424, 0.96976414, 0.99612207, 0.88035491],\n",
      "       [0.89707047, 0.84221925, 0.30247147, 0.7313884 , 0.46609717,\n",
      "        0.94108816, 0.78568424, 0.96976414, 0.99612207, 0.8806718 ],\n",
      "       [0.89707047, 0.84221925, 0.30245428, 0.7313884 , 0.46609717,\n",
      "        0.94108816, 0.78568424, 0.96976414, 0.99612207, 0.88360302]])}\n"
     ]
    }
   ],
   "source": [
    "print(data['mean'])\n",
    "for k in cvals:\n",
    "    for i in range(n_tasks):\n",
    "        for j in range(i):\n",
    "            data['mean'][k][j][i] = 0\n",
    "            data['std'][k][j][i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-5.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.colors as colors\n",
    "cmap = plt.get_cmap('cool') \n",
    "cNorm  = colors.Normalize(vmin=-5, vmax=np.log(np.max(list(data['mean'].keys()))))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "print(scalarMap.get_clim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  del sys.path[0]\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x180 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(14, 2.5))\n",
    "axs = [subplot(1,n_tasks+1,1)]#, None, None]\n",
    "for i in range(1, n_tasks + 1):\n",
    "    axs.append(subplot(1, n_tasks+1, i+1, sharex=axs[0], sharey=axs[0]))\n",
    "    \n",
    "keys = list(data['mean'].keys())\n",
    "sorted_keys = np.sort(keys)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "        colorVal = scalarMap.to_rgba(np.log(cval))\n",
    "        # axs[j].plot(evals[:, j], c=colorVal)\n",
    "        axs[j].errorbar(range(n_tasks), mean_vals[:, j], yerr=std_vals[:, j]/np.sqrt(n_stats), c=colorVal)\n",
    "    label = \"c=%g\"%cval\n",
    "    average = mean_vals.mean(1)  #Taking the average of cross validation accuracies accross all tasks after learning each task\n",
    "    axs[-1].plot(average, c=colorVal, label=label)\n",
    "    \n",
    "for i, ax in enumerate(axs):\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_title((['task %d'%j for j in range(n_tasks)] + ['average'])[i])\n",
    "gcf().tight_layout()\n",
    "sns.despine()\n",
    "plt.savefig('2Attack_Accuracy_10task.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89707047 0.89707047 0.89707047 0.89707047 0.89707047 0.10292953\n",
      " 0.10292953 0.10292953 0.89707047 0.89707047] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.21184822 0.84221925 0.84221925 0.84221925 0.84221925 0.84221925\n",
      " 0.84221925 0.84221925 0.84221925 0.86849348] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.68754297 0.10867249 0.30274646 0.30272927 0.30272927 0.30293551\n",
      " 0.30293551 0.30293551 0.30293551 0.30302145] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.73149791 0.7313884  0.7313884  0.66990823 0.66990823 0.66990823\n",
      " 0.656263   0.6553212  0.66114725 0.66178242] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.53470368 0.56326749 0.56567005 0.56326749 0.56940737 0.56940737\n",
      " 0.46609717 0.48478377 0.48478377 0.48478377] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.058653   0.058653   0.90826733 0.90821556 0.90821556 0.941347\n",
      " 0.941347   0.941347   0.941347   0.941347  ] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.14329781 0.21662928 0.21655917 0.66727426 0.66832586 0.66825575\n",
      " 0.73058048 0.73114133 0.73121144 0.73142176] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.93121601 0.96976414 0.96976414 0.96976414 0.96976414 0.96976414\n",
      " 0.96976414 0.96976414 0.96976414 0.96976414] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.99612207 0.99612207 0.99612207 0.99397429 0.99397429 0.99397429\n",
      " 0.99391463 0.99391463 0.99612207 0.99612207] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.7922204  0.7922204  0.13647977 0.12160583 0.12338833 0.11550573\n",
      " 0.11304985 0.11217841 0.11217841 0.19058842] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "       print(mean_vals[:, j],std_vals[:, j]/np.sqrt(n_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "\n",
    "def simple_axis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 237.6x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fractional Correctness = Average of cross validation accuracies of learned tasks only after training each task \n",
    "fig = plt.figure(figsize=(3.3,2.5))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_stuff = []\n",
    "    std_stuff = []\n",
    "    for i in range(len(data['mean'][cval])):\n",
    "        mean_stuff.append(data['mean'][cval][i][:i+1].mean())\n",
    "        std_stuff.append(np.sqrt((data['std'][cval][i][:i+1]**2).sum())/(n_stats*np.sqrt(n_stats)))\n",
    "    # plot(range(1,n_tasks+1), mean_stuff, 'o-', label=\"c=%g\"%cval)\n",
    "    errorbar(range(1,n_tasks+1), mean_stuff, yerr=std_stuff, fmt='o-', label=\"c=%g\"%cval)\n",
    "        \n",
    "axhline(data['mean'][cval][0][0], linestyle='--', color='k')\n",
    "xlabel('Number of tasks')\n",
    "ylabel('Fraction correct')\n",
    "legend(loc='best')\n",
    "xlim(0.5, 8.5)\n",
    "ylim(0.5, 1.02)\n",
    "# grid('on')\n",
    "# sns.despine()\n",
    "simple_axis(ax)\n",
    "plt.savefig('2attack_fractional_correct_UNSW.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.897070467141726, 0.8696448574297311, 0.6806787247890768, 0.6779818040652222, 0.6562669168239876, 0.5714578153590283, 0.5774817075388184, 0.6288052173267944, 0.7585112106308061, 0.7044394974891064]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib     \n",
    "matplotlib.rc('xtick', labelsize=14)     \n",
    "matplotlib.rc('ytick', labelsize=14)\n",
    "Hess_rank=[1802, 1907, 2035, 2116, 2170, 2215, 2254, 2257, 2300, 2301] #calculated previously\n",
    "plt.plot(Hess_rank,mean_stuff,'ko-', linewidth=2)\n",
    "for i,j,k in zip(Hess_rank,mean_stuff,range(n_tasks)):\n",
    "    plt.annotate(str(k),xy=(i,j),color='r', fontsize=14)\n",
    "plt.xlabel('Hessian Matrix Rank',fontsize=12)\n",
    "plt.ylabel('Fractional Correct Accuracy(*100%)',fontsize=12)\n",
    "plt.savefig('Fractioncorrect-Hessian-UNSW.pdf')\n",
    "plt.show()\n",
    "print(mean_stuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the Autocorrelation Matrix for task= 0 is : 24\n",
      "Rank of the Autocorrelation Matrix for task= 1 is : 36\n",
      "Rank of the Autocorrelation Matrix for task= 2 is : 36\n",
      "Rank of the Autocorrelation Matrix for task= 3 is : 38\n",
      "Rank of the Autocorrelation Matrix for task= 4 is : 39\n",
      "Rank of the Autocorrelation Matrix for task= 5 is : 39\n",
      "Rank of the Autocorrelation Matrix for task= 6 is : 39\n",
      "Rank of the Autocorrelation Matrix for task= 7 is : 40\n",
      "Rank of the Autocorrelation Matrix for task= 8 is : 41\n",
      "Rank of the Autocorrelation Matrix for task= 9 is : 41\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import matrix_rank\n",
    "import math\n",
    "corr_matrix = []\n",
    "corr_row = []\n",
    "Rank_corr_matrix=[]\n",
    "for j in range(n_tasks):\n",
    "    df = pd.DataFrame(training_datasets[j][0])\n",
    "    correlation_matrix = df.corr().values\n",
    "    correlation_matrix = np.nan_to_num(correlation_matrix)\n",
    "    for k in range(len(correlation_matrix)):\n",
    "        for i in range(len(correlation_matrix)):\n",
    "            corr_elem = (math.ceil(correlation_matrix[k][i]*1e10)/1e10)\n",
    "            corr_row.append(np.around(corr_elem))\n",
    "        corr_matrix.append(corr_row)\n",
    "        corr_row = []\n",
    "    rank_corr_matrix=np.linalg.matrix_rank(np.asarray(corr_matrix))\n",
    "    Rank_corr_matrix.append(rank_corr_matrix)\n",
    "    print('Rank of the Autocorrelation Matrix for task=',j,'is :',rank_corr_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights Pattern after training each task\n",
    "Flatten_weights=[]\n",
    "#Flattening the weights into a list\n",
    "def flatten(x):\n",
    "    try:\n",
    "        it = iter(x)\n",
    "    except TypeError:\n",
    "        yield x\n",
    "    else:\n",
    "        for i in it:\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "                \n",
    "for i in range(len(model_weights_save)):\n",
    "    Flatten_weights.append(list(flatten(model_weights_save[i]))) \n",
    "\n",
    "Extract_model_params = [];\n",
    "#For model parameters without consolidation use val, with consolidation use val+50 \n",
    "for i in range(n_tasks):   \n",
    "    Extract_model_params.append(Flatten_weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(save_weights_epoch),len(model_weights_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the Hessian Matrix after task= 0 is : 854\n",
      "Rank of the Hessian Matrix after task= 1 is : 1661\n",
      "Rank of the Hessian Matrix after task= 2 is : 1774\n",
      "Rank of the Hessian Matrix after task= 3 is : 1948\n",
      "Rank of the Hessian Matrix after task= 4 is : 1993\n",
      "Rank of the Hessian Matrix after task= 5 is : 2034\n",
      "Rank of the Hessian Matrix after task= 6 is : 2065\n",
      "Rank of the Hessian Matrix after task= 7 is : 2085\n",
      "Rank of the Hessian Matrix after task= 8 is : 2099\n",
      "Rank of the Hessian Matrix after task= 9 is : 2104\n"
     ]
    }
   ],
   "source": [
    "#Weights Pattern after training each task\n",
    "Flatten_weights=[]\n",
    "#Flattening the weights into a list\n",
    "def flatten(x):\n",
    "    try:\n",
    "        it = iter(x)\n",
    "    except TypeError:\n",
    "        yield x\n",
    "    else:\n",
    "        for i in it:\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "                \n",
    "for i in range(len(model_weights_save)):\n",
    "    if i == 0:\n",
    "        Flatten_weights.append(list(flatten(save_weights_epoch[epochs_per_task-2])))\n",
    "        Flatten_weights.append(list(flatten(save_weights_epoch[epochs_per_task-1])))\n",
    "    Flatten_weights.append(list(flatten(model_weights_save[i]))) \n",
    "\n",
    "Extract_model_params = [];\n",
    "#For model parameters without consolidation use val, with consolidation use val+80 \n",
    "for i in range(len(Flatten_weights)):   \n",
    "    Extract_model_params.append(Flatten_weights[i])\n",
    "    \n",
    "gradient_save=[]\n",
    "for i in range(1,len(Extract_model_params)):\n",
    "    if i == 2:\n",
    "        pass\n",
    "    else :\n",
    "        temp=list(np.asarray(Extract_model_params[i])-np.asarray(Extract_model_params[i-1]))\n",
    "        gradient = [j/0.001 for j in temp]\n",
    "        gradient_save.append(gradient)\n",
    "    \n",
    "#Creating the Hessian matrix from the gradients\n",
    "import math\n",
    "Hessian_matrix = []\n",
    "Hessian_row = []\n",
    "Rank_Hessian_matrix = []\n",
    "for k in range(len(gradient_save)):\n",
    "    for i in range(len(gradient_save[k])):\n",
    "        partial_deriv_1 = (math.ceil(gradient_save[k][i]*1e10)/1e10)\n",
    "        for j in range(len(gradient_save[k])):\n",
    "            partial_deriv_2 = (math.ceil(gradient_save[k][j]*1e10)/1e10)\n",
    "            Hessian_row.append(np.around(partial_deriv_1*partial_deriv_2))\n",
    "        Hessian_matrix.append(Hessian_row)\n",
    "        Hessian_row = []\n",
    "    rank_Hessian_matrix = np.linalg.matrix_rank(np.asarray(Hessian_matrix))\n",
    "    Rank_Hessian_matrix.append(rank_Hessian_matrix)\n",
    "    print('Rank of the Hessian Matrix after task=',k,'is :',rank_Hessian_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the Hessian Matrix after task= 0 is : 932\n",
      "Rank of the Hessian Matrix after task= 1 is : 1737\n",
      "Rank of the Hessian Matrix after task= 2 is : 1800\n",
      "Rank of the Hessian Matrix after task= 3 is : 1870\n",
      "Rank of the Hessian Matrix after task= 4 is : 1902\n",
      "Rank of the Hessian Matrix after task= 5 is : 1967\n",
      "Rank of the Hessian Matrix after task= 6 is : 2071\n",
      "Rank of the Hessian Matrix after task= 7 is : 2117\n",
      "Rank of the Hessian Matrix after task= 8 is : 2130\n",
      "Rank of the Hessian Matrix after task= 9 is : 2134\n"
     ]
    }
   ],
   "source": [
    "#Weights Pattern after training each task\n",
    "Flatten_weights=[]\n",
    "#Flattening the weights into a list\n",
    "def flatten(x):\n",
    "    try:\n",
    "        it = iter(x)\n",
    "    except TypeError:\n",
    "        yield x\n",
    "    else:\n",
    "        for i in it:\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "                \n",
    "                \n",
    "for i in range(n_tasks):\n",
    "    Flatten_weights.append(list(flatten(save_weights_epoch[(i+1)*epochs_per_task-2])))\n",
    "    Flatten_weights.append(list(flatten(save_weights_epoch[(i+1)*epochs_per_task-1])))\n",
    "\n",
    "Extract_model_params = [];\n",
    "#For model parameters without consolidation use val, with consolidation use val+80 \n",
    "for i in range(len(Flatten_weights)):   \n",
    "    Extract_model_params.append(Flatten_weights[i])\n",
    "    \n",
    "gradient_save=[]\n",
    "for i in range(1,len(Extract_model_params),2):\n",
    "    temp=list(np.asarray(Extract_model_params[i])-np.asarray(Extract_model_params[i-1]))\n",
    "    \n",
    "    gradient = [j/0.001 for j in temp]\n",
    "    gradient_save.append(gradient)\n",
    "    \n",
    "#Creating the Hessian matrix from the gradients\n",
    "import math\n",
    "Hessian_matrix = []\n",
    "Hessian_row = []\n",
    "Rank_Hessian_matrix = []\n",
    "for k in range(len(gradient_save)):\n",
    "    for i in range(len(gradient_save[k])):\n",
    "        partial_deriv_1 = (math.ceil(gradient_save[k][i]*1e10)/1e10)\n",
    "        for j in range(len(gradient_save[k])):\n",
    "            partial_deriv_2 = (math.ceil(gradient_save[k][j]*1e10)/1e10)\n",
    "            Hessian_row.append(np.around(partial_deriv_1*partial_deriv_2))\n",
    "        Hessian_matrix.append(Hessian_row)\n",
    "        Hessian_row = []\n",
    "    rank_Hessian_matrix = np.linalg.matrix_rank(np.asarray(Hessian_matrix))\n",
    "    Rank_Hessian_matrix.append(rank_Hessian_matrix)\n",
    "    print('Rank of the Hessian Matrix after task=',k,'is :',rank_Hessian_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eucledian Parameter shift after task 1 : 18.42116476268859\n",
      "Eucledian Parameter shift after task 2 : 9.208601450530098\n",
      "Eucledian Parameter shift after task 3 : 3.934590313084037\n",
      "Eucledian Parameter shift after task 4 : 0.7763082720953064\n",
      "Eucledian Parameter shift after task 5 : 2.4158320680373264\n",
      "Eucledian Parameter shift after task 6 : 2.6746329869635184\n",
      "Eucledian Parameter shift after task 7 : 5.5886347410127915\n",
      "Eucledian Parameter shift after task 8 : 3.289132188129787\n",
      "Eucledian Parameter shift after task 9 : 3.2878901208808284\n",
      "Cosine Parameter shift after task 1 : 0.132\n",
      "Cosine Parameter shift after task 2 : 0.891\n",
      "Cosine Parameter shift after task 3 : 0.981\n",
      "Cosine Parameter shift after task 4 : 0.999\n",
      "Cosine Parameter shift after task 5 : 0.993\n",
      "Cosine Parameter shift after task 6 : 0.992\n",
      "Cosine Parameter shift after task 7 : 0.966\n",
      "Cosine Parameter shift after task 8 : 0.989\n",
      "Cosine Parameter shift after task 9 : 0.989\n",
      "Jaccard Parameter shift after task 1 : 0.16968781470292044\n",
      "Jaccard Parameter shift after task 2 : 0.21566579634464753\n",
      "Jaccard Parameter shift after task 3 : 0.16733466933867736\n",
      "Jaccard Parameter shift after task 4 : 0.2149557060969255\n",
      "Jaccard Parameter shift after task 5 : 0.1787158746208291\n",
      "Jaccard Parameter shift after task 6 : 0.16837885241794037\n",
      "Jaccard Parameter shift after task 7 : 0.16396306463688545\n",
      "Jaccard Parameter shift after task 8 : 0.16862941618641944\n",
      "Jaccard Parameter shift after task 9 : 0.19835560123329907\n",
      "Heuristic Parameter shift after task 1 : 0.2911663807890223\n",
      "Heuristic Parameter shift after task 2 : 0.35548885077186965\n",
      "Heuristic Parameter shift after task 3 : 0.2868782161234991\n",
      "Heuristic Parameter shift after task 4 : 0.35377358490566035\n",
      "Heuristic Parameter shift after task 5 : 0.3031732418524871\n",
      "Heuristic Parameter shift after task 6 : 0.2881646655231561\n",
      "Heuristic Parameter shift after task 7 : 0.28173241852487135\n",
      "Heuristic Parameter shift after task 8 : 0.2885934819897084\n",
      "Heuristic Parameter shift after task 9 : 0.33104631217838765\n"
     ]
    }
   ],
   "source": [
    "#Weights Pattern after training each task\n",
    "from math import*\n",
    "#1. Euclidean distance\n",
    "def euclidean_distance(x,y):\n",
    "    return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))\n",
    "#2. Manhattan Distance\n",
    "def manhattan_distance(x,y):\n",
    "    return sum(abs(a-b) for a,b in zip(x,y))\n",
    "#3.  Minkowski distance \n",
    "from decimal import Decimal\n",
    "def nth_root(value, n_root):\n",
    "    root_value = 1/float(n_root)\n",
    "    return round (Decimal(value) ** Decimal(root_value),3)\n",
    "def minkowski_distance(x,y,p_value):\n",
    "    return nth_root(sum(pow(abs(a-b),p_value) for a,b in zip(x, y)),p_value)\n",
    "#4. Cosine Similarity\n",
    "def square_rooted(x):\n",
    "    return round(sqrt(sum([a*a for a in x])),3)\n",
    "def cosine_similarity(x,y):\n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = square_rooted(x)*square_rooted(y)\n",
    "    return round(numerator/float(denominator),3)\n",
    "#5. Jaccard similarity\n",
    "def jaccard_similarity(x,y):\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "#6. Using Heuristic    \n",
    "import difflib \n",
    "\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Eucledian Parameter shift after task {0} :\".format(i+1),euclidean_distance(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Cosine Parameter shift after task {0} :\".format(i+1),cosine_similarity(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Jaccard Parameter shift after task {0} :\".format(i+1),jaccard_similarity(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Heuristic Parameter shift after task {0} :\".format(i+1),difflib.SequenceMatcher(None,Extract_model_params[i],Extract_model_params[i+1]).ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#Counting the number of changed parameters\n",
    "changed_model_parameters=[]\n",
    "for i in range(1,len(Extract_model_params)):\n",
    "    temp=[]\n",
    "    for j,k in zip(Extract_model_params[i],Extract_model_params[i-1]):\n",
    "        temp.append(abs(i-j))\n",
    "    changed_model_parameters.append(temp)\n",
    "print(len(changed_model_parameters))\n",
    "\n",
    "import csv\n",
    "#Save the model parameters in text file\n",
    "with open('temp', 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(Extract_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----After learning 2 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 1\n",
      "0.1 ----> 14\n",
      "-----After learning 3 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 4 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 1\n",
      "-----After learning 5 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 1\n"
     ]
    }
   ],
   "source": [
    "#Number of parameters unchanged within the thresold. Checked for five threshold values as [1e-5, 1e-4, 1e-3, 1e-2, 1e-1].\n",
    "for i in range(len(changed_model_parameters)):\n",
    "    print('-----After learning',i+2,'task-----')\n",
    "    for j in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "        print(j,'---->',sum(k < j for k in changed_model_parameters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the parameters for future use\n",
    "import pickle\n",
    "with open(\"UNSW_Parameters.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(model_weights_save, fp)\n",
    "    \n",
    "with open(\"UNSW_Parameters.txt\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
