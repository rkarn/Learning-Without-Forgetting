{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.chdir('/Users/rupesh.karn/Desktop/WorkPart-1/UNSW-NB15 Dataset')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 5.0)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X and Y  (1000000, 20) (1000000,)\n",
      "Labels length:  21 . They are:  {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20}\n",
      "Datasetset Formatting\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "(670000, 20) (330000, 20) (670000,) (330000,)\n"
     ]
    }
   ],
   "source": [
    "#Type-2\n",
    "np.random.seed(2)\n",
    "x1 = np.random.rand(1000000,1)\n",
    "x2 =3*np.random.rand(1000000,1)\n",
    "x3 = x1+np.random.rand(1000000,1)\n",
    "x4 = 0.5324*x2+np.random.rand(1000000,1)\n",
    "x5 = x4*x3+np.random.rand(1000000,1)\n",
    "x6 = x1+np.random.rand(1000000,1)\n",
    "x7 =2*np.random.rand(1000000,1)\n",
    "x8 = x6+np.random.rand(1000000,1)\n",
    "x9 = 0.5324*x2+np.random.rand(1000000,1)\n",
    "x10 = x8*x2+np.random.rand(1000000,1)\n",
    "x11 = x4+np.random.rand(1000000,1)\n",
    "x12 =8*np.random.rand(1000000,1)\n",
    "x13 = x9*np.random.rand(1000000,1)\n",
    "x14 = 0.824*x12+np.random.rand(1000000,1)\n",
    "x15 = x14*x3+np.random.rand(1000000,1)\n",
    "x16 = x7+np.random.rand(1000000,1)\n",
    "x17 =9*np.random.rand(1000000,1)\n",
    "x18 = x17+np.random.rand(1000000,1)\n",
    "x19 = 0.24*x12+np.random.rand(1000000,1)\n",
    "x20 = x7+x3+np.random.rand(1000000,1)\n",
    "\n",
    "X=np.concatenate((x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20), axis=1)\n",
    "Y=[]\n",
    "label=0\n",
    "for i in range(1000000):\n",
    "    Y.append(label)\n",
    "    if i%50000 == 0:\n",
    "        label=label+1\n",
    "Y = np.array(Y)\n",
    "print ('shape of X and Y ',X.shape,Y.shape)\n",
    "lalbels_length = len(set(Y))\n",
    "print('Labels length: ',lalbels_length,'. They are: ',set(Y))\n",
    "print(\"Datasetset Formatting\")\n",
    "for j in range(0,20):\n",
    "    maximum = max([float(k) for k in X[:,j]]) if  max([float(k) for k in X[:,j]]) != 0 else 1\n",
    "    print(j)\n",
    "    for i in range(0,len(X)):\n",
    "        X[i,j] = round(float(X[i,j])/maximum,3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train_all_attacks, Y_test_all_attacks = train_test_split(X, Y, test_size=0.33)\n",
    "print (X_train.shape,X_test.shape,Y_train_all_attacks.shape,Y_test_all_attacks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['average', 'maximum', 'select']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "graph_replace = tf.contrib.graph_editor.graph_replace\n",
    "\n",
    "import sys, os\n",
    "sys.path.extend([os.path.expanduser('..')])\n",
    "from pathint import utils\n",
    "import seaborn as sns\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "\n",
    "# import operator\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['ps.fonttype'] = 42\n",
    "\n",
    "select = tf.select if hasattr(tf, 'select') else tf.where"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data params\n",
    "input_dim = 20\n",
    "output_dim = lalbels_length\n",
    "\n",
    "# Network params\n",
    "n_hidden_units = 41\n",
    "activation_fn = tf.nn.relu\n",
    "\n",
    "# Optimization params\n",
    "batch_size = 64\n",
    "epochs_per_task = 10\n",
    "\n",
    "n_stats = 1\n",
    "\n",
    "# Reset optimizer after each age\n",
    "reset_optimizer = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "#task_labels = [[0,1],[2,3],[4,5],[6,7],[8,9],[10,11],[12,13],[14,15],[16,17],[18,19],[20,21],[22,23],[24,25],[26,27],[28,29],[30,31],[32,33],[34,35],[36,37],[38,39]]\n",
    "#nb_classes  = 40\n",
    "task_labels = [[0,1],[2,3],[4,5],[6,7],[8,9],[10,11],[12,13],[14,15],[16,17],[18,19],[20,1]]\n",
    "nb_classes  = lalbels_length\n",
    "#task_labels = [[8,9], [6,7], [4,5], [2,3], [0,1]]\n",
    "#task_labels = [[0,9], [7,8], [3,6], [1,4], [2,5]]\n",
    "#task_labels = [[0,1,2], [3,4,5], [6,7,8,9]]\n",
    "#task_labels = [[1,5,8],[2,5,7,9],[3,4,6]]\n",
    "#task_labels = [[0,1], [2,3], [4,5], [6,7], [8,9],[1,5],[0,9],[3,8],[0,6],[4,2],[3,5],[0,4],[9,6],[1,2]]\n",
    "n_tasks = len(task_labels)\n",
    "training_datasets = []\n",
    "validation_datasets = []\n",
    "multihead=False\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_train_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = X_train[idx], np_utils.to_categorical(label_map[Y_train_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        data = X_train[idx], np_utils.to_categorical(Y_train_all_attacks[idx], nb_classes)\n",
    "        training_datasets.append(data)\n",
    "\n",
    "for labels in task_labels:\n",
    "    idx = np.in1d(Y_test_all_attacks, labels)\n",
    "    if multihead:\n",
    "        label_map = np.arange(nb_classes)\n",
    "        label_map[labels] = np.arange(len(labels))\n",
    "        data = X_test[idx], np_utils.to_categorical(label_map[Y_test_all_attacks[idx]], len(labels))\n",
    "    else:\n",
    "        data = X_test[idx], np_utils.to_categorical(Y_test_all_attacks[idx], nb_classes)\n",
    "        validation_datasets.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: 0 (33239, 20) (33239, 21) (16762, 20) (16762, 21)\n",
      "Task: 1 (67249, 20) (67249, 21) (32751, 20) (32751, 21)\n",
      "Task: 2 (66959, 20) (66959, 21) (33041, 20) (33041, 21)\n",
      "Task: 3 (66918, 20) (66918, 21) (33082, 20) (33082, 21)\n",
      "Task: 4 (66833, 20) (66833, 21) (33167, 20) (33167, 21)\n",
      "Task: 5 (67115, 20) (67115, 21) (32885, 20) (32885, 21)\n",
      "Task: 6 (66937, 20) (66937, 21) (33063, 20) (33063, 21)\n",
      "Task: 7 (67243, 20) (67243, 21) (32757, 20) (32757, 21)\n",
      "Task: 8 (67169, 20) (67169, 21) (32831, 20) (32831, 21)\n",
      "Task: 9 (66918, 20) (66918, 21) (33082, 20) (33082, 21)\n",
      "Task: 10 (66658, 20) (66658, 21) (33341, 20) (33341, 21)\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_tasks):\n",
    "    print('Task:',i,training_datasets[i][0].shape,training_datasets[i][1].shape,validation_datasets[i][0].shape,validation_datasets[i][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "import keras.backend as K\n",
    "import keras.activations as activations\n",
    "\n",
    "output_mask = tf.Variable(tf.zeros(output_dim), name=\"mask\", trainable=False)\n",
    "\n",
    "def masked_softmax(logits):\n",
    "    # logits are [batch_size, output_dim]\n",
    "    x = select(tf.tile(tf.equal(output_mask[None, :], 1.0), [tf.shape(logits)[0], 1]), logits, -1e32 * tf.ones_like(logits))\n",
    "    return activations.softmax(x)\n",
    "\n",
    "def set_active_outputs(labels):\n",
    "    new_mask = np.zeros(output_dim)\n",
    "    for l in labels:\n",
    "        new_mask[l] = 1.0\n",
    "    sess.run(output_mask.assign(new_mask))\n",
    "    #print(sess.run(output_mask))\n",
    "    \n",
    "def masked_predict(model, data, targets):\n",
    "    pred = model.predict(data)\n",
    "    #print(pred)\n",
    "    acc = np.argmax(pred,1)==np.argmax(targets,1)\n",
    "    return acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn, input_shape=(input_dim,)))\n",
    "#model.add(Dense(n_hidden_units, kernel_initializer='random_uniform', activation=activation_fn))\n",
    "#model.add(Dense(n_hidden_units, activation=activation_fn))\n",
    "model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax))\n",
    "#model.add(Dense(output_dim, kernel_initializer='random_uniform', activation=masked_softmax, input_shape=(input_dim,)))\n",
    "\n",
    "from pathint import protocols\n",
    "from pathint.optimizers import KOOptimizer\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.callbacks import Callback\n",
    "from pathint.keras_utils import LossHistory\n",
    "\n",
    "#protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "protocol_name, protocol = protocols.PATH_INT_PROTOCOL(omega_decay='sum',xi=1e-3)\n",
    "#protocol_name, protocol = protocols.FISHER_PROTOCOL('sum')\n",
    "opt = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)\n",
    "#opt = SGD(1e-3)\n",
    "#opt = RMSprop(lr=1e-3)\n",
    "oopt = KOOptimizer(opt, model=model, **protocol)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=oopt, metrics=['accuracy'])\n",
    "model.model._make_train_function()\n",
    "saved_weights = model.get_weights()\n",
    "\n",
    "history = LossHistory()\n",
    "callbacks = [history]\n",
    "datafile_name = \"split_mnist_data_%s.pkl.gz\"%protocol_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regularizer_fn': <function quadratic_regularizer at 0x7fb262bcd1e0>, 'init_updates': [('cweights', <function <lambda>.<locals>.<lambda> at 0x7fb26c6e6620>)], 'step_updates': [('grads2', <function <lambda>.<locals>.<lambda> at 0x7fb26c7fd8c8>)], 'task_updates': [('omega', <function <lambda>.<locals>.<lambda> at 0x7fb2406fe158>), ('cweights', <function <lambda>.<locals>.<lambda> at 0x7fb2406feae8>), ('grads2', <function <lambda>.<locals>.<lambda> at 0x7fb2406fe9d8>)]}\n"
     ]
    }
   ],
   "source": [
    "print(protocol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fits(cvals, training_data, valid_data, eval_on_train_set=False, nstats=1):\n",
    "    acc_mean = dict()\n",
    "    acc_std = dict()\n",
    "    model_weights_save = []   #Empty list to save the model weights aftertraining each task\n",
    "    #model_weights_save.append(model.get_weights())\n",
    "    for cidx, cval_ in enumerate(tqdm(cvals)):\n",
    "        runs = []\n",
    "        for runid in range(nstats):\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            # model.set_weights(saved_weights)\n",
    "            cstuffs = []\n",
    "            evals = []\n",
    "            print(\"setting cval\")\n",
    "            cval = cval_\n",
    "            oopt.set_strength(cval)\n",
    "            oopt.init_task_vars()\n",
    "            print(\"cval is\", sess.run(oopt.lam))\n",
    "            for age, tidx in enumerate(range(n_tasks)):\n",
    "                print(\"Age %i, cval is=%f\"%(age,cval))\n",
    "                print(\"settint output mask\")\n",
    "                set_active_outputs(task_labels[age])\n",
    "                stuffs = model.fit(training_data[tidx][0], training_data[tidx][1], batch_size, epochs_per_task, callbacks=callbacks)\n",
    "                oopt.update_task_metrics(training_data[tidx][0], training_data[tidx][1], batch_size)\n",
    "                oopt.update_task_vars()\n",
    "                ftask = []\n",
    "                model_weights_save.append(model.get_weights()) #Save the model weights aftertraining each task\n",
    "                for j in range(n_tasks):\n",
    "                    set_active_outputs(task_labels[j])\n",
    "                    if eval_on_train_set:\n",
    "                        f_ = masked_predict(model, training_data[j][0], training_data[j][1])\n",
    "                    else:\n",
    "                        f_ = masked_predict(model, valid_data[j][0], valid_data[j][1])\n",
    "                    ftask.append(np.mean(f_))\n",
    "                evals.append(ftask)\n",
    "                cstuffs.append(stuffs)\n",
    "\n",
    "                # Re-initialize optimizater variables\n",
    "                if reset_optimizer:\n",
    "                    oopt.reset_optimizer()\n",
    "\n",
    "            evals = np.array(evals)\n",
    "            runs.append(evals)\n",
    "        \n",
    "        runs = np.array(runs)\n",
    "        acc_mean[cval_] = runs.mean(0)\n",
    "        acc_std[cval_] = runs.std(0)\n",
    "    return dict(mean=acc_mean, std=acc_std),model_weights_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# cvals = np.concatenate(([0], np.logspace(-2, 2, 10)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-1, 2, 2)))\n",
    "# cvals = np.concatenate(([0], np.logspace(-2, 0, 3)))\n",
    "#cvals = np.logspace(-3, 3, 7)#[0, 1.0, 2, 5, 10]\n",
    "cvals = [0, 1.0]\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cval\n",
      "cval is 0.0\n",
      "Age 0, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "33239/33239 [==============================] - 1s - loss: 0.0539 - acc: 0.9997     \n",
      "Epoch 2/10\n",
      "33239/33239 [==============================] - 0s - loss: 8.6208e-04 - acc: 1.0000     \n",
      "Epoch 3/10\n",
      "33239/33239 [==============================] - 0s - loss: 5.6915e-04 - acc: 1.0000     \n",
      "Epoch 4/10\n",
      "33239/33239 [==============================] - 0s - loss: 5.0355e-04 - acc: 1.0000     \n",
      "Epoch 5/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.8586e-04 - acc: 1.0000     \n",
      "Epoch 6/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.7692e-04 - acc: 1.0000     \n",
      "Epoch 7/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.7303e-04 - acc: 1.0000     \n",
      "Epoch 8/10\n",
      "33239/33239 [==============================] - 1s - loss: 4.7007e-04 - acc: 1.0000     \n",
      "Epoch 9/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.6879e-04 - acc: 1.0000     \n",
      "Epoch 10/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.6115e-04 - acc: 1.0000     \n",
      "Age 1, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "67249/67249 [==============================] - 2s - loss: 0.6944 - acc: 0.4997     \n",
      "Epoch 2/10\n",
      "67249/67249 [==============================] - 2s - loss: 0.6936 - acc: 0.4964     \n",
      "Epoch 3/10\n",
      "67249/67249 [==============================] - 2s - loss: 0.6933 - acc: 0.5012     \n",
      "Epoch 4/10\n",
      "67249/67249 [==============================] - 2s - loss: 0.6933 - acc: 0.5002     \n",
      "Epoch 5/10\n",
      "67249/67249 [==============================] - 2s - loss: 0.6933 - acc: 0.4995     \n",
      "Epoch 6/10\n",
      "67249/67249 [==============================] - 2s - loss: 0.6932 - acc: 0.5034     \n",
      "Epoch 7/10\n",
      "67249/67249 [==============================] - 2s - loss: 0.6932 - acc: 0.5014     \n",
      "Epoch 8/10\n",
      "67249/67249 [==============================] - 2s - loss: 0.6932 - acc: 0.5015     \n",
      "Epoch 9/10\n",
      "67249/67249 [==============================] - 2s - loss: 0.6932 - acc: 0.4978     \n",
      "Epoch 10/10\n",
      "67249/67249 [==============================] - 2s - loss: 0.6932 - acc: 0.4989     \n",
      "Age 2, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6932 - acc: 0.4999     \n",
      "Epoch 2/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6932 - acc: 0.4995     \n",
      "Epoch 3/10\n",
      "66959/66959 [==============================] - 2s - loss: 0.6932 - acc: 0.4999     \n",
      "Epoch 4/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6932 - acc: 0.5024     \n",
      "Epoch 5/10\n",
      "66959/66959 [==============================] - 2s - loss: 0.6932 - acc: 0.4976     \n",
      "Epoch 6/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6932 - acc: 0.5012     \n",
      "Epoch 7/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6932 - acc: 0.5018     \n",
      "Epoch 8/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6932 - acc: 0.4983     \n",
      "Epoch 9/10\n",
      "66959/66959 [==============================] - 2s - loss: 0.6932 - acc: 0.5011     \n",
      "Epoch 10/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6932 - acc: 0.4985     \n",
      "Age 3, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.5019     \n",
      "Epoch 2/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.5023     \n",
      "Epoch 3/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.5019     \n",
      "Epoch 4/10\n",
      "66918/66918 [==============================] - 2s - loss: 0.6932 - acc: 0.5000     \n",
      "Epoch 5/10\n",
      "66918/66918 [==============================] - 2s - loss: 0.6932 - acc: 0.5012     \n",
      "Epoch 6/10\n",
      "66918/66918 [==============================] - 2s - loss: 0.6932 - acc: 0.4986     \n",
      "Epoch 7/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.5002     \n",
      "Epoch 8/10\n",
      "66918/66918 [==============================] - 2s - loss: 0.6932 - acc: 0.5000     \n",
      "Epoch 9/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.4999     \n",
      "Epoch 10/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.4996     \n",
      "Age 4, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66833/66833 [==============================] - 1s - loss: 0.6933 - acc: 0.4962     \n",
      "Epoch 2/10\n",
      "66833/66833 [==============================] - 1s - loss: 0.6932 - acc: 0.4983     \n",
      "Epoch 3/10\n",
      "66833/66833 [==============================] - 1s - loss: 0.6932 - acc: 0.4988     \n",
      "Epoch 4/10\n",
      "66833/66833 [==============================] - 1s - loss: 0.6932 - acc: 0.5021     \n",
      "Epoch 5/10\n",
      "66833/66833 [==============================] - 1s - loss: 0.6932 - acc: 0.4966     \n",
      "Epoch 6/10\n",
      "66833/66833 [==============================] - 1s - loss: 0.6932 - acc: 0.4952     \n",
      "Epoch 7/10\n",
      "66833/66833 [==============================] - 1s - loss: 0.6932 - acc: 0.5019     \n",
      "Epoch 8/10\n",
      "66833/66833 [==============================] - 2s - loss: 0.6932 - acc: 0.4990     \n",
      "Epoch 9/10\n",
      "66833/66833 [==============================] - 1s - loss: 0.6932 - acc: 0.4994     \n",
      "Epoch 10/10\n",
      "66833/66833 [==============================] - 1s - loss: 0.6932 - acc: 0.4996     \n",
      "Age 5, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6933 - acc: 0.4987     \n",
      "Epoch 2/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6932 - acc: 0.4989     \n",
      "Epoch 3/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6932 - acc: 0.4991     \n",
      "Epoch 4/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6932 - acc: 0.4990     \n",
      "Epoch 5/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6932 - acc: 0.5015     \n",
      "Epoch 6/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6932 - acc: 0.4985     \n",
      "Epoch 7/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6932 - acc: 0.4961     \n",
      "Epoch 8/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6932 - acc: 0.4993     \n",
      "Epoch 9/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6932 - acc: 0.5001     \n",
      "Epoch 10/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6932 - acc: 0.4973     \n",
      "Age 6, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6932 - acc: 0.4969     \n",
      "Epoch 2/10\n",
      "66937/66937 [==============================] - 2s - loss: 0.6932 - acc: 0.4973     \n",
      "Epoch 3/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6932 - acc: 0.5004     \n",
      "Epoch 4/10\n",
      "66937/66937 [==============================] - 2s - loss: 0.6932 - acc: 0.4989     \n",
      "Epoch 5/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6932 - acc: 0.4989     \n",
      "Epoch 6/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6932 - acc: 0.4984     \n",
      "Epoch 7/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6932 - acc: 0.5004     \n",
      "Epoch 8/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6932 - acc: 0.4983     \n",
      "Epoch 9/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6932 - acc: 0.4975     \n",
      "Epoch 10/10\n",
      "66937/66937 [==============================] - 2s - loss: 0.6932 - acc: 0.4973     \n",
      "Age 7, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6932 - acc: 0.4972     \n",
      "Epoch 2/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6932 - acc: 0.4998     \n",
      "Epoch 3/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6932 - acc: 0.5005     \n",
      "Epoch 4/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6932 - acc: 0.5007     \n",
      "Epoch 5/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6932 - acc: 0.5015     \n",
      "Epoch 6/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6932 - acc: 0.4994     \n",
      "Epoch 7/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6932 - acc: 0.4983     \n",
      "Epoch 8/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6932 - acc: 0.4958     \n",
      "Epoch 9/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6932 - acc: 0.4963     \n",
      "Epoch 10/10\n",
      "67243/67243 [==============================] - 1s - loss: 0.6932 - acc: 0.5015     \n",
      "Age 8, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "67169/67169 [==============================] - 2s - loss: 0.6932 - acc: 0.5006     \n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67169/67169 [==============================] - 1s - loss: 0.6932 - acc: 0.4945     \n",
      "Epoch 3/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6932 - acc: 0.5011     \n",
      "Epoch 4/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6932 - acc: 0.5005     \n",
      "Epoch 5/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6932 - acc: 0.4984     \n",
      "Epoch 6/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6932 - acc: 0.4961     \n",
      "Epoch 7/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6932 - acc: 0.5001     \n",
      "Epoch 8/10\n",
      "67169/67169 [==============================] - 2s - loss: 0.6932 - acc: 0.4994     \n",
      "Epoch 9/10\n",
      "67169/67169 [==============================] - 2s - loss: 0.6932 - acc: 0.5009     \n",
      "Epoch 10/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6932 - acc: 0.4992     \n",
      "Age 9, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.5011     \n",
      "Epoch 2/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.4973     \n",
      "Epoch 3/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.5012     \n",
      "Epoch 4/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.5003     \n",
      "Epoch 5/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.4982     \n",
      "Epoch 6/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.4993     \n",
      "Epoch 7/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.5021     \n",
      "Epoch 8/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.4984     \n",
      "Epoch 9/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.4997     \n",
      "Epoch 10/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6932 - acc: 0.4995     \n",
      "Age 10, cval is=0.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6933 - acc: 0.4976     \n",
      "Epoch 2/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6932 - acc: 0.4981     \n",
      "Epoch 3/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6932 - acc: 0.5007     \n",
      "Epoch 4/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6932 - acc: 0.4967     \n",
      "Epoch 5/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6932 - acc: 0.5007     \n",
      "Epoch 6/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6932 - acc: 0.5029     \n",
      "Epoch 7/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6932 - acc: 0.4997     \n",
      "Epoch 8/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6932 - acc: 0.4984     \n",
      "Epoch 9/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6932 - acc: 0.5002     \n",
      "Epoch 10/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6932 - acc: 0.5005     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 1/2 [04:21<04:21, 261.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting cval\n",
      "cval is 1.0\n",
      "Age 0, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "33239/33239 [==============================] - 0s - loss: 0.0565 - acc: 0.9996     \n",
      "Epoch 2/10\n",
      "33239/33239 [==============================] - 0s - loss: 9.4500e-04 - acc: 1.0000     \n",
      "Epoch 3/10\n",
      "33239/33239 [==============================] - 0s - loss: 6.0286e-04 - acc: 1.0000     \n",
      "Epoch 4/10\n",
      "33239/33239 [==============================] - 0s - loss: 5.1563e-04 - acc: 1.0000     \n",
      "Epoch 5/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.8830e-04 - acc: 1.0000     \n",
      "Epoch 6/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.7666e-04 - acc: 1.0000     \n",
      "Epoch 7/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.6624e-04 - acc: 1.0000     \n",
      "Epoch 8/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.6886e-04 - acc: 1.0000     \n",
      "Epoch 9/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.6458e-04 - acc: 1.0000     \n",
      "Epoch 10/10\n",
      "33239/33239 [==============================] - 0s - loss: 4.5517e-04 - acc: 1.0000     \n",
      "Age 1, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "67249/67249 [==============================] - 1s - loss: 0.6951 - acc: 0.5016     \n",
      "Epoch 2/10\n",
      "67249/67249 [==============================] - 1s - loss: 0.6942 - acc: 0.5015     \n",
      "Epoch 3/10\n",
      "67249/67249 [==============================] - 1s - loss: 0.6945 - acc: 0.5002     \n",
      "Epoch 4/10\n",
      "67249/67249 [==============================] - 1s - loss: 0.6941 - acc: 0.4981     \n",
      "Epoch 5/10\n",
      "67249/67249 [==============================] - 1s - loss: 0.6941 - acc: 0.5007     \n",
      "Epoch 6/10\n",
      "67249/67249 [==============================] - 1s - loss: 0.6943 - acc: 0.4972     \n",
      "Epoch 7/10\n",
      "67249/67249 [==============================] - 1s - loss: 0.6941 - acc: 0.4974     \n",
      "Epoch 8/10\n",
      "67249/67249 [==============================] - 1s - loss: 0.6942 - acc: 0.5000     \n",
      "Epoch 9/10\n",
      "67249/67249 [==============================] - 1s - loss: 0.6942 - acc: 0.4999     \n",
      "Epoch 10/10\n",
      "67249/67249 [==============================] - 1s - loss: 0.6941 - acc: 0.5000     \n",
      "Age 2, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6949 - acc: 0.4997     \n",
      "Epoch 2/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6941 - acc: 0.5018     \n",
      "Epoch 3/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6944 - acc: 0.4992     \n",
      "Epoch 4/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6944 - acc: 0.5007     \n",
      "Epoch 5/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6941 - acc: 0.4998     \n",
      "Epoch 6/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6940 - acc: 0.5034     \n",
      "Epoch 7/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6943 - acc: 0.5014     \n",
      "Epoch 8/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6942 - acc: 0.4999     \n",
      "Epoch 9/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6940 - acc: 0.5012     \n",
      "Epoch 10/10\n",
      "66959/66959 [==============================] - 1s - loss: 0.6939 - acc: 0.5022     \n",
      "Age 3, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6947 - acc: 0.5005     \n",
      "Epoch 2/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6943 - acc: 0.5011     \n",
      "Epoch 3/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6941 - acc: 0.5018     \n",
      "Epoch 4/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6940 - acc: 0.4997     \n",
      "Epoch 5/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6939 - acc: 0.5031     \n",
      "Epoch 6/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6940 - acc: 0.4983     \n",
      "Epoch 7/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6943 - acc: 0.4993     \n",
      "Epoch 8/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6942 - acc: 0.4973     \n",
      "Epoch 9/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6943 - acc: 0.4951     \n",
      "Epoch 10/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6941 - acc: 0.5007     \n",
      "Age 4, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66833/66833 [==============================] - 2s - loss: 0.6951 - acc: 0.4982     \n",
      "Epoch 2/10\n",
      "66833/66833 [==============================] - 2s - loss: 0.6942 - acc: 0.4980     \n",
      "Epoch 3/10\n",
      "66833/66833 [==============================] - 2s - loss: 0.6941 - acc: 0.4989     \n",
      "Epoch 4/10\n",
      "66833/66833 [==============================] - 2s - loss: 0.6942 - acc: 0.4981     \n",
      "Epoch 5/10\n",
      "66833/66833 [==============================] - 2s - loss: 0.6943 - acc: 0.4966     \n",
      "Epoch 6/10\n",
      "66833/66833 [==============================] - 2s - loss: 0.6943 - acc: 0.4992     \n",
      "Epoch 7/10\n",
      "66833/66833 [==============================] - 2s - loss: 0.6940 - acc: 0.5004     \n",
      "Epoch 8/10\n",
      "66833/66833 [==============================] - 1s - loss: 0.6941 - acc: 0.4996     \n",
      "Epoch 9/10\n",
      "66833/66833 [==============================] - 2s - loss: 0.6942 - acc: 0.4987     \n",
      "Epoch 10/10\n",
      "66833/66833 [==============================] - 2s - loss: 0.6942 - acc: 0.5028     \n",
      "Age 5, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6953 - acc: 0.4997     \n",
      "Epoch 2/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6944 - acc: 0.4995     \n",
      "Epoch 3/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6941 - acc: 0.5005     \n",
      "Epoch 4/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6942 - acc: 0.4986     \n",
      "Epoch 5/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6941 - acc: 0.4973     \n",
      "Epoch 6/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6940 - acc: 0.5010     \n",
      "Epoch 7/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6944 - acc: 0.4982     \n",
      "Epoch 8/10\n",
      "67115/67115 [==============================] - 1s - loss: 0.6941 - acc: 0.5008     \n",
      "Epoch 9/10\n",
      "67115/67115 [==============================] - 2s - loss: 0.6942 - acc: 0.5002     \n",
      "Epoch 10/10\n",
      "67115/67115 [==============================] - 1s - loss: 0.6939 - acc: 0.5013     \n",
      "Age 6, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6952 - acc: 0.4990     \n",
      "Epoch 2/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6940 - acc: 0.4992     \n",
      "Epoch 3/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6944 - acc: 0.4985     \n",
      "Epoch 4/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6941 - acc: 0.4997     \n",
      "Epoch 5/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6941 - acc: 0.4995     \n",
      "Epoch 6/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6944 - acc: 0.4984     \n",
      "Epoch 7/10\n",
      "66937/66937 [==============================] - 2s - loss: 0.6941 - acc: 0.4988     \n",
      "Epoch 8/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6941 - acc: 0.5006     \n",
      "Epoch 9/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6940 - acc: 0.5008     \n",
      "Epoch 10/10\n",
      "66937/66937 [==============================] - 1s - loss: 0.6942 - acc: 0.5020     \n",
      "Age 7, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "67243/67243 [==============================] - 1s - loss: 0.6955 - acc: 0.4990     \n",
      "Epoch 2/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6943 - acc: 0.4987     \n",
      "Epoch 3/10\n",
      "67243/67243 [==============================] - 1s - loss: 0.6942 - acc: 0.4991     \n",
      "Epoch 4/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6938 - acc: 0.5006     \n",
      "Epoch 5/10\n",
      "67243/67243 [==============================] - 1s - loss: 0.6942 - acc: 0.5024     \n",
      "Epoch 6/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6941 - acc: 0.5019     \n",
      "Epoch 7/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6943 - acc: 0.4981     \n",
      "Epoch 8/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6940 - acc: 0.5015     \n",
      "Epoch 9/10\n",
      "67243/67243 [==============================] - 1s - loss: 0.6940 - acc: 0.5019     \n",
      "Epoch 10/10\n",
      "67243/67243 [==============================] - 2s - loss: 0.6941 - acc: 0.5007     \n",
      "Age 8, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "67169/67169 [==============================] - 2s - loss: 0.6950 - acc: 0.4984     \n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67169/67169 [==============================] - 2s - loss: 0.6942 - acc: 0.5004     \n",
      "Epoch 3/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6944 - acc: 0.4981     \n",
      "Epoch 4/10\n",
      "67169/67169 [==============================] - 2s - loss: 0.6939 - acc: 0.5022     \n",
      "Epoch 5/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6943 - acc: 0.4971     \n",
      "Epoch 6/10\n",
      "67169/67169 [==============================] - 2s - loss: 0.6939 - acc: 0.4984     \n",
      "Epoch 7/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6940 - acc: 0.4999     \n",
      "Epoch 8/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6942 - acc: 0.5002     \n",
      "Epoch 9/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6943 - acc: 0.4998     \n",
      "Epoch 10/10\n",
      "67169/67169 [==============================] - 1s - loss: 0.6940 - acc: 0.5019     \n",
      "Age 9, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6951 - acc: 0.4996     \n",
      "Epoch 2/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6942 - acc: 0.5012     \n",
      "Epoch 3/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6942 - acc: 0.4986     \n",
      "Epoch 4/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6941 - acc: 0.4985     \n",
      "Epoch 5/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6941 - acc: 0.5009     \n",
      "Epoch 6/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6942 - acc: 0.5014     \n",
      "Epoch 7/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6940 - acc: 0.4988     \n",
      "Epoch 8/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6941 - acc: 0.5005     \n",
      "Epoch 9/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6941 - acc: 0.4974     \n",
      "Epoch 10/10\n",
      "66918/66918 [==============================] - 1s - loss: 0.6941 - acc: 0.5016     \n",
      "Age 10, cval is=1.000000\n",
      "settint output mask\n",
      "Epoch 1/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.7130 - acc: 0.4984     \n",
      "Epoch 2/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6943 - acc: 0.5006     \n",
      "Epoch 3/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6942 - acc: 0.5016     \n",
      "Epoch 4/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6942 - acc: 0.5053     \n",
      "Epoch 5/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6941 - acc: 0.5001     \n",
      "Epoch 6/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6940 - acc: 0.5021     \n",
      "Epoch 7/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6940 - acc: 0.4992     \n",
      "Epoch 8/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6943 - acc: 0.4997     \n",
      "Epoch 9/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6942 - acc: 0.4997     \n",
      "Epoch 10/10\n",
      "66658/66658 [==============================] - 1s - loss: 0.6942 - acc: 0.4983     \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [08:43<00:00, 261.71s/it]\n"
     ]
    }
   ],
   "source": [
    "#%%capture\n",
    "\n",
    "recompute_data = True\n",
    "\n",
    "if recompute_data:\n",
    "    data,model_weights_save = run_fits(cvals, training_datasets, validation_datasets, eval_on_train_set=False, nstats=n_stats)\n",
    "    utils.save_zipped_pickle(data, datafile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 41)                861       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 21)                882       \n",
      "=================================================================\n",
      "Total params: 1,743\n",
      "Trainable params: 1,743\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(20, 41)\n",
      "(41,)\n",
      "(41, 21)\n",
      "(21,)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "print(model.summary())\n",
    "model.save_weights('saved_weights.h5') #This file cannot be opend normaly to view the weghts. It can be loaded through load_model() or can be opend via hdf5 viewer\n",
    "\n",
    "#Shape of the array containg model weights\n",
    "a_list = model.get_weights()\n",
    "for i in range(len(a_list)):\n",
    "    print((np.array(a_list[i])).shape)\n",
    "\n",
    "#a_list[0][0][0] = a_list[0][0][0]+0.00001\n",
    "#print(a_list[0][0][0])\n",
    "#model.set_weights(a_list)\n",
    "\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#import pydot\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "data = utils.load_zipped_pickle(datafile_name)\n",
    "print(cvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: array([[0.53809524, 0.30994152, 0.51470588, 0.61083744, 0.56118143,\n",
      "        0.52439024, 0.48358209, 0.60721757, 0.70200108, 0.35001296,\n",
      "        0.53306746],\n",
      "       [0.53809524, 0.53216374, 0.51470588, 0.61083744, 0.56118143,\n",
      "        0.52439024, 0.48358209, 0.60721757, 0.70200108, 0.35001296,\n",
      "        0.53306746],\n",
      "       [0.53809524, 0.53216374, 0.5       , 0.61083744, 0.56118143,\n",
      "        0.52439024, 0.48358209, 0.60721757, 0.70200108, 0.35001296,\n",
      "        0.53306746],\n",
      "       [0.53809524, 0.53216374, 0.5       , 0.46059113, 0.56118143,\n",
      "        0.52439024, 0.48358209, 0.60721757, 0.70200108, 0.35001296,\n",
      "        0.53306746],\n",
      "       [0.53809524, 0.53216374, 0.5       , 0.46059113, 0.46413502,\n",
      "        0.52439024, 0.48358209, 0.60721757, 0.70200108, 0.35001296,\n",
      "        0.53306746],\n",
      "       [0.53809524, 0.53216374, 0.5       , 0.46059113, 0.46413502,\n",
      "        0.68902439, 0.48358209, 0.60721757, 0.70200108, 0.35001296,\n",
      "        0.53306746],\n",
      "       [0.53809524, 0.53216374, 0.5       , 0.46059113, 0.46413502,\n",
      "        0.68902439, 0.53134328, 0.60721757, 0.70200108, 0.35001296,\n",
      "        0.53306746],\n",
      "       [0.53809524, 0.53216374, 0.5       , 0.46059113, 0.46413502,\n",
      "        0.68902439, 0.53134328, 0.51202929, 0.70200108, 0.35001296,\n",
      "        0.53306746],\n",
      "       [0.53809524, 0.53216374, 0.5       , 0.46059113, 0.46413502,\n",
      "        0.68902439, 0.53134328, 0.51202929, 0.61546782, 0.35001296,\n",
      "        0.53306746],\n",
      "       [0.53809524, 0.53216374, 0.5       , 0.46059113, 0.46413502,\n",
      "        0.68902439, 0.53134328, 0.51202929, 0.61546782, 0.57376199,\n",
      "        0.53306746],\n",
      "       [0.53809524, 0.53216374, 0.5       , 0.46059113, 0.46413502,\n",
      "        0.68902439, 0.53134328, 0.51202929, 0.61546782, 0.57376199,\n",
      "        0.92705218]]), 1.0: array([[0.5       , 0.56140351, 0.53431373, 0.57389163, 0.45991561,\n",
      "        0.30335366, 0.3880597 , 0.39748954, 0.39588967, 0.75732435,\n",
      "        0.62470921],\n",
      "       [0.5       , 0.60233918, 0.53431373, 0.57389163, 0.45991561,\n",
      "        0.30335366, 0.3880597 , 0.39748954, 0.39588967, 0.75732435,\n",
      "        0.62470921],\n",
      "       [0.5       , 0.60233918, 0.52941176, 0.57389163, 0.45991561,\n",
      "        0.30335366, 0.3880597 , 0.39748954, 0.39588967, 0.75732435,\n",
      "        0.62470921],\n",
      "       [0.5       , 0.60233918, 0.52941176, 0.53448276, 0.45991561,\n",
      "        0.30335366, 0.3880597 , 0.39748954, 0.39588967, 0.75732435,\n",
      "        0.62470921],\n",
      "       [0.5       , 0.60233918, 0.52941176, 0.53448276, 0.47257384,\n",
      "        0.30335366, 0.3880597 , 0.39748954, 0.39588967, 0.75732435,\n",
      "        0.62470921],\n",
      "       [0.5       , 0.60233918, 0.52941176, 0.53448276, 0.47257384,\n",
      "        0.45731707, 0.3880597 , 0.39748954, 0.39588967, 0.75732435,\n",
      "        0.62470921],\n",
      "       [0.5       , 0.60233918, 0.52941176, 0.53448276, 0.47257384,\n",
      "        0.45731707, 0.54129353, 0.39748954, 0.39588967, 0.75732435,\n",
      "        0.62470921],\n",
      "       [0.5       , 0.60233918, 0.52941176, 0.53448276, 0.47257384,\n",
      "        0.45731707, 0.54129353, 0.46705021, 0.39588967, 0.75732435,\n",
      "        0.62470921],\n",
      "       [0.5       , 0.60233918, 0.52941176, 0.53448276, 0.47257384,\n",
      "        0.45731707, 0.54129353, 0.46705021, 0.64034613, 0.75732435,\n",
      "        0.62470921],\n",
      "       [0.5       , 0.60233918, 0.52941176, 0.53448276, 0.47257384,\n",
      "        0.45731707, 0.54129353, 0.46705021, 0.64034613, 0.591133  ,\n",
      "        0.62470921],\n",
      "       [0.5       , 0.60233918, 0.52941176, 0.53448276, 0.47257384,\n",
      "        0.45731707, 0.54129353, 0.46705021, 0.64034613, 0.591133  ,\n",
      "        0.92696909]])}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "print(data['mean'])\n",
    "for k in cvals:\n",
    "    for i in range(n_tasks):\n",
    "        for j in range(i):\n",
    "            data['mean'][k][j][i] = 0\n",
    "            data['std'][k][j][i] = 0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-5.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.colors as colors\n",
    "cmap = plt.get_cmap('cool') \n",
    "cNorm  = colors.Normalize(vmin=-5, vmax=np.log(np.max(list(data['mean'].keys()))))\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "print(scalarMap.get_clim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:13: RuntimeWarning: divide by zero encountered in log\n",
      "  del sys.path[0]\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n",
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANAAAAUyCAYAAAB/EHpaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3X9QVGeeP/o3IE270DbOyhrcJbITNjH+6AXEVUAcQf1mFhe/OKUrP9KDN0wMzCxgrZfNTY27+i0QtkbKKtQUWA4r0FUhSO2iWDHMTsgMIXIR40JiWxAxm+zIOKAXYWgEtRue+wehRxAB5+k+fWzer6ouus+h+/N0ct6eQ/c5n8dDCCFARH8UT1cPgOh5xgARSWCAiCQwQEQSGCAiCQwQkQQGyA1cvnwZmzZtcvUw5iUGyIXi4uLQ3NyseN0LFy4gNjYWoaGh+PGPf4yBgQHFx+AuGKB5pqurC//yL/+Cn/3sZ7h06RIWLlyI//N//o+rh/XcYoBcJDc3F7dv30ZGRgbCwsJw+vRpAEB2djaio6Oxdu1apKamoqury/6cxsZGxMfHIywsDDExMSgrK5v2tSsrKxEfH4+enp4n1l24cAFxcXFYt24dfH19kZOTg1/+8pcYGhpyzht1d4JcJjY2Vly6dGnSspqaGmGxWMTDhw9Ffn6+2LFjh31ddHS0uHLlihBCiIGBAWE2m4UQQrS0tIiYmBghhBAnTpwQiYmJoq+vb9qaGRkZ4tSpU5OWhYaGimvXrjnsfc0nC1wdYJps165d9vtZWVlYt24dLBYLdDodFixYgJs3b2LFihXQ6/XQ6/X23xVCoLCwEF988QUqKyuh0+mmff3h4eEn1vn5+eH+/fvOeUNujodwKjI6OoqioiJs3boV4eHhiIuLAwD09/cDAI4fP47GxkbExsbi9ddfR1tbm/25FosFZ8+exVtvvfXU8ADAn/zJnzxxuDY0NARfX18nvCP3xwCpyIULF9DQ0IAzZ87g6tWr+PjjjwGM710AwGAwoKSkBM3Nzdi6dSv2799vf+6iRYtQWlqKd955B1evXn1qjb/6q79CZ2en/fGtW7dgtVoRHBzsnDfl5hggF1qyZAlu3bplf3z//n1oNBosXrwYIyMjOHbsmH3do0ePUFdXB4vFAm9vb/j6+sLTc/L/vvXr16OoqAhZWVn44osvpq2ZkJCAX/3qV/jss88wPDyM4uJibNu2DX5+fs55k+7O1X+EzWe//OUvxfe+9z2xdu1a8fOf/1wMDQ2JjIwMERoaKjZv3ixqa2vFyy+/LL755hvx8OFD8cYbb4iIiAgRFhYmfvCDH9g/UHj8QwQhhPjVr34lIiMj7R8yTFVXVye+973vib/+678WGRkZor+/X5H36448hOAFdUR/LB7CEUlggIgkMEBEEhggIgmKB8hms6G7uxs2m03p0kQON2uAent7sXPnTqxZs+aJjf7GjRtITk5GUlLSpC/nZtLT04MtW7ZMe6Ij0fNm1gD5+/ujvLwcoaGhT6wrLi7GsWPHUFxcjOLiYqcMkEjNZj2Z1MfHBz4+PtOuGxwcRGBgIIDxc7Ec4dNKwO/fHPJSRE8YegPY+EPHvZ7U2dhjY2P2+9N9H1tdXY3q6upJyx49eiRTkkhVpALk4eFhvz/1vCwA2LNnD/bs2TNpWXd3N7Zs2fLU19z4QwAO/BeCyJmkAqTX69HT0wMPDw+eDk/z0qwfIlitVuzduxednZ1IT09Ha2srSkpKAIxf8LV//37k5OQgJyfH6YMlUhvFTyadOIRraGjAX/zFXyhZmsjheCYCkQQGiEgCA0QkgQEiksAAEUlggIgkMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJDBCRBAaISAIDRCRhTgEqKChASkoK8vPzJy3/8MMPsWvXLuzevRsfffSRUwZIpGazBuj69esYHh7Ge++9B6vVOmnuzYqKCphMJphMJpSXlztznESqNGuA2tvbERUVBQCIiopCe3u7fV1QUBBGRkYwPDzMSWppXpq1saLFYkFQUBAAQKfToaury75u27ZtSExMhBAChYWFTzyXrX3J3c0aIJ1Oh6GhIQDA0NAQFi1aZF/37rvv4uLFiwCAN998Exs3bpz03D+mtS/R82TWQ7jQ0FC0tLQAAJqbmydNc6LRaKDVarFw4UJYrVbnjZJIpWYN0KpVq6DRaJCSkgIvLy8EBgbaW/smJyfbJ9iauqchmg/Y2pdIAr9IJZLAABFJYICIJDBARBIYICIJDBCRBAaISAIDRCSBASKSwAARSWCAiCQwQEQSGCAiCQwQkQQGiEgCA0QkgQEiksAAEUlggIgkMEBEEmbtCweM98Y2m81YuXIlDh48aF8+MDCAQ4cOob+/H5GRkcjMzHTaQInUSKo39smTJ5GdnY3KykqGh+alWfdA0/XGNhgMAICuri6cOnUKv/vd7/CP//iPCAsLm/RctvYldyfVG7utrQ21tbXQ6/XIyspCVVXVpOeytS+5O6ne2MHBwXjppZcAAJ6e/DyC5h+p3tjBwcG4c+cOhoeHMTo66rxREqmUVG/s7OxsHDhwAGlpafwQgeYl9sYmksA/XIgkMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJc7qk25Emztru6elRujTRnLzwwgtYsGBu0VA8QHfv3gUApKamKl2aaE6e5URnxc/GfvDgAcxmMwICAuDl5TXt72RkZKC0tFTJYc3Luq6srea6qt4DabVaREREzPg7Go3GJZc6zLe6rqztLnX5IQKRBAaISAIDRCTB6/Dhw4ddPYjprF69mnXdvLY71FX8Uzgid8JDOCIJDBCRBNUFqKCgACkpKcjPz1es5ueff46kpCQkJyejoKBAsboTysvLkZycrHjdc+fOIS0tDUajEb29vYrUHBkZwb59+2A0GpGZmen0Xum9vb3YuXMn1qxZA5vNBsCx25iqAjTTTBDOtGzZMlRUVKCqqgp9fX348ssvFakLjDfb7+joUKzehN7eXrS2tqKiogImkwlLly5VpG5TUxMMBgNMJhMMBgM++eQTp9bz9/dHeXm5vaOuo7cxVQVoupkglBAQEAAfHx8AgLe391NPMXKGmpoaJCYmKlZvQlNTE8bGxpCWloa8vDzFWjO/+OKLGBkZAQAMDg7C39/fqfV8fHyg1+vtjx29jakqQBaLBX5+fgDGm9oPDg4qWr+zsxP37t1DSEiIIvWsVitaW1sRGRmpSL3H9fX1wWq1oqKiAlqtFg0NDYrUXb58Odrb27F9+3aYzWaEh4crUneCo7cxVQVoppkgnG1gYAB5eXk4cuSIYjXPnz+PhIQExeo9zs/PD+vWrQMAbNiwAV999ZUidWtraxEbG4sPPvgAmzdvRl1dnSJ1Jzh6G1NVgGaaCcKZbDYbcnNz8fbbbyMgIECRmgDw9ddfo6qqCunp6bh58yZMJpNitcPDw+1/63V0dCh2YqcQwn5ItXjxYlgsFkXqTnD0NqaqAE2dCWJiJjxnq6+vx7Vr13D06FEYjUa0tbUpUjc3NxdlZWUoKytDSEgIjEajInUB4NVXX4VWq4XRaITZbMZrr72mSN2EhATU19fDaDTiwoULTt8DW61W7N27F52dnUhPT4fNZnPoNsYzEYgkqGoPRPS8YYCIJDBARBIYICIJDBCRBAaISAIDRCSBASKSwAARSWCAiCQwQEQSGCAiCQyQG7h8+TI2bdrk6mHMSwyQC8XFxaG5uVnRmnfu3EFGRgY2btyIV155Bd3d3YrWdzcM0Dzj6emJmJgYnDhxwtVDcQsMkIvk5ubi9u3byMjIQFhYGE6fPg0AyM7ORnR0NNauXYvU1FR0dXXZn9PY2Ij4+HiEhYUhJiYGZWVl0752ZWUl4uPjp50FcMmSJUhNTcWaNWuc88bmG0EuExsbKy5dujRpWU1NjbBYLOLhw4ciPz9f7Nixw74uOjpaXLlyRQghxMDAgDCbzUIIIVpaWkRMTIwQQogTJ06IxMRE0dfXN2Ntq9UqXn75ZXHr1i1HvqV5R/EJtmhmu3btst/PysrCunXrYLFYoNPpsGDBAty8eRMrVqyAXq+f1K5JCIHCwkJ88cUXqKyshE6nc8Xw5x0ewqnI6OgoioqKsHXrVoSHhyMuLg4A0N/fDwA4fvw4GhsbERsbi9dff31S7waLxYKzZ8/irbfeYngUxACpyIULF9DQ0IAzZ87g6tWr+PjjjwGM710AwGAwoKSkBM3Nzdi6dSv2799vf+6iRYtQWlqKd955B1evXnXJ+OcjBsiFlixZglu3btkf379/HxqNBosXL8bIyAiOHTtmX/fo0SPU1dXBYrHA29sbvr6+8PSc/L9v/fr1KCoqQlZW1owtax8+fGjvSf3o0SM8fPjQwe9s/mCAXGjfvn0oKSlBREQEysrKkJiYiGXLliEmJgbbt29/omfZ+fPnERcXh/DwcLz//vs4evToE68ZHR2NgoICZGRk4Pr169PWNRgMCAsLAwD87d/+rWLtw9wR21oRSeAeiEgCA0QkgQEikqB4gGw2G7q7u+2zhRE9zxQPUE9PD7Zs2TLteVpEz5tZAzTdHJMTbty4geTkZCQlJaGzs9NpgyRSq1kDNHWOyccVFxfj2LFjKC4uRnFxsVMGSKRms55M6uPjY58/dKrBwUEEBgYCgOITJRGpgdTZ2GNjY/b7030fW11djerq6knLnD2tOZGSpALk4eFhvz/1vCwA2LNnD/bs2TNpWXd3N7Zs2SJTlkg1pAKk1+vR09MDDw8P+Pr6OmpMRM+NWT9EmDrHZGtrK0pKSgCMX/C1f/9+5OTkICcnx+mDJVIbxU8mnTiEa2hoUGxmaCJn4ak8RBIYICIJDBCRBAaISAIDRCSBASKSwAARSWCAiCQwQEQSGCAiCQwQkQQGiEgCA0QkgQEiksAAEUlggIgkMEBEEhggIgkMEJGEOQWooKAAKSkpyM/Pn7T8ww8/xK5du7B792589NFHThkgkZrNGqDr169jeHgY7733HqxW66S5NysqKmAymWAymVBeXu7McRKp0qwBam9vR1RUFAAgKioK7e3t9nVBQUEYGRnB8PAw/Pz8nDdKIpWatbGixWJBUFAQAECn06Grq8u+btu2bUhMTIQQAoWFhU88l619yd3NGiCdToehoSEAwNDQEBYtWmRf9+677+LixYsAgDfffBMbN26c9Fy29iV3N+shXGhoKFpaWgAAzc3Nk6Y50Wg00Gq1WLhwIaxWq/NGSaRSswZo1apV0Gg0SElJgZeXFwIDA+2tfZOTk+0TbE3d0xDNB2ztSySBX6QSSWCAiCQwQEQSGCAiCQwQkQQGiEgCA0QkgQEiksAAEUlggIgkMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBJmbWsFjLf2NZvNWLlyJQ4ePGhfPjAwgEOHDqG/vx+RkZHIzMx02kCJ1Eiqte/JkyeRnZ2NyspKhofmJanWvl1dXTh16hSMRiPa2tqcN0oilZJq7dvW1oba2lro9XpkZWWhqqpq0nPZ2pfcnVRr3+DgYLz00ksAAE/PJ3dmbO1L7k6qtW9wcDDu3LmD4eFhjI6OOm+URCol1do3OzsbBw4cQFpaGj9EoHmJrX2JJPCLVCIJDBCRBAaISAIDRCSBASKSwAARSWCAiCTM6XIGJQ0D6HvssceUn8+yjGiqJQC8HPh6qgtQfiXwv/7N1aMgd3XzDeBHP3Tc66kuQP8XAL8py+Z6qoSip1TQc+llB7+e6gL0Vz8E4MB/IYiciR8iEElQfA80cdlDT0+P0qWJ5uSFF17AggVzi4biAbp79y4AIDU1VenSRHPyLFcKKH45w4MHD2A2mxEQEAAvr+k/UMzIyEBpaamSw5qXdV1ZW811Vb0H0mq1iIiImPF3NBqNS64Vmm91XVnbXeryQwQiCQwQkQQGiEiC1+HDhw+7ehDTWb16Neu6eW13qKv4p3BE7oSHcEQSGCAiCaoLUEFBAVJSUpCfn69Yzc8//xxJSUlITk5GQUGBYnUnlJeXIzk5WfG6586dQ1paGoxGI3p7exWpOTIygn379sFoNCIzM9PpvdJ7e3uxc+dOrFmzBjabDYBjtzFVBWimqVScadmyZaioqEBVVRX6+vrw5ZdfKlIXGG+239HRoVi9Cb29vWhtbUVFRQVMJhOWLl2qSN2mpiYYDAaYTCYYDAZ88sknTq3n7++P8vJye0tqR29jqgrQTFOpOFNAQAB8fHwAAN7e3k89xcgZampqkJiYqFi9CU1NTRgbG0NaWhry8vIU623+4osvYmRkBAAwODgIf39/p9bz8fGBXq+3P3b0NqaqAFksFvj5jV9Op9PpMDg4qGj9zs5O3Lt3DyEhIYrUs1qtaG1tRWRkpCL1HtfX1wer1YqKigpotVo0NDQoUnf58uVob2/H9u3bYTabER4erkjdCY7exlQVoJmmUnG2gYEB5OXl4ciRI4rVPH/+PBISEhSr9zg/Pz+sW7cOALBhwwZ89dVXitStra1FbGwsPvjgA2zevBl1dXWK1J3g6G1MVQGaaSoVZ7LZbMjNzcXbb7+NgIAARWoCwNdff42qqiqkp6fj5s2bMJlMitUODw+3/63X0dGh2ImdQgj7IdXixYthsVgUqTvB0duYqgI0dSoVg8GgSN36+npcu3YNR48eVXS6ytzcXJSVlaGsrAwhISEwGo2K1AWAV199FVqtFkajEWazGa+99poidRMSElBfXw+j0YgLFy44fQ9stVqxd+9edHZ2Ij09HTabzaHbGM9EIJKgqj0Q0fOGASKSwAARSWCAiCQwQEQSGCAiCQwQkQQGiEgCA0QkgQEiksAAEUlggNzA5cuXsWnTJlcPY15igFwoLi4Ozc3Nitb89a9/jeTkZERERCA6Oho//elP7dfH0LNjgOYZi8WCzMxMNDU14eLFi+jt7cXPfvYzVw/rucUAuUhubi5u376NjIwMhIWF4fTp0wCA7OxsREdHY+3atUhNTUVXV5f9OY2NjYiPj0dYWBhiYmJQVlY27WtXVlYiPj5+2knMEhISsGnTJixcuBB6vR5///d/r9j1T25JkMvExsaKS5cuTVpWU1MjLBaLePjwocjPzxc7duywr4uOjhZXrlwRQggxMDAgzGazEEKIlpYWERMTI4QQ4sSJEyIxMVH09fXNaQz5+fli//79jng785LqJhme73bt2mW/n5WVhXXr1sFisUCn02HBggW4efMmVqxYAb1eP6nbjBAChYWF+OKLL1BZWQmdTjdrrUuXLuHcuXM4e/asU97LfMBDOBUZHR1FUVERtm7divDwcMTFxQEA+vv7AQDHjx9HY2MjYmNj8frrr0869LJYLDh79izeeuutOYWnvb0dBw4cwPHjx/GXf/mXznlD84Grd4Hz2dRDuNraWvH9739f/OY3vxFjY2Pi97//vXj55ZfFN998M+l5jx49EmfOnBGbNm0SQvzhEK6lpUVs2LBBfPbZZzPWvX79utiwYYNoaGhw/JuaZ7gHcqElS5bg1q1b9sf379+HRqPB4sWLMTIygmPHjtnXPXr0CHV1dbBYLPD29oavry88PSf/71u/fj2KioqQlZX11I6bN27cwI9+9CP88z//s30PR388BsiF9u3bh5KSEkRERKCsrAyJiYlYtmwZYmJisH379idaLp0/fx5xcXEIDw/H+++/j6NHjz7xmtHR0SgoKEBGRgauX7/+xPozZ87g3r17+OlPf4qwsDCEhYVh+/btTnuP7o5deYgkcA9EJIEBIpLAABFJYICIJCgeIJvNhu7ubvtsYUTPs1kDNN0UeRNu3LiB5ORkJCUlobOzc04Fe3p6sGXLlmlPdCR63swaoKlT5D2uuLgYx44dQ3FxMYqLi50yQCI1m/VkUh8fH/v0h1MNDg4iMDAQABSf54VIDaTOxh4bG7Pfn+772OrqalRXV09a5uxZmYmUJBUgDw8P+/2p52UBwJ49e7Bnz55Jy7q7u7FlyxaZskSqIRUgvV6Pnp4eeHh4wNfX11FjInpuzPohwtQp8lpbW1FSUgJg/IKv/fv3IycnBzk5OU4fLJHaKH4y6cQhXENDg2IT2xI5C89EIJLAABFJYICIJDBARBIYICIJDBCRBAaISAIDRCSBASKSwAARSWCAiCQwQEQSGCAiCQwQkQQGiEgCA0QkgQEiksAAEUlggIgkMEBEEuYUoIKCAqSkpCA/P3/S8g8//BC7du3C7t278dFHHzllgERqNmuArl+/juHhYbz33nuwWq2TJq+tqKiAyWSCyWRCeXm5M8dJpEqzNlZsb29HVFQUACAqKgrt7e0wGAwAgKCgIIyMjAAA/Pz8nnguW/uSu5s1QBaLBUFBQQAAnU6Hrq4u+7pt27YhMTERQggUFhY+8Vy29iV3N2uAdDodhoaGAABDQ0NYtGiRfd27776LixcvAgDefPNNbNy40UnDJFKnWf8GCg0NRUtLCwCgubl50jxBGo0GWq0WCxcuhNVqdd4oiVRq1gCtWrUKGo0GKSkp8PLyQmBgoL03dnJysn2GuqmHakTzAXtjE0ngF6lEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJDBCRBAaISAIDRCSBASKSwAARSWCAiCQwQEQSGCAiCQwQkYRZ21oB4619zWYzVq5ciYMHD9qXDwwM4NChQ+jv70dkZCQyMzOdNlAiNZJq7Xvy5ElkZ2ejsrKS4aF5adYATdfad0JXVxdOnToFo9GItrY2542SSKWkWvu2tbWhtrYWer0eWVlZqKqqmvRc9sYmdyfV2jc4OBgvvfQSAMDT88mdGXtjk7uTau0bHByMO3fuYHh4GKOjo84bJZFKSbX2zc7OxoEDB5CWlsYPEWheYmtfIgn8IpVIAgNEJIEBIpLAABFJYICIJDBARBIYICIJc7qcQUmfNgBD16df5/GU50ws9xAAHrt5PMN9D0W/DSNXWfK/gNUbHPd6qgvQn/3fwMb22X+P6I/R+P8BcOcA/dVlYGz83FU8vlOY630PD4zvkjye/f5Td3HkNjY5+P+x6gLkoQE8vuPqURDNjeIBmjhru6enR+nSRHPywgsvYMGCuUVD8QDdvXsXAJCamqp0aaI5eZYTnRU/G/vBgwcwm80ICAiAl5fXtL+TkZGB0tJSJYc1L+u6sraa66p6D6TVahERETHj72g0Gpdc6jDf6rqytrvU5RepRBIYICIJDBCRBK/Dhw8fdvUgprN69WrWdfPa7lBX8U/hiNwJD+GIJDBARBJUF6CCggKkpKQgPz9fsZqff/45kpKSkJycjIKCAsXqTigvL0dycrLidc+dO4e0tDQYjUb09vYqUnNkZAT79u2D0WhEZmam01s99/b2YufOnVizZg1sNhsAx25jqgrQTDNBONOyZctQUVGBqqoq9PX14csvv1SkLjDeK7yjo0OxehN6e3vR2tqKiooKmEwmLF26VJG6TU1NMBgMMJlMMBgM+OSTT5xaz9/fH+Xl5faOuo7exlQVoJlmgnCmgIAA+Pj4AAC8vb2feoqRM9TU1CAxMVGxehOampowNjaGtLQ05OXlKdaa+cUXX8TIyAgAYHBwEP7+/k6t5+PjA71eb3/s6G1MVQGyWCzw8/MDMN7UfnBwUNH6nZ2duHfvHkJCQhSpZ7Va0draisjISEXqPa6vrw9WqxUVFRXQarVoaGhQpO7y5cvR3t6O7du3w2w2Izw8XJG6Exy9jakqQDPNBOFsAwMDyMvLw5EjRxSref78eSQkJChW73F+fn5Yt24dAGDDhg346quvFKlbW1uL2NhYfPDBB9i8eTPq6uoUqTvB0duYqgI000wQzmSz2ZCbm4u3334bAQEBitQEgK+//hpVVVVIT0/HzZs3YTKZFKsdHh5u/1uvo6NDsRM7hRD2Q6rFixfDYrEoUneCo7cxVQVo6kwQBoNBkbr19fW4du0ajh49quhse7m5uSgrK0NZWRlCQkJgNBoVqQsAr776KrRaLYxGI8xmM1577TVF6iYkJKC+vh5GoxEXLlxw+h7YarVi79696OzsRHp6Omw2m0O3MZ6JQCRBVXsgoucNA0QkgQEiksAAEUlggIgkMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYIDcwOXLl7Fp0yZXD2NeYoBcKC4uDs3NzYrWbGlpQUJCAiIiIrB+/Xr85Cc/UayhiDtigOaZkJAQ/PznP8dnn32GpqYmLF++HIcOHXL1sJ5bDJCL5Obm4vbt28jIyEBYWBhOnz4NAMjOzkZ0dDTWrl2L1NRUdHV12Z/T2NiI+Ph4hIWFISYmBmVlZdO+dmVlJeLj46edBXDJkiWTOvB4eXnhN7/5jYPf3TwiyGViY2PFpUuXJi2rqakRFotFPHz4UOTn54sdO3bY10VHR4srV64IIYQYGBgQZrNZCCFES0uLiImJEUIIceLECZGYmCj6+vqeWve3v/2tWLt2rXjllVfEypUrxb//+787+q3NG6qbZHi+27Vrl/1+VlYW1q1bB4vFAp1OhwULFuDmzZtYsWIF9Hr9pHZNQggUFhbiiy++QGVlJXQ63VNrLFu2DJ999hkGBgZw9uxZfPe733Xqe3JnPIRTkdHRURQVFWHr1q0IDw9HXFwcAKC/vx8AcPz4cTQ2NiI2Nhavv/76pN4NFosFZ8+exVtvvTVjeB7n7++PnTt34sc//rG9ayc9GwZIRS5cuICGhgacOXMGV69exccffwxgfO8CAAaDASUlJWhubsbWrVuxf/9++3MXLVqE0tJSvPPOO7h69eqca46OjqKvr8/e6omeDQPkQkuWLMGtW7fsj+/fvw+NRoPFixdjZGQEx44ds6979OgR6urqYLFY4O3tDV9fX3h6Tv7ft379ehQVFSErK+upLWv/8z//E//93/+NsbEx3Lt3D4WFhVi5cqXTO4S6KwbIhfbt24eSkhJERESgrKwMiYmJWLZsGWJiYrB9+/YnepadP38ecXFxCA8Px/vvv4+jR48+8ZrR0dEoKChARkYGrl+//sT63t5e/OhHP0J4eDgSEhLg6emJkydPOu09uju2tSKFT/twAAAgAElEQVSSwD0QkQQGiEgCA0QkQfEA2Ww2dHd383sHcguKB6inpwdbtmyZ9jwtoufNrAGabo7JCTdu3EBycjKSkpLQ2dnptEESqdWsAZo6x+TjiouLcezYMRQXF6O4uNgpAyRSs1lPJvXx8bHPHzrV4OAgAgMDAUDxiZKI1EDqbOyxsTH7/em+j62urkZ1dfWkZc6e1pxISVIB8vDwsN+fel4WAOzZswd79uyZtKy7uxtbtmyRKUukGlIB0uv16OnpgYeHB3x9fR01JqLnxqwfIkydY7K1tRUlJSUAxi/42r9/P3JycpCTk+P0wRKpjeInk04cwjU0NCg2MzSRs/BUHiIJDBCRBAaISAIDRCSBASKSwAARSWCAiCQwQEQSGCAiCQwQkQQGiEgCA0QkgQEiksAAEUlggIgkMEBEEhggIgkMEJEEBohIwpwCVFBQgJSUFOTn509a/uGHH2LXrl3YvXs3PvroI6cMkEjNZg3Q9evXMTw8jPfeew9Wq3XS3JsVFRUwmUwwmUwoLy935jiJVGnWALW3tyMqKgoAEBUVhfb2dvu6oKAgjIyMYHh4GH5+fs4bJZFKzdpY0WKxICgoCACg0+nQ1dVlX7dt2zYkJiZCCIHCwsInnsvWvuTuZg2QTqfD0NAQAGBoaAiLFi2yr3v33Xdx8eJFAMCbb76JjRs3TnouW/uSu5v1EC40NBQtLS0AgObm5knTnGg0Gmi1WixcuBBWq9V5oyRSqVkDtGrVKmg0GqSkpMDLywuBgYH21r7Jycn2Cbam7mmI5gO29iWSwC9SiSQwQEQSGCAiCQwQkQQGiEgCA0QkgQEiksAAEUlggIgkMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJs7a1AsZb+5rNZqxcuRIHDx60Lx8YGMChQ4fQ39+PyMhIZGZmOm2gRGok1dr35MmTyM7ORmVlJcND85JUa9+uri6cOnUKRqMRbW1tzhslkUpJtfZta2tDbW0t9Ho9srKyUFVVNem5bO1L7k6qtW9wcDBeeuklAICn55M7M7b2JXcn1do3ODgYd+7cwfDwMEZHR503SiKVkmrtm52djQMHDiAtLY0fItC8xNa+RBL4RSqRBAaISAIDRCSBASKSwAARSWCAiCQwQEQS5nQ5g5J6APyPi2p7A/D79qYD4Av+C0MzU12AiiqBv/s319QeATA4ZZknAK/HbgumPJ64TQTN49sb5vhz4j4ATP1G+1kf0xy8AfzFDx33cqoLUC5cNygBYHQONxuAh1OWjblgvPTsvgKQ7sDXU12Alv4QgAP/hVCKwHiIHr+NPsNjD4kbzd0mB7+e6gL0vPLAHw7naP5QPEATlz309PQoXZpoTl544QUsWDC3aCgeoLt37wIAUlNTlS5NNCfPcqWA4pczPHjwAGazGQEBAfDymv6AJyMjA6WlpUoOa17WdWVtNddV9R5Iq9UiIiJixt/RaDQuuVZovtV1ZW13qcvvCYkkMEBEEhggIglehw8fPuzqQUxn9erVrOvmtd2hruKfwhG5Ex7CEUlggIgkqC5ABQUFSElJQX5+vmI1P//8cyQlJSE5ORkFBQWK1Z1QXl6O5ORkxeueO3cOaWlpMBqN6O3tVaTmyMgI9u3bB6PRiMzMTKf3Su/t7cXOnTuxZs0a2Gw2AI7dxlQVoJmmUnGmZcuWoaKiAlVVVejr68OXX36pSF1gvNl+R0eHYvUm9Pb2orW1FRUVFTCZTFi6dKkidZuammAwGGAymWAwGPDJJ584tZ6/vz/Ky8vtLakdvY2pKkAzTaXiTAEBAfDx8QEAeHt7P/UUI2eoqalBYmKiYvUmNDU1YWxsDGlpacjLy1Ost/mLL76IkZERAMDg4CD8/f2dWs/Hxwd6vd7+2NHbmKoCZLFY4OfnB2B8VojBwanXhzpXZ2cn7t27h5CQEEXqWa1WtLa2IjIyUpF6j+vr64PVakVFRQW0Wi0aGhoUqbt8+XK0t7dj+/btMJvNCA8PV6TuBEdvY6oK0ExTqTjbwMAA8vLycOTIEcVqnj9/HgkJCYrVe5yfnx/WrVsHANiwYQO++uorRerW1tYiNjYWH3zwATZv3oy6ujpF6k5w9DamqgDNNJWKM9lsNuTm5uLtt99GQECAIjUB4Ouvv0ZVVRXS09Nx8+ZNmEwmxWqHh4fb/9br6OhQ7MROIYT9kGrx4sWwWCyK1J3g6G1MVQGaOpWKwWBQpG59fT2uXbuGo0ePKjpdZW5uLsrKylBWVoaQkBAYjUZF6gLAq6++Cq1WC6PRCLPZjNdee02RugkJCaivr4fRaMSFCxecvge2Wq3Yu3cvOjs7kZ6eDpvN5tBtjGciEElQ1R6I6HnDABFJYICIJDBARBIYICIJDBCRBAaISAIDRCSBASKSwAARSWCAiCQwQEQSGCA3cPnyZWza5Oipo2guGCAXiouLQ3Nzs8vqv/POO3jllVfwP//jqmmdn38M0Dz12Wef4datW64exnOPAXKR3Nxc3L59GxkZGQgLC8Pp06cBANnZ2YiOjsbatWuRmpqKrq4u+3MaGxsRHx+PsLAwxMTEoKysbNrXrqysRHx8/FNnAbTZbMjPz8fBgwcd/8bmG0EuExsbKy5dujRpWU1NjbBYLOLhw4ciPz9f7Nixw74uOjpaXLlyRQghxMDAgDCbzUIIIVpaWkRMTIwQQogTJ06IxMRE0dfX99S6p0+fFnl5eUIIIV5++WXxzTffOPR9zSecZFhldu3aZb+flZWFdevWwWKxQKfTYcGCBbh58yZWrFgBvV4/qV2TEAKFhYX44osvUFlZCZ1ON+3r/+53v0N1dTX+4z/+w+nvZT7gIZyKjI6OoqioCFu3bkV4eDji4uIAAP39/QCA48ePo7GxEbGxsXj99dcn9W6wWCw4e/Ys3nrrraeGBxjvyvmTn/xkxt+hZ+DqXeB8NvUQrra2Vnz/+98Xv/nNb8TY2Jj4/e9/P+0h1qNHj8SZM2fEpk2bhBB/OIRraWkRGzZsEJ999tlTa65du1ZERkaKqKgoERUVJV5++WWxfv16UVdX55w36eZ4COdCS5YsmfRJ2P3796HRaLB48WKMjIzg2LFj9nWPHj1CfX09YmNjodPp4OvrC0/PyQcQ69evR1FREbKyslBaWjptx5lf/OIXGBsbsz/euHEjSktLsWLFCie8Q/fHQzgX2rdvH0pKShAREYGysjIkJiZi2bJliImJwfbt25/oWXb+/HnExcUhPDwc77//Po4ePfrEa0ZHR6OgoAAZGRm4fv36E+v/9E//FAEBAfYbMN6fTavVOudNujm2tSKSwD0QkQQGiEgCA0QkQfEA2Ww2dHd322cLI3qeKR6gnp4ebNmy5annaRE9T2YN0HRzTE64ceMGkpOTkZSUhM7OTqcNkkitZg3Q1DkmH1dcXIxjx46huLgYxcXFThkgkZrNeiaCj4+Pff7QqQYHBxEYGAgAik+URKQGUqfyPH5KyHTfx1ZXV6O6unrSMmdPa06kJKkAeXh42O9PPS8LAPbs2YM9e/ZMWtbd3Y0tW7bIlCVSDakA6fV69PT0wMPDA76+vo4aE9FzY9YPEabOMdna2oqSkhIA4xd87d+/Hzk5OcjJyXH6YInURvGTSScO4RoaGhSbGZrIWXgqD5EEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJDBCRBAaISAIDRCSBASKSwAARSWCAiCQwQEQSGCAiCQwQkQQGiEgCA0QkYU4BKigoQEpKCvLz8yct//DDD7Fr1y7s3r0bH330kVMGSKRmswbo+vXrGB4exnvvvQer1YovvvjCvq6iogImkwkmkwnl5eXOHCeRKs0aoPb2dkRFRQEAoqKi0N7ebl8XFBSEkZERDA8Pw8/Pz3mjJFKpWRsrWiwWBAUFAQB0Oh26urrs67Zt24bExEQIIVBYWPjEc9nal9zdrAHS6XQYGhoCAAwNDWHRokX2de+++y4uXrwIAHjzzTexcePGSc9la19yd7MewoWGhqKlpQUA0NzcPGmaE41GA61Wi4ULF8JqtTpvlEQqNWuAVq1aBY1Gg5SUFHh5eSEwMNDe2jc5Odk+wdbUPQ3RfMDWvkQS+EUqkQQGiEgCA0QkgQEiksAAEUlggIgkMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJDBCRBAaISAIDRCRh1rZWwHhrX7PZjJUrV+LgwYP25QMDAzh06BD6+/sRGRmJzMxMpw2USI2kWvuePHkS2dnZqKysZHhoXpJq7dvV1YVTp07BaDSira3NeaMkUimp1r5tbW2ora2FXq9HVlYWqqqqJj2XrX3J3Um19g0ODsZLL70EAPD0fHJnxta+5O6kWvsGBwfjzp07GB4exujoqPNGSaRSUq19s7OzceDAAaSlpfFDBJqX2NqXSAK/SCWSwAARSWCAiCQwQEQSGCAiCQwQkQQGiEjCnC5nUFLLEPCbu4A3AC+MD3DBt/enW7Zgyk32XwSPP/J5QgBiDBj99ufY2B+WjX37c+L+4+uEGL9Nrf/4OKYumzrGP3bM89HyVcBjZ6NJU12AAv4G2NDh6lGQu2r+eyCqevbfmyvVBejPy4G+DmAUk29jT7k/9aboaRVTeHg+dvMA8O3Px5c9/tPz258Tu5DHxy6e8vNp62luXlnr2NdTXYC0fzN+I3oeKB6gibO2e3p6lC5NNCcvvPACFiyYWzQUD9Ddu3cBAKmpqUqXJpqTZznRWfGzsR88eACz2YyAgAB4eXlN+zsZGRkoLS1Vcljzsq4ra6u5rqr3QFqtFhERETP+jkajccmlDvOtritru0tdfpFKJIEBIpLAABFJ8Dp8+PBhVw9iOqtXr2ZdN6/tDnUV/xSOyJ3wEI5IAgNEJIEBIpKgugAVFBQgJSUF+fn5itX8/PPPkZSUhOTkZBQUFChWd0J5eTmSk5MVr3vu3DmkpaXBaDSit7dXkZojIyPYt28fjEYjMjMznd4rvbe3Fzt37sSaNWtgs9kAOHYbU1WAZppKxZmWLVuGiooKVFVVoa+vD19++aUidYHxZvsdHcpfANXb24vW1lZUVFTAZDJh6dKlitRtamqCwWCAyWSCwWDAJ5984tR6/v7+KC8vt7ekdvQ2pqoAzTSVijMFBATAx8cHAODt7f3Uc/ScoaamBomJiYrVm9DU1ISxsTGkpaUhLy9Psd7mL774IkZGRgAAg4OD8Pf3d2o9Hx8f6PV6+2NHb2OqCpDFYoGfnx+A8VkhBgcHFa3f2dmJe/fuISQkRJF6VqsVra2tiIyMVKTe4/r6+mC1WlFRUQGtVouGhgZF6i5fvhzt7e3Yvn07zGYzwsPDFak7wdHbmKoCNNNUKs42MDCAvLw8HDlyRLGa58+fR0JCgmL1Hufn54d169YBADZs2ICvvvpKkbq1tbWIjY3FBx98gM2bN6Ourk6RuhMcvY2pKkAzTaXiTDabDbm5uXj77bcREBCgSE0A+Prrr1FVVYX09HTcvHkTJpNJsdrh4eH2v/U6OjoUOzNaCGE/pFq8eDEsFosidSc4ehtTVYCmTqViMBgUqVtfX49r167h6NGjik5XmZubi7KyMpSVlSEkJARGo1GRugDw6quvQqvVwmg0wmw247XXXlOkbkJCAurr62E0GnHhwgWn74GtViv27t2Lzs5OpKenw2azOXQb46k8RBJUtQciet4wQEQSGCAiCQwQkQQGiEgCA0QkgQEiksAAEUlggIgkMEBEEhggIgkMkBu4fPkyNm3a5OphzEsMkAvFxcWhublZ0ZqXL1/GihUrEBYWZr/V1tYqOgZ3oroZ6sj5/uzP/szpvQjmC+6BXCQ3Nxe3b99GRkYGwsLCcPr0aQBAdnY2oqOjsXbtWqSmpqKrq8v+nMbGRsTHxyMsLAwxMTEoKyub9rUrKysRHx/PWQCVIMhlYmNjxaVLlyYtq6mpERaLRTx8+FDk5+eLHTt22NdFR0eLK1euCCGEGBgYEGazWQghREtLi4iJiRFCCHHixAmRmJgo+vr6pq3Z0tIiVq1aJSIjI0VsbKw4cuSIuH//vjPe3rzAPZDK7Nq1C35+ftBoNMjKykJnZ6f9sucFCxbg5s2bGBoagl6vx6pVq+zPE0KgsLAQly5dQmVlJb7zne9M+/rf/e53ce7cOXz66aeoqKjA9evX8a//+q+KvDd3xACpyOjoKIqKirB161aEh4cjLi4OANDf3w8AOH78OBobGxEbG4vXX3990qXnFosFZ8+exVtvvQWdTvfUGgEBAQgJCYGnpyeCgoKQm5uLX/ziF859Y26MAVKRCxcuoKGhAWfOnMHVq1fx8ccfAxjfuwCAwWBASUkJmpubsXXrVuzfv9/+3EWLFqG0tBTvvPMOrl69OueaHh4e9tenZ8cAudCSJUtw69Yt++P79+9Do9Fg8eLFGBkZwbFjx+zrHj16hLq6OlgsFnh7e8PX1xeenpP/961fvx5FRUXIysp6asfNlpYW/Pa3v4UQAr/73e9QVFSELVu2OOcNzgMMkAvt27cPJSUliIiIQFlZGRITE7Fs2TLExMRg+/btT7RcOn/+POLi4hAeHo73338fR48efeI1o6OjUVBQgIyMDFy/fv2J9R0dHUhKSkJoaCiSkpLwyiuv4Kc//anT3qO7Y1ceIgncAxFJYICIJDBARBIYICIJigfIZrOhu7vbPlsY0fNs1gBNN0XehBs3biA5ORlJSUno7OycU8Genh5s2bKFJzqSW5g1QFOnyHtccXExjh07huLiYhQXFztlgERqNuv1QD4+PvbpD6caHBxEYGAgACg+zwuRGkhdUDc2Nma/P933sdXV1aiurp60zNmzMhMpSSpAHh4e9vtTz8sCgD179mDPnj2TlnV3d/PcK3IbUgHS6/Xo6emBh4cHfH19HTUmoufGrB8iTJ0ir7W1FSUlJQCArKws7N+/Hzk5OcjJyXH6YInURvGTSScO4RoaGhSb2JbIWXgmApEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJDBCRBAaISAIDRCSBASKSwAARSWCAiCQwQEQSGCAiCQwQkQQGiEgCA0QkgQEikjCnABUUFCAlJQX5+fmTln/44YfYtWsXdu/ejY8++sgpAyRSs1kDdP36dQwPD+O9996D1WqdNHltRUUFTCYTTCYTysvLnTlOIlWatbFie3s7oqKiAABRUVFob2+HwWAAAAQFBWFkZAQA4Ofn98Rz2dqX3N2sAbJYLAgKCgIA6HQ6dHV12ddt27YNiYmJEEKgsLDwieeytS+5u1kDpNPpMDQ0BAAYGhrCokWL7OveffddXLx4EQDw5ptvYuPGjU4aJpE6zfo3UGhoKFpaWgAAzc3Nk+YJ0mg00Gq1WLhwIaxWq/NGSaRSswZo1apV0Gg0SElJgZeXFwIDA+29sZOTk+0z1E09VCOaD9gbm0gCv0glksAAEUlggIgkMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJDBCRBAaISAIDRCSBASKSwAARSWCAiCTM2tYKGG/tazabsXLlShw8eNC+fGBgAIcOHUJ/fz8iIyORmZnptIESqZFUa9+TJ08iOzsblZWVDA/NS7MGaLrWvhO6urpw6tQpGI1GtLW1OW+URCol1dq3ra0NtbW10Ov1yMrKQlVV1aTnsjc2uTup1r7BwcF46aWXAACenk/uzNgbm9ydVGvf4OBg3LlzB8PDwxgdHXXeKIlUSqq1b3Z2Ng4cOIC0tDR+iEDzElv7EkngF6lEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJmNPlDEpqqQUeXJu8zGMO9ycejwKwfXuzTvk5dfnU+wDgPeWmmWbZdDevacbzLMY8J9+Exx/uj3o+uX5iuZha9LFv9TymfsM32zd+j72WeMp/6CfqTa3ztPoz1fZ4es1pxyG+fW0BeIyN3/cY+8Ny+/2xJ39v6RbAEDbDWJ6R6gLkexTY8P+6ehTkrj59C0Cp415PdQFafQkYE3/4B+vbf0Ds92dbNrFHkNkbzIUA8AjA8Le3hzKvJQAvAXiOjd+8vr15TlnmMfaHx4/fpt0VT3d/usePv6FnvT+XQ4OZxvL4a05X52nLPL69eU75OdsyDyDab5oxSFBdgDw8xm9q5wHA59vbYhePhVxH8QBNnLXd09OjdGmiOXnhhRewYMHcoqF4gO7evQsASE1NVbo00Zw8y4nOip+N/eDBA5jNZgQEBMDLy2va38nIyEBpqQP/0puj+VbXlbXVXFfVeyCtVouIiIgZf0ej0bjkUof5VteVtd2lLr9IJZLAABFJYICIJHgdPnz4sKsHMZ3Vq1ezrpvXdoe6in8KR+ROeAhHJIEBIpKgugAVFBQgJSUF+fn5itX8/PPPkZSUhOTkZBQUFChWd0J5eTmSk5MVr3vu3DmkpaXBaDSit7dXkZojIyPYt28fjEYjMjMznd7qube3Fzt37sSaNWtgs41ftOLIbUxVAZppJghnWrZsGSoqKlBVVYW+vj58+eWXitQFxnuFd3R0KFZvQm9vL1pbW1FRUQGTyYSlS5cqUrepqQkGgwEmkwkGgwGffPKJU+v5+/ujvLzc3lHX0duYqgI000wQzhQQEAAfHx8AgLe391NPMXKGmpoaJCYmKlZvQlNTE8bGxpCWloa8vDzFWjO/+OKLGBkZAQAMDg7C39/fqfV8fHyg1+vtjx29jakqQBaLBX5+4xds6HQ6DA4OKlq/s7MT9+7dQ0hIiCL1rFYrWltbERkZqUi9x/X19cFqtaKiogJarRYNDQ2K1F2+fDna29uxfft2mM1mhIeHK1J3gqO3MVUFaKaZIJxtYGAAeXl5OHLkiGI1z58/j4SEBMXqPc7Pzw/r1q0DAGzYsAFfffWVInVra2sRGxuLDz74AJs3b0ZdXZ0idSc4ehtTVYBmmgnCmWw2G3Jzc/H2228jICBAkZoA8PXXX6Oqqgrp6em4efMmTCaTYrXDw8Ptf+t1dHQodmKnEMJ+SLV48WJYLBZF6k5w9DamqgBNnQnCYDAoUre+vh7Xrl3D0aNHFZ1tLzc3F2VlZSgrK0NISAiMRqMidQHg1VdfhVarhdFohNlsxmuvvaZI3YSEBNTX18NoNOLChQtO3wNbrVbs3bsXnZ2dSE9Ph81mc+g2xjMRiCSoag9E9LxhgIgkMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJDJAbuHz5MjZt2uTqYcxLDJALxcXFobm5WfG69+7dw4EDB7B27VqsW7cOBw4cUHwM7kJ1M9SR8/3DP/wD1qxZg1//+tfQarXo6upy9ZCeW9wDuUhubi5u376NjIwMhIWF4fTp0wCA7OxsREdHY+3atUhNTZ20cTc2NiI+Ph5hYWGIiYlBWVnZtK9dWVmJ+Pj4aWcB/PTTT9HT04N/+qd/gk6ng7e3N1auXOmcNzkfCHKZ2NhYcenSpUnLampqhMViEQ8fPhT5+flix44d9nXR0dHiypUrQgghBgYGhNlsFkII0dLSImJiYoQQQpw4cUIkJiaKvr6+aWueOHFCvPHGG+LAgQPib/7mb8QPfvADcfnyZWe8vXmBeyCV2bVrF/z8/KDRaJCVlYXOzk5734AFCxbg5s2bGBoagl6vx6pVq+zPE0KgsLAQly5dQmVlJb7zne9M+/q9vb349NNPsX79enz66ad444038OMf/xj37t1T5P25GwZIRUZHR1FUVIStW7ciPDwccXFxAID+/n4AwPHjx9HY2IjY2Fi8/vrrk3o3WCwWnD17Fm+99RZ0Ot1Ta/j4+ODP//zPsXv3bnh7e2P79u0IDAzEf/3Xfzn3zbkpBkhFLly4gIaGBpw5cwZXr17Fxx9/DGB87wIABoMBJSUlaG5uxtatW7F//377cxctWoTS0lK88847uHr16lNrvPLKK/Dw8HDuG5lHGCAXWrJkCW7dumV/fP/+fWg0GixevBgjIyM4duyYfd2jR49QV1cHi8UCb29v+Pr6wtNz8v++9evXo6ioCFlZWU9tWbtt2zYMDg6itrYWo6OjqK+vR29vr+INDt2Gq/8Im89++ctfiu9973ti7dq14uc//7kYGhoSGRkZIjQ0VGzevFnU1taKl19+WXzzzTfi4cOH4o033hAREREiLCxM/OAHP7B/oPD4hwhCCPGrX/1KREZG2j9kmOrKlSvi7/7u70RoaKjYuXOn/XXo2bGtFZEEHsIRSWCAiCQwQEQSFA+QzWZDd3e3fbYwoueZ4gHq6enBli1bpj1Pi+h5M2uApptjcsKNGzeQnJyMpKQkdHZ2Om2QRGo1a4CmzjH5uOLiYhw7dgzFxcUoLi52ygCJ1GzW64F8fHzs84dONTg4iMDAQABQfKIkIjWQuqBubGzMfn+672Orq6tRXV09aZmzpzUnUpJUgB4/KXHqeVkAsGfPHuzZs2fSsu7ubmzZskWmLJFqSAVIr9ejp6cHHh4e8PX1ddSYiJ4bs36IMHWOydbWVpSUlAAAsrKysH//fuTk5CAnJ8fpgyVSG8VPJp04hGtoaFBsZmgiZ+GpPEQSGCAiCQwQkQQGiEgCA0QkgQEiksAAEUlggIgkMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJDBCRhDkFqKCgACkpKcjPz5+0/MMPP8SuXbuwe/dufPTRR04ZIJGazRqg69evY3h4GO+99x6sVuukuTcrKipgMplgMplQXl7uzHESqdKsAWpvb0dUVBQAICoqCu3t7fZ1QUFBGBkZwfDwMPz8/Jw3SiKVmrWxosViQVBQEABAp9Ohq6vLvm7btm1ITEyEEAKFhYVPPJetfcndzRognU6HoaEhAMDQ0BAWLVpkX/fuu+/i4sWLAIA333wTGzdunPRctsMD8k8AACAASURBVPYldzfrIVxoaChaWloAAM3NzZOmOdFoNNBqtVi4cCGsVqvzRkmkUrMGaNWqVdBoNEhJSYGXlxcCAwPtrX2Tk5PtE2xN3dMQzQds7UskgV+kEklggIgkMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJDBCRBAaISAIDRCSBASKSwAARSWCAiCQwQEQSZm1rBYy39jWbzVi5ciUOHjxoXz4wMIBDhw6hv78fkZGRyMzMdNpAidRIqrXvyZMnkZ2djcrKSoaH5iWp1r5dXV04deoUjEYj2tranDdKIpWSau3b1taG2tpa6PV6ZGVloaqqatJz2dqX3J1Ua9/g4GC89NJLAABPzyd3ZmztS+5OqrVvcHAw7ty5g+HhYYyOjjpvlEQqJdXaNzs7GwcOHEBaWho/RKB5ia19iSTwi1QiCQwQkQQGiEgCA0QkgQEiksAAEUlggIgkzOlyBiWJMQBjgIerB/I88QL/g7mI6gJkjgbWtLh6FM8fmxcwumDyzeb95LKpNzHPgtdvBDY58KQZ1QXo/v8DfHwNGMX4bewpP5+2TmDyP8Yez/jzeeMhAM9RwMsGeNrGf3rZgAXWP9yfuHlOebzA6urRK89D69jXU12ANvxvAP/b1aMgmht+iEAkQfE90MRlDz09PUqXJpqTF154AQsWzC0aigfo7t27AIDU1FSlSxPNybNcKaD45QwPHjyA2WxGQEAAvLy8pv2djIwMlJaWKjmseVnXlbXVXFfVeyCtVouIiIgZf0ej0bjkWqH5VteVtd2lLj9EIJLAABFJYICIJHgdPnz4sKsHMZ3Vq1ezrpvXdoe6in8KR+ROeAhHJIEBIpKgugAVFBQgJSUF+fn5itX8/PPPkZSUhOTkZBQUFChWd0J5eTmSk5MVr3vu3DmkpaXBaDSit7dXkZojIyPYt28fjEYjMjMznd4rvbe3Fzt37sSaNWtgs9kAOHYbU1WAZppKxZmWLVuGiooKVFVVoa+vD19++aUidYHxZvsdHR2K1ZvQ29uL1tZWVFRUwGQyYenSpYrUbWpqgsFggMlkgsFgwCeffOLUev7+/igvL7e3pHb0NqaqAM00lYozBQQEwMfHBwDg7e391FOMnKGmpgaJiYmK1ZvQ1NSEsbExpKWlIS8vT7He5i+++CJGRkYAAIODg/D393dqPR8fH+j1evtjR29jqgqQxWKBn58fgPFZIQYHBxWt39nZiXv37iEkJESRelarFa2trYiMjFSk3uP6+vpgtVpRUVEBrVaLhoYGReouX74c7e3t2L59O8xmM8LDwxWpO8HR25iqAjTTVCrONjAwgLy8PBw5ckSxmufPn0dCQoJi9R7n5+eHdevWAQA2bNiAr776SpG6tbW1iI2NxQcffIDNmzejrq5OkboTHL2NqSpAM02l4kw2mw25ubl4++23ERAQoEhNAPj6669RVVWF9PR03Lx5EyaTSbHa4eHh9r/1Ojo6FDuxUwhhP6RavHgxLBaLInUnOHobU1WApk6lYjAYFKlbX1+Pa9eu4ejRo4pOV5mbm4uysjKUlZUhJCQERqNRkboA8Oqrr0Kr1cJoNMJsNuO1115TpG5CQgLq6+thNBpx4cIFp++BrVYr9u7di87OTqSnp8Nmszl0G+OZCEQSVLUHInreMEBEEhggIgkMEJEEBohIAgNEJIEBIpLAABFJYICIJDBARBIYICIJDBCRBAbIDVy+fBmbNm1y9TDmJQbIheLi4tDc3KxozdLSUoSFhdlvBoMBK1aswL179xQdh7tQ3RSP5FwZGRnIyMiwPz5x4gSuXLmC73znOy4c1fOLeyAXyc3Nxe3bt5GRkYGwsDCcPn0aAJCdnY3o6GisXbsWqamp6Orqsj+nsbER8fHxCAsLQ0xMDMrKyqZ97crKSsTHx886C6AQAufOncPOnTsd98bmG0EuExsbKy5dujRpWU1NjbBYLOLhw4ciPz9f7Nixw74uOjpaXLlyRQghxMDAgDCbzUIIIVpaWkRMTIwQQogTJ06IxMRE0dfXN2v91tZWERoaKoaGhv7/9u4/qKk73xv4OyAhXYiBjjwKz1Ddke22/mAw4iogrqDWrlSLXToKNouzrIq7C3qny3Q62xl9FsSdwess1g52XB6B7Eipey+KW+XOlvZRriyydUAbByp42125vaCDZAkSJYHz/IFkASNBv8nJMbxfMxmSc3Ly+UbO2xOSk8/XXU9p2uFLOIVJS0tzXM/JycGyZctgsVig1WoxY8YMdHR04KWXXoJOpxvXrkmSJBw8eBDXrl1DRUUFtFqty1rV1dVYv349goKCPPJcpgO+hFOQoaEhHDp0CGvXroVer0dycjIAoLe3FwBw5MgRXLhwAUlJSXjrrbfG9W6wWCz4+OOPsWvXrimFx2q1ora21is96XwJA6QgZ8+eRV1dHU6cOIErV67gs88+AzBydAGA6OholJSUoKGhAWvXrsXevXsd286cORPHjh3Du+++iytXrris9ec//xkhISFYvny5Z57MNMEAedGsWbNw69Ytx+179+5BrVYjNDQUVqsVhw8fdqwbHBxETU0NLBYLAgICEBQUBD+/8b++5cuX49ChQ8jJyXHZsvb06dN4/fXXoVKp3PukphkGyIt27tyJkpISxMbGorS0FKmpqYiIiEBiYiJSUlIe6Vl25swZJCcnQ6/X46OPPkJRUdEjj5mQkIDCwkJkZ2fj+vXrTut2d3ejsbGRL9/cgG2tiATwCEQkgAEiEsAAEQmQPUB2ux2dnZ2O2cKInmWyB6irqwtr1qxxeZ4W0bPAZYCczTE56saNG0hPT8fWrVvR1tbmsUESKZXLAE2cY3Ks4uJiHD58GMXFxSguLvbIAImUzOXJpIGBgY75Qyfq6+tDeHg4ADidKKmqqgpVVVXjlnl6VmYiOQmdjT08POy47uzz2C1btmDLli3jlnV2dmLNmjUiZYkUQ+hNhLHnUU08L4toOhA6Aul0OnR1dUGlUvE7JTQtuTxsTJxjsqmpCSUlJQBGvvC1d+9e7NmzB3v27PH4YImURvaTSUf/Bqqrq5NtZmgiT+EfLkQCGCAiAQwQkQAGiEgAA0QkgAEiEsAAEQlggIgEMEBEAhggIgEMEJEABohIAANEJIABIhLAABEJYICIBDBARAIYICIBDBCRgCkFqLCwEBkZGSgoKBi3/Pz580hLS8Obb76JTz/91CMDJFIylwG6fv06BgYGcPLkSdhstnFzb5aXl8NoNMJoNKKsrMyT4yRSJJcBamlpQXx8PAAgPj4eLS0tjnWRkZGwWq0YGBhAcHCw50ZJpFAuGytaLBZERkYCALRaLdrb2x3r1q1bh9TUVEiShIMHDz6yLXtjk69zGSCtVov+/n4AQH9/P2bOnOlY98EHH+DcuXMAgB07dmDlypXjtmVvbPJ1Ll/CxcTEoLGxEQDQ0NAwbpoTtVoNjUaD5557DjabzXOjJFIolwFauHAh1Go1MjIy4O/vj/DwcEdr3/T0dMcEWxOPNETTAVv7EgngB6lEAhggIgEMEJEABohIAANEJIABIhLAABEJYICIBDBARAIYICIBDBCRAAaISAADRCSAASISwAARCWCAiAQwQEQCGCAiAQwQkQCXba2Akda+JpMJCxYswHvvvedYbjabsW/fPvT29iIuLg67d+/22ECJlEiote/Ro0eRm5uLiooKhoemJaHWvu3t7fjwww9hMBjQ3NzsuVESKZRQa9/m5mZUV1dDp9MhJycHlZWV47Zla1/ydUKtfefNm4f58+cDAPz8Hj2YsbUv+Tqh1r7z5s3D7du3MTAwgKGhIc+NkkihhFr75ubm4u2330ZmZibfRKBpia19iQTwg1QiAQwQkQAGiEgAA0QkgAEiEsAAEQlggIgETOnrDHKyDwH3HgCDAGwY+TkI4MGE26OXictsTi72KS4DgAAXFzVG/tGcLfN/+HPsxW/Cbf8J1/3H3G/ixf/hT9Uk61UPL09Fwsg/7ANA9QDA/THXRy/3x9923G/w4fbPmIC1gGqp+x5PcQG6sQJY8IW3R0G+6mI2sMqXAzTwf4B60z//dx79H9rZ7YnLJ17G/i/uLhKAYQBDDy8Trz/tRRpzmXjb2WXsfUQMBY5c7IHAkObhzzEXu8b5fYbVgPQM/gGwWuPex1NcgGI3ANjg7VE8ngr/DCiR7AEaPWu7q6tL7tJEUzJnzhzMmDG1aMgeoDt37gAAtm3bJndpoil5khOdZT8b+/79+zCZTAgLC4O/v/MXQtnZ2Th27Jicw5qWdb1ZW8l1FX0E0mg0iI2NnfQ+arXaK191mG51vVnbV+o+g++jECkHA0QkgAEiEuC/f//+/d4ehDOLFi1iXR+v7Qt1ZX8XjsiX8CUckQAGiEgAA0QkQHEBKiwsREZGBgoKCmSrefXqVWzduhXp6ekoLCyUre6osrIypKeny1739OnTyMzMhMFgQHd3tyw1rVYrdu7cCYPBgN27d3u8V3p3dzc2b96MxYsXw263A3DvPqaoAE02lYonRUREoLy8HJWVlejp6cFXX30lS11gpNl+a2urbPVGdXd3o6mpCeXl5TAajZg9e7Ysdevr6xEdHQ2j0Yjo6GhcvHjRo/VCQkJQVlbmaEnt7n1MUQGabCoVTwoLC0NgYCAAICAg4LHn6HnCqVOnkJqaKlu9UfX19RgeHkZmZiby8/Nl623+wgsvwGq1AgD6+voQEhLi0XqBgYHQ6XSO2+7exxQVIIvFguDgYAAjs0L09fXJWr+trQ13795FVFSULPVsNhuampoQFxcnS72xenp6YLPZUF5eDo1Gg7q6Olnqzp07Fy0tLUhJSYHJZIJer5el7ih372OKCtBkU6l4mtlsRn5+Pg4cOCBbzTNnzmDjxo2y1RsrODgYy5YtAwCsWLECN2/elKVudXU1kpKS8Mknn2D16tWoqamRpe4od+9jigrQZFOpeJLdbkdeXh7eeecdhIWFyVITAL7++mtUVlYiKysLHR0dMBqNstXW6/WOv/VaW1tlOzNakiTHS6rQ0FBYLBZZ6o5y9z6mqABNnEolOjpalrq1tbX48ssvUVRUJOt0lXl5eSgtLUVpaSmioqJgMBhkqQsAL7/8MjQaDQwGA0wmE9avXy9L3Y0bN6K2thYGgwFnz571+BHYZrNh+/btaGtrQ1ZWFux2u1v3MZ7KQyRAUUcgomcNA0QkgAEiEsAAEQlggIgEMEBEAhggIgEMEJEABohIAANEJIABIhLAAPmAy5cvY9WqVd4exrTEAHlRcnIyGhoaZK9rNBqRnJwMvV6PN954A198wTk1nxYDNM1cvXoV//qv/4ojR47gypUrSEtLwy9/+UvZvtLtaxggL8nLy8O3336L7OxsLFmyBMePHwcA5ObmIiEhAUuXLsW2bdvQ3t7u2ObChQvYsGEDlixZgsTERJSWljp97IqKCmzYsMHpLID//d//jaioKCxatAgqlQqpqano7e1FT0+PZ56or5PIa5KSkqRLly6NW3bq1CnJYrFIDx48kAoKCqRNmzY51iUkJEh//etfJUmSJLPZLJlMJkmSJKmxsVFKTEyUJEmS3n//fSk1NVXq6elxWtNisUibN2+WWlpaJLvdLlVUVEivv/66NDw87Imn6PMUN8nwdJeWlua4npOTg2XLlsFisUCr1WLGjBno6OjASy+9BJ1ON67bjCRJOHjwIK5du4aKigpotVqnjx8UFIRXXnkFGRkZkCQJWq0Wx48fh0ql8vhz80V8CacgQ0NDOHToENauXQu9Xo/k5GQAQG9vLwDgyJEjuHDhApKSkvDWW2+N++q5xWLBxx9/jF27dj02PADwxz/+Ef/+7/+OP/3pTzCZTCgqKkJ2drZsjRV9DQOkIGfPnkVdXR1OnDiBK1eu4LPPPgMwcnQBgOjoaJSUlKChoQFr167F3r17HdvOnDkTx44dw7vvvosrV648tkZraytWr16N7373u/Dz88OqVasQFhYmWx8IX8MAedGsWbNw69Ytx+179+5BrVYjNDQUVqsVhw8fdqwbHBxETU0NLBYLAgICEBQUBD+/8b++5cuX49ChQ8jJyXlsx83FixfjwoULuHXrFiRJwqVLl/DNN9/ge9/7nmeepK/z7p9g09uf//xn6Yc//KG0dOlS6fe//73U398vZWdnSzExMdLq1aul6upq6cUXX5S++eYb6cGDB9JPf/pTKTY2VlqyZIn0xhtvON5QGPsmgiRJ0ueffy7FxcU53mQYa3h4WPrd734n/fCHP5RiYmKkV199VaqurpbtOfsaduUhEsCXcEQCGCAiAQwQkQAGiEiA7AGy2+3o7Ox0zBZG9CxzGSBnU+SNunHjBtLT07F161a0tbVNqWBXVxfWrFnj9ERHomeNywBNnCJvrOLiYhw+fBjFxcUoLi72yACJlMzlyaSBgYGO6Q8n6uvrQ3h4OADIPs8LkRIInY09PDzsuO7s89iqqipUVVWNW+bpWZmJ5CQUoLGnwE88LwsAtmzZgi1btoxb1tnZiTVr1oiUJVIMoQDpdDp0dXVBpVIhKCjIXWMiema4fBNh4hR5TU1NKCkpATDyha+9e/diz5492LNnj8cHS6Q0sp9MOvoSrq6uTraJbYk8hWciEAlggIgEMEBEAhggIgEMEJEABohIAANEJIABIhLAABEJYICIBDBARAIYICIBDBCRAAaISAADRCSAASISwAARCWCAiAQwQEQCphSgwsJCZGRkoKCgYNzy8+fPIy0tDW+++SY+/fRTjwyQSMlcBuj69esYGBjAyZMnYbPZxs29WV5eDqPRCKPRiLKyMk+Ok0iRXAaopaUF8fHxAID4+Hi0tLQ41kVGRsJqtWJgYADBwcGeGyWRQrlsrGixWBAZGQkA0Gq1aG9vd6xbt24dUlNTIUkSDh48+Mi2bO1Lvs5lgLRaLfr7+wEA/f39mDlzpmPdBx98gHPnzgEAduzYgZUrV47blq19yde5fAkXExODxsZGAEBDQ8O4aU7UajU0Gg2ee+452Gw2z42SSKFcBmjhwoVQq9XIyMiAv78/wsPDHa1909PTHRNsTTzSEE0HbO1LJIAfpBIJYICIBDBARAIYICIBDBCRAAaISAADRCSAASISwAARCWCAiAQwQEQCGCAiAQwQkQAGiEgAA0QkgAEiEsAAEQlggIgEMEBEAhggIgEu+8IBI72xTSYTFixYgPfee8+x3Gw2Y9++fejt7UVcXBx2797tsYESKZFQb+yjR48iNzcXFRUVDA9NS0K9sdvb2/Hhhx/CYDCgubnZc6MkUiih3tjNzc2orq6GTqdDTk4OKisrx23L3tjk64R6Y8+bNw/z588HAPj5PXowY29s8nVCvbHnzZuH27dvY2BgAENDQ54bJZFCCfXGzs3Nxdtvv43MzEy+iUDTEntjEwngB6lEAhggIgEMEJEABohIAANEJIABIhLAABEJmNLXGeR04XeA/8PzUlVjlju7PvGnK7J+4OXjxv5bSqqRy5Ncn/Ivzc00m4D4H7nv8RQXoIDLQOTImUMud3h3BcJLv0sHSQFjeFoqaeTyNNe9ofV/AfDlAMVXur4P0dNKdPPj8W8gIgGyH4FGz9ru6uqSuzTRlMyZMwczZkwtGrIH6M6dOwCAbdu2yV2aaEqe5ERn2c/Gvn//PkwmE8LCwuDv7+/0PtnZ2Th27Jicw5qWdb1ZW8l1FX0E0mg0iI2NnfQ+arXaK191mG51vVnbV+ryTQQiAQwQkQAGiEiA//79+/d7exDOLFq0iHV9vLYv1JX9XTgiX8KXcEQCGCAiAYoLUGFhITIyMlBQUCBbzatXr2Lr1q1IT09HYWGhbHVHlZWVIT09Xfa6p0+fRmZmJgwGA7q7u2WpabVasXPnThgMBuzevdvjrZ67u7uxefNmLF68GHa7HYB79zFFBWiymSA8KSIiAuXl5aisrERPTw+++uorWeoCI73CW1tbZas3qru7G01NTSgvL4fRaMTs2bNlqVtfX4/o6GgYjUZER0fj4sWLHq0XEhKCsrIyR0ddd+9jigrQZDNBeFJYWBgCAwMBAAEBAY89xcgTTp06hdTUVNnqjaqvr8fw8DAyMzORn58vW2vmF154AVarFQDQ19eHkJAQj9YLDAyETqdz3Hb3PqaoAFksFgQHBwMYaWrf19cna/22tjbcvXsXUVFRstSz2WxoampCXFycLPXG6unpgc1mQ3l5OTQaDerq6mSpO3fuXLS0tCAlJQUmkwl6vV6WuqPcvY8pKkCTzQThaWazGfn5+Thw4IBsNc+cOYONGzfKVm+s4OBgLFu2DACwYsUK3Lx5U5a61dXVSEpKwieffILVq1ejpqZGlrqj3L2PKSpAk80E4Ul2ux15eXl45513EBYWJktNAPj6669RWVmJrKwsdHR0wGg0ylZbr9c7/tZrbW2V7cROSZIcL6lCQ0NhsVhkqTvK3fuYogI0cSaI6OhoWerW1tbiyy+/RFFRkayz7eXl5aG0tBSlpaWIioqCwWCQpS4AvPzyy9BoNDAYDDCZTFi/fr0sdTdu3Ija2loYDAacPXvW40dgm82G7du3o62tDVlZWbDb7W7dx3gmApEARR2BiJ41DBCRAAaISAADRCSAASISwAARCWCAiAQwQEQCGCAiAQwQkQAGiEgAA0QkgAHyAZcvX8aqVau8PYxpiQHyouTkZDQ0NMhaU5IklJSUYPXq1dDr9fiXf/kXxxfM6MkxQNPM6dOncebMGVRWVqK+vh73799Hfn6+t4f1zGKAvCQvLw/ffvstsrOzsWTJEhw/fhwAkJubi4SEBCxduhTbtm1De3u7Y5sLFy5gw4YNWLJkCRITE1FaWur0sSsqKrBhwwanswB+/vnnSEtLQ3h4OIKCgrBjxw6cO3fO0eiDngwD5CVFRUWIiIjAsWPH0NzcjB07dgAAVq1ahf/4j//AX/7yFyxYsAC/+tWvHNv8+te/xm9+8xs0NzfjT3/6E1asWPHI4x49ehTV1dX4wx/+gDlz5jitPfY7lJIkYXBwEH/729/c/AynBwZIYdLS0hAcHAy1Wo2cnBy0tbU5+gbMmDEDHR0d6O/vh06nw8KFCx3bSZKEgwcP4tKlS6ioqMDzzz/v9PETExPxxz/+EZ2dnbBYLI4jH49AT4cBUpChoSEcOnQIa9euhV6vR3JyMgCgt7cXAHDkyBFcuHABSUlJeOutt8b1brBYLPj444+xa9cuaLXax9b48Y9/jJSUFPzkJz9BSkqK4yj2uKMVuSCR1yQlJUmXLl1y3K6urpZeffVV6e9//7s0PDws/eMf/5BefPFF6Ztvvhm33eDgoHTixAlp1apVkiRJUmNjo5SYmCg1NjZKK1askL744ospj6G+vl5KTEyUhoaG3POkphkegbxo1qxZuHXrluP2vXv3oFarERoaCqvVisOHDzvWDQ4OoqamBhaLBQEBAQgKCoKf3/hf3/Lly3Ho0CHk5OQ8tmWt2WzG3//+d0iShI6ODvz2t7/FL37xi0cei6aG/2petHPnTpSUlCA2NhalpaVITU1FREQEEhMTkZKS8kjPsjNnziA5ORl6vR4fffQRioqKHnnMhIQEFBYWIjs7G9evX39kfW9vL3bs2IGYmBjs2LEDP/7xj7FlyxaPPUdfx7ZWRAJ4BCISwAARCWCAiATIHiC73Y7Ozk7HbGFEzzLZA9TV1YU1a9Y4PU+L6FnjMkDO5pgcdePGDaSnp2Pr1q1oa2vz2CCJlMplgCbOMTlWcXExDh8+jOLiYhQXF3tkgERKNsPVHQIDAx3zh07U19eH8PBwAJB9oiQiJXAZoMkMDw87rjv7PLaqqgpVVVXjlnl6WnMiOQkFSKVSOa47O5dqy5Ytj5wm0tnZiTVr1oiUJVIMoQDpdDp0dXVBpVIhKCjIXWMiema4fBNh4hyTTU1NKCkpAQDk5ORg79692LNnD/bs2ePxwRIpjewnk46+hKurq5NtZmgiT+GpPEQCGCAiAQwQkQAGiEgAA0QkgAEiEsAAEQlggIgEMEBEAhggIgEMEJEABohIAANEJIABIhLAABEJYICIBDBARAIYICIBDBCRgCkFqLCwEBkZGSgoKBi3/Pz580hLS8Obb76JTz/91CMDJFIylwG6fv06BgYGcPLkSdhstnFzb5aXl8NoNMJoNKKsrMyT4yRSJJcBamlpQXx8PAAgPj4eLS0tjnWRkZGwWq0YGBhAcHCw50ZJpFAuGytaLBZERkYCALRaLdrb2x3r1q1bh9TUVEiShIMHDz6yLVv7kq9zGSCtVov+/n4AQH9/P2bOnOlY98EHH+DcuXMAgB07dmDlypXjtmVrX/J1Ll/CxcTEoLGxEQDQ0NAwbpoTtVoNjUaD5557DjabzXOjJFIolwFauHAh1Go1MjIy4O/vj/DwcEdr3/T0dMcEWxOPNETTAVv7EgngB6lEAhggIgEMEJEABohIAANEJIABIhLAABEJYICIBDBARAIYICIBDBCRAAaISAADRCSAASISwAARCWCAiAQwQEQCGCAiAQwQkQCXba2Akda+JpMJCxYswHvvvedYbjabsW/fPvT29iIuLg67d+/22ECJlEiote/Ro0eRm5uLiooKhoemJaHWvu3t7fjwww9hMBjQ3NzsuVESKZRQa9/m5mZUV1dDp9MhJycHlZWV47Zla1/ydUKtfefNm4f58+cDAPz8Hj2YsbUv+Tqh1r7z5s3D7du3MTAwgKGhIc+NkkihhFr75ubm4u2330ZmZibfRKBpia19iQTwg1QiAQwQkQAGiEgAA0QkgAEiEsAAEQlggIgETOnrDLLqA3Db9d2GANicXIYn3E/WD7lIiKRystDNyyIiAHXAk41rMooL0P8sB8LbXN/P/+FF4+kBkU+pNwCJFe57PMUFqOYPwEDryMBmYCQkzn4+bp2z16RT/Q+LvMjZSwUny1RTvN/jXnp8d+UTaffVAAAAD51JREFUjGkKFBegXUsBLPX2KIimhm8iEAmQ/Qg0+rWHrq4uuUsTTcmcOXMwY8bUoiF7gO7cuQMA2LZtm9yliabkSb4pIPvXGe7fvw+TyYSwsDD4+/s7vU92djaOHTsm57CmZV1v1lZyXUUfgTQaDWJjYye9j1qt9sp3haZbXW/W9pW6fBOBSAADRCSAASIS4L9///793h6EM4sWLWJdH6/tC3VlfxeOyJfwJRyRAAaISIDiAlRYWIiMjAwUFBTIVvPq1avYunUr0tPTUVhYKFvdUWVlZUhPT5e97unTp5GZmQmDwYDu7m5ZalqtVuzcuRMGgwG7d+/2eK/07u5ubN68GYsXL4bdbgfg3n1MUQGabCoVT4qIiEB5eTkqKyvR09ODr776Spa6wEiz/dbWVtnqjeru7kZTUxPKy8thNBoxe/ZsWerW19cjOjoaRqMR0dHRuHjxokfrhYSEoKyszNGS2t37mKICNNlUKp4UFhaGwMBAAEBAQMBjTzHyhFOnTiE1NVW2eqPq6+sxPDyMzMxM5Ofny9bb/IUXXoDVagUA9PX1ISQkxKP1AgMDodPpHLfdvY8pKkAWiwXBwcEARmaF6Ovrk7V+W1sb7t69i6ioKFnq2Ww2NDU1IS4uTpZ6Y/X09MBms6G8vBwajQZ1dXWy1J07dy5aWlqQkpICk8kEvV4vS91R7t7HFBWgyaZS8TSz2Yz8/HwcOHBAtppnzpzBxo0bZas3VnBwMJYtWwYAWLFiBW7evClL3erqaiQlJeGTTz7B6tWrUVNTI0vdUe7exxQVoMmmUvEku92OvLw8vPPOOwgLC5OlJgB8/fXXqKysRFZWFjo6OmA0GmWrrdfrHX/rtba2ynZipyRJjpdUoaGhsFgsstQd5e59TFEBmjiVSnR0tCx1a2tr8eWXX6KoqEjW6Srz8vJQWlqK0tJSREVFwWAwyFIXAF5++WVoNBoYDAaYTCasX79elrobN25EbW0tDAYDzp496/EjsM1mw/bt29HW1oasrCzY7Xa37mM8E4FIgKKOQETPGgaISAADRCSAASISwAARCWCAiAQwQEQCGCAiAQwQkQAGiEgAA0QkgAEiEsAAPYMuX76MVatWeXsYBAZIVsnJyWhoaJC15u3bt5GdnY2VK1fi+9//Pjo7O8etHxwcxLvvvgu9Xo+EhAScOHFC1vE96xggH+fn54fExES8//77Tte///77+Nvf/obPP/8cFRUV+P3vf+/xRh++hAGSSV5eHr799ltkZ2djyZIlOH78OAAgNzcXCQkJWLp0KbZt24b29nbHNhcuXMCGDRuwZMkSJCYmorS01OljV1RUYMOGDU5n/Zs1axa2bduGxYsXO922uroaP//5z6HT6TB//ny8+eabqK6udsMzniYkkk1SUpJ06dKlcctOnTolWSwW6cGDB1JBQYG0adMmx7qEhATpr3/9qyRJkmQ2myWTySRJkiQ1NjZKiYmJkiRJ0vvvvy+lpqZKPT09k9a22WzSiy++KN26dcuxzGw2Sy+++KJ0584dx7Lz589Lr732mtgTnUYUN0v3dJOWlua4npOTg2XLlsFisUCr1WLGjBno6OjASy+9BJ1ON649kyRJOHjwIK5du4aKigpotdonrj0wMAAA47bVarW4d++ewDOaXvgSzouGhoZw6NAhrF27Fnq9HsnJyQCA3t5eAMCRI0dw4cIFJCUl4a233hrXq8FiseDjjz/Grl27nio8APCd73wHABxdakavBwUFPe1TmnYYIC86e/Ys6urqcOLECVy5cgWfffYZgJGjCwBER0ejpKQEDQ0NWLt2Lfbu3evYdubMmTh27BjeffddXLly5anq63Q6hIWFoa2tzbGsra1Ntr54voABktGsWbNw69Ytx+179+5BrVYjNDQUVqsVhw8fdqwbHBxETU0NLBYLAgICEBQUBD+/8b+u5cuX49ChQ8jJyZm0Re2DBw8cPagHBwfx4MEDx7rU1FSUlJTgH//4B27evIlTp05h8+bN7nrKPo8BktHOnTtRUlKC2NhYlJaWIjU1FREREUhMTERKSsojPcrOnDmD5ORk6PV6fPTRRygqKnrkMRMSElBYWIjs7Gxcv37dad3o6GgsWbIEAPCjH/1oXCun3NxcREZGIikpCQaDAVlZWfyQ9gmwrRWRAB6BiAQwQEQCGCAiAbIHyG63o7Oz0zFbGNGzTPYAdXV1Yc2aNU7P2yJ61rgMkLM5JkfduHED6enp2Lp167gP44imC5cBmjjH5FjFxcU4fPgwiouLUVxc7JEBEimZy5NJAwMDHfOHTtTX14fw8HAAcDpRUlVVFaqqqsYt8/SszERyEjobe3h42HHd2eexW7ZswZYtW8Yt6+zsxJo1a0TKEimG0JsIKpXqnw/kx3fEafoROgLpdDp0dXVBpVLxFHiallweNibOMdnU1ISSkhIAI18A27t3L/bs2YM9e/Z4fLBESiP7yaSjfwPV1dXJNjM0kafwDxciAQwQ+Zzq6mq88soreOWVVzzeYYhNRcinmM1mHD16FP/2b/8GlUqFN954A8nJyeMasrgTA0QuVQD4v25+zJ8C+MkU7nf69GmUlpZCpVLh+9//vtNv5Y71n//5n0hISEBISAiAkW/s1tfX47XXXhMftBMMEClWe3s7SkpKUFlZieeffx5msxk1NTVOG0zOnTsXR44cQXd3N+bMmeNYPnv2bHR3d3tsjAwQufQTTO1o4W6NjY149dVX8fzzzwMYOS9z06ZN2LRpkxdG4xwDRM8UV0eg2bNno6mpybG8u7sbP/jBDzw3ILlbod66deuRFrNEzty4cUN65ZVXpLt370qSJEm9vb0ut+nt7ZWSkpIks9ksmc1mKSkpaUrbPS0egUixvve97yE7OxsGgwF+fn5YsGABfvvb3066TUhICH7+8587Wib/4he/cLyh4Ak8E4FIAD9IJRLAABEJYICIBDBARAIYICIBDBCRAAaIfE5WVhZiY2Oxa9cuj9fiB6nkc372s5/BarU+0lLNExggcs2L32d40q8zAEBcXBwuX74sPsYpmFKACgsLYTKZsGDBArz33nuO5efPn3c8uV27dmHt2rUeGyhNP0/zdQa5uQzQ9evXMTAwgJMnT2Lfvn24du2aY4rA8vJyGI1GqFQq/OxnP2OAfJWXvs/gE19naGlpQXx8PAAgPj4eLS0tjgBFRkbCarUCAIKDgz04TKIRz9wRyGKxIDIyEgCg1WrR3t7uWLdu3TqkpqZCkiQcPHjwkW3ZG5tErFixAr/85S+xfft2hIaGwmw2P3tHIK1Wi/7+fgBAf38/Zs6c6Vj3wQcf4Ny5cwCAHTt2YOXKleO2ZW9sEvE0X2cAgIyMDPzXf/0XBgYGsGrVKhw4cACJiYkeGaPLAMXExKCqqgobNmxAQ0MD3njjDcc6tVoNjUYDlUoFm83mkQHS9LZ582Zs3rz5ibY5efKkh0bzKJcfpC5cuBBqtRoZGRnw9/dHeHi4o7Vvenq6Y4KtiUcaoumAX6gjEsBTeYgEMEBEAhggIgEMEJEABohIAANEJIABIhLAABEJYICIBDBARAIYICIBDBCRAAaISAADRCSAASISwAARCWCAiAQwQEQCGCAiAUKtfc1mM/bt24fe3l7ExcVh9+7dHhsokRK5PAKNbe1rs9lw7do1x7qjR48iNzcXFRUVDA9NSy4D5Ky176j29nZ8+OGHMBgMaG5u9twoiRRKqLVvc3MzqqurodPpkJOTg8rKynHbsrUv+Tqh1r7z5s3D/PnzAQB+fo8ezNjal3ydy5dwMTExaGxsBAA0NDQgJibGsW7evHm4ffs2BgYGMDQ05LlREimUUGvf3NxcvP3228jMzOSbCDQtsbUvkQB+kEokQHGTDF88DkhXn3JjafxVaeJiafyyR9YDUD3tRRr/GGOpJhzjJ65/LCd3lJxtrHrM+iksH1k5ZoxTvC7K6fN4As6eztjfw+PWa18H5qWI1R5LcQHS1ADz//L024/+Yh73+3G13nG/p1g22U7xpDvMxNBNZdnTXB8dl6R68utPy9nzeJJtXdWebP0X/9vHA/SDs94egTykCdcF/0P2Cm+NWXJxGZ5k3WtuHoviAjRdTPaKiiY3+rJZCfgmApEABohIgOJewv2//cB3rnh7FKRUKmnk5dsMAAES4P/w+gxp5Kf/xOsPb/tj5GihSgeQ6b7xKC5Aft2A9ltvj4KUbEg18kbB4MPrjnfXH/e2/cPbKgD/0w+kunEsigvQqhJvj4CeNQ8AWAD0P/w52fV1bq6tuAARPanAh5dZXqgte4BGz9ru6uqSuzTRlMyZMwczZkwtGrIH6M6dOwCAbdu2yV2aaEqe5ERn2c/Gvn//PkwmE8LCwuDv7+/0PtnZ2Th27Jicw5qWdb1ZW8l1FX0E0mg0iI2NnfQ+arXaK191mG51vVnbV+ryg1QiAQwQkQAGiEiA//79+/d7exDOLFq0iHV9vLYv1JX9XTgiX8KXcEQCGCAiAYoLUGFhITIyMlBQUCBbzatXr2Lr1q1IT09HYWGhbHVHlZWVIT09Xfa6p0+fRmZmJgwGA7q7u2WpabVasXPnThgMBuzevdvjrZ67u7uxefNmLF68GHa7HYB79zFFBWiymSA8KSIiAuXl5aisrERPTw+++uorWeoCI73CW1tbZas3qru7G01NTSgvL4fRaMTs2bNlqVtfX4/o6GgYjUZER0fj4sWLHq0XEhKCsrIyR0ddd+9jigrQZDNBeFJYWBgCAwMBAAEBAY89xcgTTp06hdRUd35DZWrq6+sxPDyMzMxM5Ofny9aa+YUXXoDVagUA9PX1ISQkxKP1AgMDodPpHLfdvY8pKkAWiwXBwcEARpra9/X1yVq/ra0Nd+/eRVRUlCz1bDYbmpqaEBcXJ0u9sXp6emCz2VBeXg6NRoO6ujpZ6s6dOxctLS1ISUmByWSCXq+Xpe4od+9jigrQZDNBeJrZbEZ+fj4OHDggW80zZ85g48aNstUbKzg4GMuWLQMArFixAjdv3pSlbnV1NZKSkvDJJ59g9erVqKmpkaXuKHfvY4oK0GQzQXiS3W5HXl4e3nnnHYSFhclSEwC+/vprVFZWIisrCx0dHTAajbLV1uv1jr/1WltbZTuxU5Ikx0uq0NBQWCwWWeqOcvc+pqgATZwJIjo6Wpa6tbW1+PLLL1FUVCTrbHt5eXkoLS1FaWkpoqKiYDAYZKkLAC+//DI0Gg0MBgNMJhPWr18vS92NGzeitrYWBoMBZ8+e9fgR2GazYfv27Whra0NWVhbsdrtb9zGeiUAkQFFHIKJnDQNEJIABIhLAABEJYICIBDBARAIYICIBDBCRgP8PXwMuKsXtET8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x1440 with 11 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(3, 20))\n",
    "axs = [subplot(n_tasks+1,1,1)]#, None, None]\n",
    "for i in range(1, n_tasks):\n",
    "    axs.append(subplot(n_tasks+1,1, i+1, sharex=axs[0], sharey=axs[0]))\n",
    "    \n",
    "keys = list(data['mean'].keys())\n",
    "sorted_keys = np.sort(keys)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "        colorVal = scalarMap.to_rgba(np.log(cval))\n",
    "        # axs[j].plot(evals[:, j], c=colorVal)\n",
    "        axs[j].errorbar(range(n_tasks), mean_vals[:, j], yerr=std_vals[:, j]/np.sqrt(n_stats), c=colorVal)\n",
    "        axs[j].set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "    label = \"c=%g\"%cval\n",
    "    average = mean_vals.mean(1)  #Taking the average of cross validation accuracies accross all tasks after learning each task\n",
    "    axs[-1].plot(average, c=colorVal, label=label)\n",
    "    \n",
    "for i, ax in enumerate(axs):\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_title((['task %d'%j for j in range(n_tasks)] + ['average'])[i])\n",
    "gcf().tight_layout()\n",
    "sns.despine()\n",
    "plt.savefig('2Attack_Accuracy_10task.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50007633 0.49992367 0.49992367 0.49992367 0.49992367 0.49992367\n",
      " 0.49992367 0.49992367 0.49992367 0.49992367 0.49992367] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50022699 0.50007566 0.50022699 0.50022699 0.50022699 0.50022699\n",
      " 0.50022699 0.50022699 0.50022699 0.50022699 0.50022699] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50290188 0.50290188 0.50290188 0.49764222 0.49667493 0.49709812\n",
      " 0.49709812 0.49709812 0.49709812 0.49709812 0.49709812] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.5015829  0.49968342 0.49965327 0.49965327 0.50055778 0.50034673\n",
      " 0.50034673 0.50034673 0.50034673 0.50034673 0.50034673] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.49968071 0.49943743 0.50311692 0.49876844 0.49873803 0.49968071\n",
      " 0.49968071 0.49968071 0.49968071 0.49968071 0.49968071] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50089224 0.49871458 0.49910776 0.49910776 0.49910776 0.49910776\n",
      " 0.49910776 0.49910776 0.49910776 0.49910776 0.49910776] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.49842782 0.50108374 0.50325121 0.50099215 0.49934365 0.49842782\n",
      " 0.49842782 0.49842782 0.49842782 0.49842782 0.49842782] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50013707 0.49968018 0.49986293 0.49986293 0.49983248 0.49986293\n",
      " 0.49986293 0.49986293 0.50013707 0.50013707 0.50013707] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.49873043 0.50117889 0.50126957 0.50126957 0.50126957 0.50126957\n",
      " 0.50126957 0.50126957 0.50126957 0.50126957 0.50126957] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50274437 0.50274437 0.50274437 0.50274437 0.50274437 0.50274437\n",
      " 0.50274437 0.50274437 0.50274437 0.50274437 0.49725563] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.49992367 0.49992367 0.49992367 0.49992367 0.49992367 0.49992367\n",
      " 0.49992367 0.49992367 0.49992367 0.49992367 0.49992367] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.49977301 0.49977301 0.50022699 0.50022699 0.50022699 0.50022699\n",
      " 0.50022699 0.50022699 0.50022699 0.50022699 0.50022699] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50290188 0.50290188 0.50290188 0.50290188 0.50290188 0.50290188\n",
      " 0.50290188 0.50290188 0.50290188 0.50290188 0.50290188] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.49965327 0.49965327 0.49965327 0.49965327 0.50034673 0.50034673\n",
      " 0.50034673 0.50034673 0.50034673 0.50034673 0.50034673] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.49968071 0.49968071 0.49968071 0.49968071 0.49968071 0.49885966\n",
      " 0.49895089 0.49882925 0.49895089 0.49879884 0.49940702] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50089224 0.50089224 0.50089224 0.50089224 0.50089224 0.50089224\n",
      " 0.49910776 0.49910776 0.49910776 0.49910776 0.49910776] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.49842782 0.49842782 0.49842782 0.49842782 0.49842782 0.49842782\n",
      " 0.49842782 0.50157218 0.50157218 0.50157218 0.50157218] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50013707 0.50013707 0.50013707 0.50013707 0.50013707 0.50013707\n",
      " 0.50013707 0.50013707 0.49986293 0.49986293 0.49986293] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50126957 0.50126957 0.50126957 0.50126957 0.50126957 0.50126957\n",
      " 0.50126957 0.50126957 0.50126957 0.50117889 0.50108821] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0.50274437 0.50274437 0.50274437 0.50274437 0.50274437 0.50274437\n",
      " 0.50274437 0.50274437 0.50274437 0.50274437 0.50286434] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for cval in sorted_keys:\n",
    "    mean_vals = data['mean'][cval]\n",
    "    std_vals = data['std'][cval]\n",
    "    for j in range(n_tasks):\n",
    "       print(mean_vals[:, j],std_vals[:, j]/np.sqrt(n_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=False)\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "\n",
    "def simple_axis(ax):\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO8AAAC7CAYAAACNb8lYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAH09JREFUeJzt3XtcVHX+x/HXGWAABbkoCCKiS94vC4Kmtu1W7rpZyVpqioZSbpZ3y8tqUvr72Zqu2Yr2y7RaLxjeMl3NtE2tNvOCqUioeEsRVC4idwa5nd8fxCRymUEZZkY+z8eDR8w5M+d8MN6c7znn+z1fRVVVFSGE1dGYuwAhxL2R8AphpSS8QlgpCa8QVkrCK4SVkvAKYaUkvEJYKQmvEFZKwiuElZLwCmGlrCK8JSUlJCcnU1JSYu5ShLAYVhHelJQU+vfvT0pKirlLEcJimCS8qampPPvss3Tv3r3K0fL8+fOEhoYyYsQIEhIS6n3fx3auImX+Q5TNcyFl/kMc27mq3vchhCUwSXhdXV1Zu3YtAQEBVdZFRkby3nvvERkZSWRkZL3u99jOVXQ7HoEX6WgU8CKdbscjJMDigWRrio3a29tjb29f7bqcnBy8vb0ByM3NrdN2R4wYga3tryU///zzTJgwgYKCAp566ik+/X0ijpqiSp9xVIpofeIfPPbexirbGz9+PMOHDycpKYmwsLAq66dPn86gQYM4d+4cr7zySpX1ERER/PGPfyQ2NpZp06ZVWb9w4UL69evHoUOHeOONN6qsX7ZsGQEBAezbt4+33367yvpVq1bRsWNHdu3axdKlS6usj4qKwtfXl82bN7Ny5coq6z/77DNatGjB2rVrWbt2bZX1X375JU2aNOGDDz5gy5YtVdZ/++23ALz77rt88cUXldY5OjqyZ88eABYsWMD+/fsrrW/evDnbtm0DYM6cORw+fLjS+tatW7NhwwYApk2bRmxsbKX1HTp0YPXq1QCMGzeO8+fPV1ofEBDAsmXLAHjhhRdITk6utL5v37688847AAwZMoSMjIxK6/v378+bb74JwMCBA9HpdJXWP/PMM8yYMQOAxx57jLvd/bt3t/DwcMLDw7l58yZDhw6tsv7u372Kf+u6MEl4a1NWVqb/vrqhxJs3b2bz5s2VlhUVFVV5X3W8lVvVLm+pZgC+xhcphBVQTDkYPywsjDVr1lQ6Wr7wwgv6v7hhYWFERUUZ3E5ycjL9+/dn//79tG7dusb3pcx/CC/Sqy7HA6/5F+/hJxDCcjX41WYXFxdSUlJITU2ladOm9brtpJ4z0anaSstuq3Yk9ZxZr/sRwhKYJLzFxcWEh4eTkJDA2LFjiYmJ0Z+TTZ48mWnTpjF16lSmTp1ar/vtFfIK8UFvk4IHZSqUqBrSFTeCnv5rve5HCEtg0mZzfTG22Xy3Yzv+j16xb/Bj8BKCnxlnwgqFaHhW0UnjXgUNepVLNr/B58d/UKjLN3c5woSGrzrM8FWHDb/xAfJAh1djY4Pu8f/Bm3RiP1ts7nJEI7B9+3YGDBjAgAED2L59u0n39UCHF6Db70KIdexDl0sfkZl+w9zlCBPYcfIaJ69mcfTyLR5ZdIAdJ6+ZpY6srCzef/99tmzZwtatW3n//ffJzs422f4e+PACuP3lHZqohZzfEmHuUkQ923HyGnM+/4mi0vL+A9eydMz5/Kd6CfCOHTsYNGgQISEhzJxp+I7FwYMHeeSRR3B1dcXFxYVHHnmE77///r7rqEmDd9IwB79OPTnaIoSeadtJujAF3/a/NXdJwkjbjiez5cekGtefvJqlD24FXXEpsz6LY2PM1Wo/83ywL0OCar/weeHCBVauXMnGjRtxd3cnKyuLnTt38sknn1R5r5+fH8uXLyc1NRUvLy/98pYtW5Kamlrrfu5HowgvgP+wtylauZebO97Ad+Zuc5cj6sndwTW03FhHjhzhySefxN3dHSjvrx8SEkJISMh9bbc+NZrwtvDy5XC7F+l7ZSVnjuylS58nzV2SMMKQoNa1HiUfWXSAa1m6Kst9XB3Z/Erfeq3F0JG3ZcuWxMTE6JenpqbSu3fveq3hTg/0fd676fJzyVnyW7Jtm/PQnCNobGzqsUphDhXnvLriUv0yRzsb3nmuO4MDfe55uxcuXGDSpEls2rQJNzc3srKycHV1rfUzWVlZPPfcc/qrzM8++yyff/65wc/dq0ZxwaqCY1NnrgZMp0PJeU7sqfoXVFifwYE+vPNcd7Q25b/KPq6O9x1cgPbt2/Pqq68SFhZGSEgIixYtMvgZV1dXJkyYwNChQxk6dCgTJ040WXChkR15AcpKS7m8MJgmpbm4/e0UDo71279amEdFB436bipbskZ15AXpuPGg2vxK30YVXGiE4YXyjhunHB+WjhvCqjXK8AK4hkjHDWHdGm14/ToHcVzfceOUucsRos4abXjhl44b2HFzR9XnSwlh6Rp1eFt4+RLX7kUC8w9y5shec5cj7seap8u/GpFGHV6AgGFzScMd231vUlZaavgDQtRi7NixBAcHV/u00frW6MPr2NSZROm4Yd3itkDyMUg8CP/sVv7aTP7617/yj3/8o0H21ejDCxA0aLw8ccNaxW2BXVOg9Hb56+yk8tf1EOC6DgmE8udF1/eDFWvSaAYm1Kai44b/vjCOfLaYPmH/a+6SRIXYjXByQ83rk4/9GtwKxTr49yQ4vq76zwS+AAGhte72XoYENjQJ7y+6/S6EUz9UdNwYj5uHt7lLEsa4O7iGlhtJhgRaGdeQd2i6qT/HtrxJn4kfm7scAeVHyNqOkv/sVt5UvpuLL7xYv+O25chrwfw6B3G0RQhBaZ+TdGGyPHHDGvR/q/wct/iOMb12juXL70OfPn2YNGkS4eHh+iGBlnbklQtWd/Ef9nfpuGFNejwPg5aDzS8T27n4lr/u8fx9bfZehgQCjBw5kqlTp3L48GF+//vfm/QZVo1uSKAxDq+dXf7EjSc3yxM3rEVFB416bipbMpMdeRcuXMjIkSOrTF25Z88ehg4dyrBhw9i3b5+pdn9fpOOGFXpxd6MKLpgovKdPn6agoIDo6GiKi4uJi4vTr1u3bh1RUVFERUVVO2esJZCOG8IamCS8sbGx9OvXD4B+/fpVmjjZ19cXnU5HQUEBTk5Opth9vej5jEyVIiybSa425+bm4utbPpm1s7MzFy5c0K/705/+xODBg1FVVT9z+Z3uZ3Lt+mRja4vusfn47x8tHTeEZVINCA8Pr/T6tddeM/QRdcOGDeru3btVVVXVr776Sl23bp1+XUhIiJqbm6vm5uaqI0aMMLgtVVXVpKQktUOHDmpSUpJR769PsYv+qGbP81JvpV1v8H0LUZsaj7xHjhzhyJEjJCYmEhkZCUBpaSlpaWkG/yAEBASwefNmnnrqKQ4dOsRzzz2nX6fVanFwcEBRFIqLi+vhz49puYYsko4bwiLVGF5fX180Gg1JSUn07Vv+YC9bW1vGjTM8z23Xrl3RarWMHDmSzp074+3tzcqVKxk/fjyhoaGEhpb3mBk+fHg9/RimIx03hKUyeJ93z549DBw4EABVVdm7d6/+dUNp6Pu8d7uZchXHlb047xRMoEyVIiyEwavNGzdu1H+vKAqbNm0yaUGWqIVXG+LahhOYf5Cb89tQNs+FlPkPcWznKnOXJhoxg+EtLi7WzzGalZXF7dv3N1rDWmlcWlGmQguy0SjgRTrdjkdIgIXZGLxVNGPGDCZOnIiqqmg0GmbNmtUQdVkcv7gVaJTKyxyVInxPLIEQ0z/yRIi7GQxvUFAQa9as4datW7Rs2bIharJInmo6KNUtv9nwxQiBEc3m7du3M27cOF5++WVKS0uZMmVKQ9RlcdIUj2qX5+NAfm5WA1cjhBHh3bp1K2vWrMHFxQUbGxuyshrnL2pSz5noVG2lZSWqBmdFR/7SQI5/+Qlq2f1N6CxEXRgMr42NDfn5+SiKQmFhIYpSTduxEegV8grxQW+TggdlqkIKHpwMWkTC09vIsXEjKOZ1Ti9+nMSEE+YuVTQSBu/zxsXFERkZyblz5+jSpQuTJk2iR48eDVUfYP77vIaUlpTw47aldD4biaNayHHvEXQb+XecmrmZuzTxAKv1gpWqqly8eLHa5/aIX9nY2vLw8L9xK+0FTkbPoE/Kp6S9t4dzvebSc+BLKBp5YImof7X+VimKwnfffddQtVg9d08fek/b+GtT+tj08qb02ePmLk08gAzeKsrMzGTQoEF07NgRRVFQFKXBnghvrTr1+iOlgTEc/fw9Op9ZhuOmP3FEmtKinhk85/3pp5/0z66t4OPjY9Ki7mbp57y1uZV2jYsbZ9I7czdpuHO11xsEDRwrTWlx3wz+Bi1btgwfH59KX8J47p4+9J4aTcIzn5Nj40bwsRmcWfQYV6QpLe6TwWazp6cnq1evplu3bvrbRBVDBIXxOgX3pzSgvCnd6cwymmz6E4e9h9N95EJpSot7YjC8Pj4+FBUVceLEr/cvJbz3xsbWloefn0Vmehgno2fQNyWatPf2khD8BmppCb4nl+KpppOmeJDUcya9pM+0qIVRz21OT08nOTkZHx8fPD09G6KuSqz5nLc25348gGbPTNqXXqRUVbBRfv1foVO1xAe9LQEWNTJ45P344485evQonTp14syZM/Tp04eXX365IWp74HUMfoLSgKNkve2Hq5JXaZ2MWBKGGAzvgQMHiI6O1r8ODQ2V8NYjG1tbmql51Y5Yaqmmc3zDm/g8/CxeDwVCI+2aKqpnMLx2dnacOHGCLl26EB8fj62tzE1W39IUD7xIr7K8GBuCLi6Hi8tJVTy40fIPOPd4mnZBT6Kxb2KGSoUlMXjOe+PGDT766COuXr2Kn58fY8eOpVWrVg1VH/DgnvNWOLZzFd2OR+Co/Pp86opzXs8e/Uk8sgPHy/voUniCpsptCtFy2TkYpcOTtO33LA7N25ixemEuBsN75coV/Pz8UBQFVVVJTEykbdu2DVReuQc9vFAeYN8TS/BUb5KmtKj2anNmdg5njnxJ8Zm9+Gf9gK9S/hjeJK0/ub5P4N17MG7t+4LGxhw/gmhgBsM7ZswY1q1bV+PrhtAYwltXt4tLiIs9xq2TO/G48R09ys5iq5SRrTQjxfNRmvV4Gq+eT6E4ut3xh0FuQz1IDJ7AFhYW6r9XVbXSa2E+9na29OrVF3r1RVVVEq5c5crRL3C4/DW/TfkO99TdlHytIdXGh4CS69gppfDLg/NcjkdwDCTAVs5geAcPHkx4eDhdunTh7NmzDB48uCHqEnWgKAqd2/nRud1EYCIpmfl8dXQfRWf28OfsLeXBvYOjUkT7Ewso6fkwti07gZ2DeQoX98WoThq3bt0iOTmZ1q1bVxmk0BCk2Xzvyua5VHnq5Z1K0ZBu34Z8107YenfH3T8Q5zYB0KyV3JqycEbd93F3d69zaBcuXEh8fDxdunQhIiJCvzwrK4t58+aRmZlJ3759GT9+fN0qFnVS022oNNz43n86NulncM89z29SfqR16l74ZTbWPI0zGU3bU+zRhSa+v8XDvyd2Xl1AW/kWlZxPm49JbtreObn2vHnziIuL0z865/3332fKlCn4+/ubYtfiLkk9Z+JSzW2oxKA5DLkjZOm5tzl89Ro3fz5J0bWfaJJ5Fq/sS3TI2UrTnzfAd+VH6ZtaH/JcOqHx6kpB9k26J27GQSmW82kzMCq8eXl55ObmUtHCNnSft7rJtSvCe+HCBVatWsWNGzd4/fXXCQwMvJ/6hQG9Ql7hGFS+DRVU9ejo4WyPR9ffQNffAEMAKC4t40p6LomXzpKbeBJN6mlccs/TNjWOtulfl3+wmgfRdzjxP2T4tMTF+zfYuvuBg4vpf9BGyGB433zzTa5fv15pQEJ1k2LfqbbJtU+ePMn27dtxcXFh8uTJleZCAsuZXPtB0ivkFX0faa9fvoxhZ6OhvZcL7b36wCN99MuzC4o5lnSdoOge1Z5Pu5APu8boX+crTcnSelPQxJuyZr7YurehiWc73Fr549CiHTRpXu35tTTJa2cwvMnJyaxZs6ZOG3V2diYvr7yjfV5eHs2aNdOva9u2rb7JrKnmaRLDhw+vMvVnxQUrYRlcmtjRq6MfKTWcT6fiTmzf97mdcQWyrqLNu4ZT4Q08Mq7Q6taPOCfqKr2/EHtu2bUk37EVJc4+aNz8KLx5lR43/o29NMlrZNRg/HXr1tGhQwf9MkPjeWubXLtt27akpaXh5OREaWlpLVsRlq6m8+mrQbP585+frvL+ktIy0nIKuZCWSvaNS+jSL1OWeRXb3Gs01V3HPTsF7+x43K/9MsKqmiZ5j+NzOZu4j7KmLdA4eWLn7ImDmzdOzb1wdvfGxtkTtE0N1v4gHNUNhtfX15fc3FyOH//1sS2Gwlvb5NpTpkxh+vTpFBYWMmnSpPv/CYTZGHs+XcHWRkMrtya0cmsHHdtVWa+qKtm6Ys6k3aTTms7VNsm1FON4M47mN7NxVnRV3wDocCDXxpV8Ozdu2zen1LEFNPXAxtkDrYsX2Vdi6X4lymQX2hrqD4MMxhcWKWX+Q9U2yVPwwPOtC2TrirmVnUX2zRQKMlO4nZ1CSXYaakE6tgXpaG/fwrE4E+fSTNzVbNzJwVapfTqaYtWGq027UmLXjFJ7F1T7ZiiOrtg6umLn5IbWyQ1H5+Y0cWmOvZMrioMr2DeDO07/ahtkUt8BlsH4wiLV1CRPCpqJl0bBrakWt6ae0MoTqH0Gj9slpaTnFZKVkU5uxnWCdw+s9qhuSynZhWU45ifjrJ7DRcmnmVJQ67bLUChQmqLTOHHb1okehVewV0oqvaf8Cvz/kuRsh12TZtg3cca+qQsOTV3QODiD1gkcXY3+t/m1XgNkML4wh7o2yWtjb2uDt2tTvF2bgn9bUr6s4UKb4kHPt34AoLRMJbewmMT8QnJzMtHlZFKYe4vbeZmU5N+iTJeFWpiNUpiNTVEOdsW5aEty8eFitTW4kIfLd6/VXOT87Dr/XDIYX1ise73FZUitR/VfXttoFFybaHFtogWPZoCfUduuqbmfijsXBm6mRJdNsS6HEl0uZYV5cDsXinKpennPMINJXLRoER999BEffPABfn5+LF68+B52I4TlqM+j+t1quwL/u4d73/f271TjBStVVVEUhbJf5pyteA3V3581JblgJayJMQ9WqA81HnkXLVrEnDlzGDNmjD60FQFev359vRcixIPCVM39u9UY3jlz5gAwfvx4fT9lgB9//NFEpQgh6sJg+/fDDz+s9Hrt2rWmqkUIUQc1Hnm3bdvGtm3bOH/+PKNGjUJVVTQaDd27d2/I+oQQNagxvEOGDGHIkCEcOHCAJ554oiFrEkIYwWCzed++ffrvVVVl7ty5Ji1ICGEcg+FNSkrSf68oClevXjVpQUII4xjspOHm5sbWrVsJDAzk5MmTuLnJXLJCWAKDR97FixeTn5/Phg0b0Ol00sNKCAth8Mjr6OjIyJEjycjIQFVVMjMzcXR0bIjahBC1MBje1atXc/DgQX7++WfatGmDVquVe71CWACDzeb9+/ezfv162rVrR3R0NK6udR93KISofwbDq9VqAXBwcODYsWNcunTJ5EUJIQwzGN65c+dSVFTE7Nmz+eqrr5g1a1ZD1CWEMKDW8Kqqyr/+9S+0Wi3+/v5ERETw6KOPNlRtQoha1BpeRVHw8PDg1KlTlJSUUFZWph/fK4QwL4NXm+Pi4oiLi0NRFBnPK4QFqTG8eXl5ODk5ERUV1ZD1CCGMVGOzecKECfrv33jjjQYpRghhPKMeRpWcnGzqOoQQdVRjszk5OZnIyEhUVdV/X2Hq1KkGN1zT5NoAhYWF9O/fnyVLllR6xI4Qwni1PoCuQl0DVtvk2gBbt26tNHGZEKLuagxv7973/ozZ2ibXLioqIjY2lp49e97z9oUQRtwquhe1Ta69fft2QkJCiIuLq/azMrm2EMYxSXhrmly7pKSEgwcPsmLFihrDK5NrC2Eck0x9EBAQwJEjRwA4dOgQAQEBAGRkZHD9+nXGjh3Lzp07Wbp0KdnZdZ9gSQhhoiNvbZNrb9u2DYAVK1YQFBSEi4uLKUoQ4oFn1OTa5iZzFQlRVcPOGCaEqDcSXiGslIRXCCsl4RXCSkl4hbBSEl4hrJSEVwgrJeEVwkpJeIWwUhJeIayUhFcIKyXhFcJKSXiFsFISXiGslIRXCCsl4RXCSkl4hbBSEl4hrJSEVwgrJeEVwkpJeIWwUhJeIayUhFcIKyXhFcJKSXiFsFISXiGslEnmKgJYuHAh8fHxdOnShYiICP3yt956i/Pnz6MoCvPmzaNTp06mKkGIB5pJwnv69GkKCgqIjo5m3rx5xMXF6SfXfvnll/H19eXKlSssXbqUFStWGNxeaWkpACkpKaYoVwiL4OXlha2t8ZE0SXhjY2Pp168fAP369SM2NlYf3opJt21tbdFoqrbaq5tcOz8/H4BRo0aZolwhLEJdJ9IzSXhzc3P1IXV2dubChQtV3vPee+8RFhZWZXl1k2sXFhYSHx+Ph4cHNjY2pii5Tl599VU+/PBDc5dRZ1J3w6pr3V5eXnXavknC6+zsTF5eHgB5eXk0a9as0vq1a9fi7+9PcHCwUdtzcHAw+r0NQavVWuVUo1J3wzJ13Sa52hwQEMCRI0cAOHToEAEBAfp1Bw8e5OTJk0yYMMEUuxai0TBJeLt27YpWq2XkyJHY2Njg7e3NypUrAViwYAHJycmMHj2at956yxS7F6JRMNmtojtvDwGMHz8egK+++spUuxSiUbGZP3/+fHMXYY26detm7hLuidTdsExZt6KqqmqyrQshTEa6RwphpSS8QlgpCa8QVkrCWwenTp1ixIgRhIaGsnDhQnOXU2dr164lNDTU3GXUyY4dOxgzZgxhYWGkpqaauxyj6HQ6xo0bR1hYGOPHj6eoqMgk+5Hw1kGrVq1Yt24dGzduJCMjg3Pnzpm7JKMVFRVx9uxZc5dRJ6mpqcTExLBu3TqioqJo2bKluUsyyvfff0+PHj2IioqiR48e/Pe//zXJfiS8deDh4YG9vT0AdnZ2FtHP2lhbt25l8ODB5i6jTr7//nvKysoYM2YMCxYs0I8us3Rt2rRBp9MBkJOTg6urq0n2I+G9BwkJCdy6dYuHHnrI3KUYpbi4mJiYGPr27WvuUuokIyOD4uJi1q1bh4ODA/v37zd3SUbx8/MjNjaWp59+mvj4eHr27GmS/Uh46ygrK4sFCxbw97//3dylGO3f//43gwYNMncZdebk5ESvXr0A6NOnD5cuXTJzRcbZvn07jz/+OLt37+axxx5j586dJtmPhLcOSkpKmDlzJn/729/w8PAwdzlGu3z5Mhs3bmTs2LFcvHiRqKgoc5dklJ49e+qvK5w9e9ZqRhapqoqLiwsAbm5u5ObmmmQ/0sOqDr744gvefvtt2rdvD8Drr79OYGCgmauqm9DQUDZu3GjuMoy2ePFi4uPjcXNz491330Wr1Zq7JINycnJ47bXXKCoqwtbWln/+858mOe+V8AphpaTZLISVkvAKYaUkvEJYKQmvEFZKwiuElZLwWqCjR48SGBhITk4OALNnzyYxMfGetvX555+zdevW+iyPgoICRowYwZQpUyot/+yzz+q0nbCwMEpKSuqztEZFwmuhvL296z10xiorK6t1fUJCAsHBwSxfvrzS8m3btpmyLHEXkz2ATtyf/v3788033xAeHq5ftmLFCoKCgujXrx+zZ89m0qRJxMTE8O2331JYWEhpaSlPPPEEX375JW3bttV34Txw4AB79+5Fq9USGRmJnZ0d8+fP5/Llyzg4OLBkyRISEhJYs2YNUN6R4w9/+ANQ/gD9GTNmkJeXR+fOnYmIiGDJkiWkpKRgY2PDa6+9BpTPdHH+/HnCwsKIiIhg69atJCQkUFZWxrvvvkuLFi2YNGkSOp0Od3d3IiMj9T/Xrl27iIuLY+LEiUyePBmAjh07VnmIoahMjrwWSqPR8Pjjj/Of//zH4Hs9PT1ZvXo1rVq1ori4mE8//ZQbN26QlZUFQPPmzfnkk08IDAzk66+/5ptvvqFVq1asX7+eUaNGsWnTJqB8AMOHH36oDy6Uh3LgwIF8+umn6HQ6Tp06xbRp0wgJCdEHF8pnuujQoQNRUVF07NiR6dOns2HDBiZNmsTmzZtJSUnB3d2dqKgoli1bpv/cF198walTp5g7dy5nz56ld+/eREVFMXfu3Pr6p3xgyZHXgg0bNoxp06bh6ekJgKIo+nV3dozr0KEDUB7iiq6bnp6e+nPmzp076//7008/YWdnx+7duzl48CAlJSX6h+J37dq1Sg1Xr17Vh7lbt24kJiYaNa72448/5vDhw5SUlODv70+bNm3o0KED06dPp1u3brz44osAfPTRR0RHRwMQHBxMTEwM06dP59FHH7W6IYwNTcJrwZo1a0a7du04fPgwUD7KJi0tDVVVK83/dGeoqwt4Ref+hIQE2rRpg4ODA4MHD+all14Cyo+4J06cqPTZCm3atOH06dO0b9+e+Ph4hg0bxu3bt6utt+LzmZmZxMTEEB0dzQ8//MCuXbsoKioiPDwcjUbDSy+9pB/ltGjRImbOnMny5ctRFIWpU6cC8Je//EXCa4A0my1cWFgYP//8MwADBgxg/fr1TJ06VT9qxRhZWVm89NJLHD9+nAEDBtC/f3+uXbvG6NGjGT16dK1Penj++efZvXs3I0eORKvVVpq65m7e3t5MnjyZjIwMmjRpwujRo/n2228BuHbtGqNGjWL48OG4ubnRvHlzoLw1MHbsWGbNmkVcXByhoaEMGzZMP8ukqJkMTBDCSsmRVwgrJeEVwkpJeIWwUhJeIayUhFcIKyXhFcJKSXiFsFL/DzetswPtcIQJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 237.6x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fractional Correctness = Average of cross validation accuracies of learned tasks only after training each task \n",
    "fig = plt.figure(figsize=(3.3,2.5))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "for cval in sorted_keys:\n",
    "    mean_stuff = []\n",
    "    std_stuff = []\n",
    "    for i in range(len(data['mean'][cval])):\n",
    "        mean_stuff.append(data['mean'][cval][i][:i+1].mean())\n",
    "        std_stuff.append(np.sqrt((data['std'][cval][i][:i+1]**2).sum())/(n_stats*np.sqrt(n_stats)))\n",
    "    # plot(range(1,n_tasks+1), mean_stuff, 'o-', label=\"c=%g\"%cval)\n",
    "    errorbar(range(1,n_tasks+1), mean_stuff, yerr=std_stuff, fmt='o-', label=\"c=%g\"%cval)\n",
    "        \n",
    "axhline(data['mean'][cval][0][0], linestyle='--', color='k')\n",
    "xlabel('Number of tasks')\n",
    "ylabel('Fraction correct')\n",
    "legend(loc='best')\n",
    "xlim(0.5, 8.5)\n",
    "ylim(0.2, 1.02)\n",
    "# grid('on')\n",
    "# sns.despine()\n",
    "simple_axis(ax)\n",
    "plt.savefig('2attack_fractional_correct_UNSW.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the Autocorrelation Matrix for task= 0 is : 10\n",
      "Rank of the Autocorrelation Matrix for task= 1 is : 10\n",
      "Rank of the Autocorrelation Matrix for task= 2 is : 10\n",
      "Rank of the Autocorrelation Matrix for task= 3 is : 10\n",
      "Rank of the Autocorrelation Matrix for task= 4 is : 10\n",
      "Rank of the Autocorrelation Matrix for task= 5 is : 10\n",
      "Rank of the Autocorrelation Matrix for task= 6 is : 10\n",
      "Rank of the Autocorrelation Matrix for task= 7 is : 10\n",
      "Rank of the Autocorrelation Matrix for task= 8 is : 10\n",
      "Rank of the Autocorrelation Matrix for task= 9 is : 10\n",
      "Rank of the Autocorrelation Matrix for task= 10 is : 10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from numpy.linalg import matrix_rank\n",
    "import math\n",
    "corr_matrix = []\n",
    "corr_row = []\n",
    "Rank_corr_matrix=[]\n",
    "for j in range(n_tasks):\n",
    "    df = pd.DataFrame(training_datasets[j][0])\n",
    "    correlation_matrix = df.corr().values\n",
    "    correlation_matrix = np.nan_to_num(correlation_matrix)\n",
    "    for k in range(len(correlation_matrix)):\n",
    "        for i in range(len(correlation_matrix)):\n",
    "            corr_elem = (math.ceil(correlation_matrix[k][i]*1e10)/1e10)\n",
    "            corr_row.append(np.around(corr_elem))\n",
    "        corr_matrix.append(corr_row)\n",
    "        corr_row = []\n",
    "    rank_corr_matrix=np.linalg.matrix_rank(np.asarray(corr_matrix))\n",
    "    Rank_corr_matrix.append(rank_corr_matrix)\n",
    "    print('Rank of the Autocorrelation Matrix for task=',j,'is :',rank_corr_matrix)\n",
    "    corr_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-6c25ee737fb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mcurr_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprev_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_datasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mcorrelation_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_task\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprev_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mcorrelation_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan_to_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelation_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelation_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof)\u001b[0m\n\u001b[1;32m   2390\u001b[0m         warnings.warn('bias and ddof have no effect and are deprecated',\n\u001b[1;32m   2391\u001b[0m                       DeprecationWarning, stacklevel=2)\n\u001b[0;32m-> 2392\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2393\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2394\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights)\u001b[0m\n\u001b[1;32m   2323\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m         \u001b[0mX_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2326\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrue_divide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corr_matrix = []\n",
    "corr_row = []\n",
    "Rank_corr_matrix=[]\n",
    "for j in range(1,n_tasks):\n",
    "    for m in range(j):\n",
    "        curr_task = training_datasets[j][0]\n",
    "        prev_task = training_datasets[m][0]\n",
    "        correlation_matrix = np.corrcoef(curr_task,prev_task)\n",
    "        correlation_matrix = np.nan_to_num(correlation_matrix)\n",
    "        for k in range(len(correlation_matrix)):\n",
    "            for i in range(len(correlation_matrix)):\n",
    "                corr_elem = (math.ceil(correlation_matrix[k][i]*1e5)/1e5)\n",
    "                corr_row.append(np.around(corr_elem))\n",
    "            corr_matrix.append(corr_row)\n",
    "            corr_row = []\n",
    "        rank_corr_matrix=np.linalg.matrix_rank(np.asarray(corr_matrix))\n",
    "        Rank_corr_matrix.append(rank_corr_matrix)\n",
    "        print('Rank of the Cross-correlation Matrix of shape {0} between task {1} and {2} is: {3}'.format(correlation_matrix.shape,j,m,rank_corr_matrix))\n",
    "        corr_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "mean_stuff = [0.897,0.9301,0.9498,0.8902,0.8321]\n",
    "print(len(model_weights_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weights Pattern after training each task\n",
    "Flatten_weights=[]\n",
    "#Flattening the weights into a list\n",
    "def flatten(x):\n",
    "    try:\n",
    "        it = iter(x)\n",
    "    except TypeError:\n",
    "        yield x\n",
    "    else:\n",
    "        for i in it:\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "                \n",
    "for i in range(len(model_weights_save)):\n",
    "    Flatten_weights.append(list(flatten(model_weights_save[i]))) \n",
    "\n",
    "Extract_model_params = [];\n",
    "#For model parameters without consolidation use val, with consolidation use val+50 \n",
    "for i in range(n_tasks):   \n",
    "    Extract_model_params.append(Flatten_weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of the Hessian Matrix after task= 0 is : 152\n",
      "Rank of the Hessian Matrix after task= 1 is : 141\n",
      "Rank of the Hessian Matrix after task= 2 is : 155\n",
      "Rank of the Hessian Matrix after task= 3 is : 158\n",
      "Rank of the Hessian Matrix after task= 4 is : 139\n",
      "Rank of the Hessian Matrix after task= 5 is : 141\n",
      "Rank of the Hessian Matrix after task= 6 is : 135\n",
      "Rank of the Hessian Matrix after task= 7 is : 115\n",
      "Rank of the Hessian Matrix after task= 8 is : 30\n"
     ]
    }
   ],
   "source": [
    "#Weights Pattern after training each task\n",
    "Flatten_weights=[]\n",
    "#Flattening the weights into a list\n",
    "def flatten(x):\n",
    "    try:\n",
    "        it = iter(x)\n",
    "    except TypeError:\n",
    "        yield x\n",
    "    else:\n",
    "        for i in it:\n",
    "            for j in flatten(i):\n",
    "                yield j\n",
    "                \n",
    "for i in range(len(model_weights_save)):\n",
    "    Flatten_weights.append(list(flatten(model_weights_save[i]))) \n",
    "\n",
    "Extract_model_params = [];\n",
    "#For model parameters without consolidation use val, with consolidation use val+80 \n",
    "for i in range(n_tasks):   \n",
    "    Extract_model_params.append(Flatten_weights[i])\n",
    "    \n",
    "gradient_save=[]\n",
    "for i in range(1,len(Extract_model_params)):\n",
    "    temp=list(np.asarray(Extract_model_params[i-1])-np.asarray(Extract_model_params[i]))\n",
    "    \n",
    "    gradient = [j/0.001 for j in temp]\n",
    "    gradient_save.append(gradient)\n",
    "    \n",
    "#Creating the Hessian matrix from the gradients\n",
    "import math\n",
    "Hessian_matrix = []\n",
    "Hessian_row = []\n",
    "Rank_Hessian_matrix = []\n",
    "for k in range(len(gradient_save)):\n",
    "    for i in range(len(gradient_save[k])):\n",
    "        partial_deriv_1 = (math.ceil(gradient_save[k][i]*1e10)/1e10)\n",
    "        for j in range(len(gradient_save[k])):\n",
    "            partial_deriv_2 = (math.ceil(gradient_save[k][j]*1e10)/1e10)\n",
    "            Hessian_row.append(np.around(partial_deriv_1*partial_deriv_2))\n",
    "        Hessian_matrix.append(Hessian_row)\n",
    "        Hessian_row = []\n",
    "    rank_Hessian_matrix = np.linalg.matrix_rank(np.asarray(Hessian_matrix))\n",
    "    Rank_Hessian_matrix.append(rank_Hessian_matrix)\n",
    "    print('Rank of the Hessian Matrix after task=',k,'is :',rank_Hessian_matrix)\n",
    "    Hessian_matrix = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eucledian Parameter shift after task 1 : 18.42116476268859\n",
      "Eucledian Parameter shift after task 2 : 9.208601450530098\n",
      "Eucledian Parameter shift after task 3 : 3.934590313084037\n",
      "Eucledian Parameter shift after task 4 : 0.7763082720953064\n",
      "Eucledian Parameter shift after task 5 : 2.4158320680373264\n",
      "Eucledian Parameter shift after task 6 : 2.6746329869635184\n",
      "Eucledian Parameter shift after task 7 : 5.5886347410127915\n",
      "Eucledian Parameter shift after task 8 : 3.289132188129787\n",
      "Eucledian Parameter shift after task 9 : 3.2878901208808284\n",
      "Cosine Parameter shift after task 1 : 0.132\n",
      "Cosine Parameter shift after task 2 : 0.891\n",
      "Cosine Parameter shift after task 3 : 0.981\n",
      "Cosine Parameter shift after task 4 : 0.999\n",
      "Cosine Parameter shift after task 5 : 0.993\n",
      "Cosine Parameter shift after task 6 : 0.992\n",
      "Cosine Parameter shift after task 7 : 0.966\n",
      "Cosine Parameter shift after task 8 : 0.989\n",
      "Cosine Parameter shift after task 9 : 0.989\n",
      "Jaccard Parameter shift after task 1 : 0.16968781470292044\n",
      "Jaccard Parameter shift after task 2 : 0.21566579634464753\n",
      "Jaccard Parameter shift after task 3 : 0.16733466933867736\n",
      "Jaccard Parameter shift after task 4 : 0.2149557060969255\n",
      "Jaccard Parameter shift after task 5 : 0.1787158746208291\n",
      "Jaccard Parameter shift after task 6 : 0.16837885241794037\n",
      "Jaccard Parameter shift after task 7 : 0.16396306463688545\n",
      "Jaccard Parameter shift after task 8 : 0.16862941618641944\n",
      "Jaccard Parameter shift after task 9 : 0.19835560123329907\n",
      "Heuristic Parameter shift after task 1 : 0.2911663807890223\n",
      "Heuristic Parameter shift after task 2 : 0.35548885077186965\n",
      "Heuristic Parameter shift after task 3 : 0.2868782161234991\n",
      "Heuristic Parameter shift after task 4 : 0.35377358490566035\n",
      "Heuristic Parameter shift after task 5 : 0.3031732418524871\n",
      "Heuristic Parameter shift after task 6 : 0.2881646655231561\n",
      "Heuristic Parameter shift after task 7 : 0.28173241852487135\n",
      "Heuristic Parameter shift after task 8 : 0.2885934819897084\n",
      "Heuristic Parameter shift after task 9 : 0.33104631217838765\n"
     ]
    }
   ],
   "source": [
    "#Weights Pattern after training each task\n",
    "from math import*\n",
    "#1. Euclidean distance\n",
    "def euclidean_distance(x,y):\n",
    "    return sqrt(sum(pow(a-b,2) for a, b in zip(x, y)))\n",
    "#2. Manhattan Distance\n",
    "def manhattan_distance(x,y):\n",
    "    return sum(abs(a-b) for a,b in zip(x,y))\n",
    "#3.  Minkowski distance \n",
    "from decimal import Decimal\n",
    "def nth_root(value, n_root):\n",
    "    root_value = 1/float(n_root)\n",
    "    return round (Decimal(value) ** Decimal(root_value),3)\n",
    "def minkowski_distance(x,y,p_value):\n",
    "    return nth_root(sum(pow(abs(a-b),p_value) for a,b in zip(x, y)),p_value)\n",
    "#4. Cosine Similarity\n",
    "def square_rooted(x):\n",
    "    return round(sqrt(sum([a*a for a in x])),3)\n",
    "def cosine_similarity(x,y):\n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = square_rooted(x)*square_rooted(y)\n",
    "    return round(numerator/float(denominator),3)\n",
    "#5. Jaccard similarity\n",
    "def jaccard_similarity(x,y):\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "#6. Using Heuristic    \n",
    "import difflib \n",
    "\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Eucledian Parameter shift after task {0} :\".format(i+1),euclidean_distance(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Cosine Parameter shift after task {0} :\".format(i+1),cosine_similarity(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Jaccard Parameter shift after task {0} :\".format(i+1),jaccard_similarity(Extract_model_params[i],Extract_model_params[i+1]))\n",
    "for i in [0,1,2,3,4,5,6,7,8]:\n",
    "    print(\"Heuristic Parameter shift after task {0} :\".format(i+1),difflib.SequenceMatcher(None,Extract_model_params[i],Extract_model_params[i+1]).ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#Counting the number of changed parameters\n",
    "changed_model_parameters=[]\n",
    "for i in range(1,len(Extract_model_params)):\n",
    "    temp=[]\n",
    "    for j,k in zip(Extract_model_params[i],Extract_model_params[i-1]):\n",
    "        temp.append(abs(i-j))\n",
    "    changed_model_parameters.append(temp)\n",
    "print(len(changed_model_parameters))\n",
    "\n",
    "import csv\n",
    "#Save the model parameters in text file\n",
    "with open('temp', 'w') as myfile:\n",
    "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(Extract_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----After learning 2 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 1\n",
      "0.1 ----> 14\n",
      "-----After learning 3 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 0\n",
      "-----After learning 4 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 1\n",
      "-----After learning 5 task-----\n",
      "1e-05 ----> 0\n",
      "0.0001 ----> 0\n",
      "0.001 ----> 0\n",
      "0.01 ----> 0\n",
      "0.1 ----> 1\n"
     ]
    }
   ],
   "source": [
    "#Number of parameters unchanged within the thresold. Checked for five threshold values as [1e-5, 1e-4, 1e-3, 1e-2, 1e-1].\n",
    "for i in range(len(changed_model_parameters)):\n",
    "    print('-----After learning',i+2,'task-----')\n",
    "    for j in [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]:\n",
    "        print(j,'---->',sum(k < j for k in changed_model_parameters[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the parameters for future use\n",
    "import pickle\n",
    "with open(\"UNSW_Parameters.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(model_weights_save, fp)\n",
    "    \n",
    "with open(\"UNSW_Parameters.txt\", \"rb\") as fp:   # Unpickling\n",
    "    b = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
