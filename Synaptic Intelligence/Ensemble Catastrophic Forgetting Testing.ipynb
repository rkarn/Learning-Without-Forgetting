{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Training csv file.\n",
      "Reading Testing csv file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir('/Users/rupesh.karn/Desktop/WorkPart-1/UNSW-NB15 Dataset')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "pylab.rcParams['figure.figsize'] = (16.0, 5.0)\n",
    "import sklearn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf1 = KNeighborsClassifier()\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "clf2 = sklearn.naive_bayes.GaussianNB()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3 =  RandomForestClassifier()\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf4 = MLPClassifier()\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf5 = GradientBoostingClassifier()\n",
    "from sklearn import tree\n",
    "clf6 = tree.DecisionTreeClassifier()\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf7 = SGDClassifier()\n",
    "\n",
    "# Read in the training CSV file\n",
    "print \"Reading Training csv file.\"\n",
    "df1 = pd.read_csv(\"UNSW_NB15_training-set.csv\")\n",
    "df1.drop('label', axis=1, inplace=True)\n",
    "\n",
    "obj_df=df1\n",
    "\n",
    "obj_df[\"proto\"] = obj_df[\"proto\"].astype('category')\n",
    "obj_df[\"service\"] = obj_df[\"service\"].astype('category')\n",
    "obj_df[\"state\"] = obj_df[\"state\"].astype('category')\n",
    "obj_df[\"proto_cat\"] = obj_df[\"proto\"].cat.codes\n",
    "obj_df[\"service_cat\"] = obj_df[\"service\"].cat.codes\n",
    "obj_df[\"state_cat\"] = obj_df[\"state\"].cat.codes\n",
    "\n",
    "obj_df[\"proto\"] = obj_df[\"proto_cat\"]\n",
    "obj_df[\"service\"] = obj_df[\"service_cat\"]\n",
    "obj_df[\"state\"] = obj_df[\"state_cat\"]\n",
    "\n",
    "obj_df.drop('proto_cat', axis=1, inplace=True)\n",
    "obj_df.drop('service_cat', axis=1, inplace=True)\n",
    "obj_df.drop('state_cat', axis=1, inplace=True)\n",
    "\n",
    "obj_df=pd.get_dummies(obj_df, columns=[\"attack_cat\"])\n",
    "\n",
    "\n",
    "X_train = obj_df.values[:,:-10]\n",
    "\n",
    "\n",
    "for j in range(0,43):\n",
    "    maximum = max(X_train[:,j])\n",
    "    for i in range(0,len(X_train)):\n",
    "        X_train[i,j] = round(X_train[i,j]/maximum,3)\n",
    "\n",
    "# Read in the testing CSV file \n",
    "print \"Reading Testing csv file.\"\n",
    "df2 = pd.read_csv(\"UNSW_NB15_testing-set.csv\")\n",
    "df2.drop('label', axis=1, inplace=True)\n",
    "\n",
    "obj_df2=df2\n",
    "\n",
    "obj_df2[\"proto\"] = obj_df2[\"proto\"].astype('category')\n",
    "obj_df2[\"service\"] = obj_df2[\"service\"].astype('category')\n",
    "obj_df2[\"state\"] = obj_df2[\"state\"].astype('category')\n",
    "obj_df2[\"proto_cat\"] = obj_df2[\"proto\"].cat.codes\n",
    "obj_df2[\"service_cat\"] = obj_df2[\"service\"].cat.codes\n",
    "obj_df2[\"state_cat\"] = obj_df2[\"state\"].cat.codes\n",
    "\n",
    "obj_df2[\"proto\"] = obj_df2[\"proto_cat\"]\n",
    "obj_df2[\"service\"] = obj_df2[\"service_cat\"]\n",
    "obj_df2[\"state\"] = obj_df2[\"state_cat\"]\n",
    "\n",
    "obj_df2.drop('proto_cat', axis=1, inplace=True)\n",
    "obj_df2.drop('service_cat', axis=1, inplace=True)\n",
    "obj_df2.drop('state_cat', axis=1, inplace=True)\n",
    "\n",
    "obj_df2=pd.get_dummies(obj_df2, columns=[\"attack_cat\"])\n",
    "\n",
    "\n",
    "X_test = obj_df2.values[:,:-10]\n",
    "\n",
    "\n",
    "for j in range(0,43):\n",
    "    maximum = max(X_train[:,j])\n",
    "    for i in range(0,len(X_test)):\n",
    "        X_test[i,j] = round(X_test[i,j]/maximum,3)\n",
    "\n",
    "\n",
    "estimators_number = list(range(10,30))\n",
    "\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = []\n",
    "model_list=[clf1,clf2,clf3,clf4,clf5,clf6,clf7]\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "dataspace = 0;\n",
    "overall_accuracy_matrix = [None]*len(X_train)\n",
    "iTERATION=0\n",
    "dataspace_number=1\n",
    "attack_type = 4\n",
    "Y_train = obj_df.values[:,-attack_type]\n",
    "Y_test = obj_df2.values[:,-attack_type]\n",
    "\n",
    "Y_train_all_attack=df1[\"attack_cat\"]\n",
    "Y_test_all_attack=df2[\"attack_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Modeling\n",
      "Naive Bayes Modeling\n",
      "Random Forest Modeling\n",
      "ML Perceptron Modeling\n",
      "Gradient Boosting Modeling\n",
      "Decision Tree Modeling\n",
      "SGD Modeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rkarn\\AppData\\Local\\Continuum\\anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting from the model.\n",
      "KNN Model 35.0 %\n",
      "Naive Bayes Model 26.4 %\n",
      "Random Forest Model 32.0 %\n",
      "ML Perceptron Model 32.9 %\n",
      "Gradient Boosting Model 3.2 %\n",
      "Decision Tree Model 21.8 %\n",
      "SGD Model 21.5 %\n"
     ]
    }
   ],
   "source": [
    "print \"KNN Modeling\"; clf1=clf1.fit(X_train, Y_train_all_attack);   \n",
    "print \"Naive Bayes Modeling\";  clf2=clf2.fit(X_train, Y_train_all_attack)\n",
    "print \"Random Forest Modeling\";  clf3=clf3.fit(X_train, Y_train_all_attack)\n",
    "print \"ML Perceptron Modeling\";  clf4=clf4.fit(X_train, Y_train_all_attack)\n",
    "print \"Gradient Boosting Modeling\";  clf5=clf5.fit(X_train, Y_train_all_attack)\n",
    "print \"Decision Tree Modeling\";  clf6=clf6.fit(X_train, Y_train_all_attack)\n",
    "print \"SGD Modeling\";  clf7=clf7.fit(X_train, Y_train_all_attack)\n",
    "\n",
    "print \"Predicting from the model.\"\n",
    "# predict the response34.212.121.9\n",
    "pred = clf1.predict(X_test); print \"KNN Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf2.predict(X_test); print \"Naive Bayes Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf3.predict(X_test); print \"Random Forest Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf4.predict(X_test); print \"ML Perceptron Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf5.predict(X_test); print \"Gradient Boosting Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf6.predict(X_test); print \"Decision Tree Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf7.predict(X_test); print \"SGD Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_Normal = [i for i, x in enumerate(Y_train_all_attack.tolist()) if x == \"Normal\"]\n",
    "indices_Reconnaissance = [i for i, x in enumerate(Y_train_all_attack.tolist()) if x == \"Reconnaissance\"]\n",
    "indices_Backdoor = [i for i, x in enumerate(Y_train_all_attack.tolist()) if x == \"Backdoor\"]\n",
    "indices_DoS = [i for i, x in enumerate(Y_train_all_attack.tolist()) if x == \"DoS\"]\n",
    "indices_Exploits = [i for i, x in enumerate(Y_train_all_attack.tolist()) if x == \"Exploits\"]\n",
    "indices_Analysis = [i for i, x in enumerate(Y_train_all_attack.tolist()) if x == \"Analysis\"]\n",
    "indices_Fuzzers = [i for i, x in enumerate(Y_train_all_attack.tolist()) if x == \"Fuzzers\"]\n",
    "indices_Worms = [i for i, x in enumerate(Y_train_all_attack.tolist()) if x == \"Worms\"]\n",
    "indices_Shellcode = [i for i, x in enumerate(Y_train_all_attack.tolist()) if x == \"Shellcode\"]\n",
    "indices_Generic = [i for i, x in enumerate(Y_train_all_attack.tolist()) if x == \"Generic\"]\n",
    "\n",
    "X_train_Normal = X_train[indices_Normal,:]; Y_train_Normal = Y_train_all_attack[indices_Normal]\n",
    "X_train_Reconnaissance = X_train[indices_Reconnaissance,:]; Y_train_Reconnaissance = Y_train_all_attack[indices_Reconnaissance]\n",
    "X_train_Backdoor = X_train[indices_Backdoor,:]; Y_train_Backdoor = Y_train_all_attack[indices_Backdoor]\n",
    "X_train_DoS = X_train[indices_DoS,:]; Y_train_DoS = Y_train_all_attack[indices_DoS]\n",
    "X_train_Exploits = X_train[indices_Exploits,:]; Y_train_Exploits = Y_train_all_attack[indices_Exploits]\n",
    "X_train_Analysis = X_train[indices_Analysis,:]; Y_train_Analysis = Y_train_all_attack[indices_Analysis]\n",
    "X_train_Fuzzers = X_train[indices_Fuzzers,:]; Y_train_Fuzzers = Y_train_all_attack[indices_Fuzzers]\n",
    "X_train_Worms = X_train[indices_Worms,:]; Y_train_Worms = Y_train_all_attack[indices_Worms]\n",
    "X_train_Shellcode = X_train[indices_Shellcode,:]; Y_train_Shellcode = Y_train_all_attack[indices_Shellcode]\n",
    "X_train_Generic = X_train[indices_Generic,:]; Y_train_Generic = Y_train_all_attack[indices_Generic]\n",
    "\n",
    "X_train_reduced1 = np.concatenate((X_train_Normal, X_train_Reconnaissance, X_train_Backdoor, X_train_DoS, X_train_Exploits), axis=0)\n",
    "X_train_reduced2 = np.concatenate((X_train_Analysis, X_train_Fuzzers, X_train_Worms, X_train_Shellcode, X_train_Generic), axis=0)\n",
    "\n",
    "Y_train_all_attack_reduced1 = np.concatenate((Y_train_Normal, Y_train_Reconnaissance, Y_train_Backdoor, Y_train_DoS, Y_train_Exploits), axis=0)\n",
    "Y_train_all_attack_reduced2 = np.concatenate((Y_train_Analysis, Y_train_Fuzzers, Y_train_Worms, Y_train_Shellcode, Y_train_Generic), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Modeling\n",
      "Naive Bayes Modeling\n",
      "Random Forest Modeling\n",
      "ML Perceptron Modeling\n",
      "Gradient Boosting Modeling\n",
      "Decision Tree Modeling\n",
      "SGD Modeling\n",
      "KNN Modeling\n",
      "Naive Bayes Modeling\n",
      "Random Forest Modeling\n",
      "ML Perceptron Modeling\n",
      "Gradient Boosting Modeling\n",
      "Decision Tree Modeling\n",
      "SGD Modeling\n",
      "Predicting from the model.\n",
      "KNN Model 10.4 %\n",
      "Naive Bayes Model 9.0 %\n",
      "Random Forest Model 15.4 %\n",
      "ML Perceptron Model 4.6 %\n",
      "Gradient Boosting Model 23.1 %\n",
      "Decision Tree Model 6.7 %\n",
      "SGD Model 3.6 %\n"
     ]
    }
   ],
   "source": [
    "del clf1; del clf2; del clf3; del clf4; del clf5; del clf6; del clf7;\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf1 = KNeighborsClassifier()\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "clf2 = sklearn.naive_bayes.GaussianNB()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3 =  RandomForestClassifier()\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "clf4 = MLPClassifier()\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf5 = GradientBoostingClassifier()\n",
    "from sklearn import tree\n",
    "clf6 = tree.DecisionTreeClassifier()\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf7 = SGDClassifier()\n",
    "\n",
    "\n",
    "print \"KNN Modeling\"; clf1.fit(X_train_reduced1, Y_train_all_attack_reduced1);   \n",
    "print \"Naive Bayes Modeling\"; clf2.fit(X_train_reduced1, Y_train_all_attack_reduced1)\n",
    "print \"Random Forest Modeling\";  clf3.fit(X_train_reduced1, Y_train_all_attack_reduced1)\n",
    "print \"ML Perceptron Modeling\";  clf4.fit(X_train_reduced1, Y_train_all_attack_reduced1)\n",
    "print \"Gradient Boosting Modeling\";  clf5.fit(X_train_reduced1, Y_train_all_attack_reduced1)\n",
    "print \"Decision Tree Modeling\";  clf6.fit(X_train_reduced1, Y_train_all_attack_reduced1)\n",
    "print \"SGD Modeling\"; clf7.fit(X_train_reduced1, Y_train_all_attack_reduced1)\n",
    "\n",
    "print \"KNN Modeling\"; clf1.fit(X_train_reduced2, Y_train_all_attack_reduced2);   \n",
    "print \"Naive Bayes Modeling\"; clf2.fit(X_train_reduced2, Y_train_all_attack_reduced2)\n",
    "print \"Random Forest Modeling\";  clf3.fit(X_train_reduced2, Y_train_all_attack_reduced2)\n",
    "print \"ML Perceptron Modeling\";  clf4.fit(X_train_reduced2, Y_train_all_attack_reduced2)\n",
    "print \"Gradient Boosting Modeling\";  clf5.fit(X_train_reduced2, Y_train_all_attack_reduced2)\n",
    "print \"Decision Tree Modeling\";  clf6.fit(X_train_reduced2, Y_train_all_attack_reduced2)\n",
    "print \"SGD Modeling\"; clf7.fit(X_train_reduced2, Y_train_all_attack_reduced2)\n",
    "\n",
    "print \"Predicting from the model.\"\n",
    "# predict the response34.212.121.9\n",
    "pred = clf1.predict(X_test); print \"KNN Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf2.predict(X_test); print \"Naive Bayes Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf3.predict(X_test); print \"Random Forest Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf4.predict(X_test); print \"ML Perceptron Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf5.predict(X_test); print \"Gradient Boosting Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf6.predict(X_test); print \"Decision Tree Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "pred = clf7.predict(X_test); print \"SGD Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model 24.3 %\n",
      "set(['DoS', 'Exploits', 'Normal'])\n"
     ]
    }
   ],
   "source": [
    "del clf3; clf3 =  RandomForestClassifier(); \n",
    "clf3.fit(X_train_reduced2, Y_train_all_attack_reduced2); clf3.fit(X_train_reduced1, Y_train_all_attack_reduced1)\n",
    "pred = clf3.predict(X_test); print \"Random Forest Model\",(round(accuracy_score(Y_test_all_attack, pred),3)*100),\"%\"\n",
    "print set(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
